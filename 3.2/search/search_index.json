{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kotbase","text":"<p>Kotlin Multiplatform library for Couchbase Lite</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Kotbase pairs Kotlin Multiplatform with Couchbase Lite, an embedded NoSQL JSON document database. Couchbase Lite can be used as a standalone client database, or paired with Couchbase Server and Sync Gateway or Capella App Services for cloud to edge data synchronization. Features include:</p> <ul> <li>SQL++, key/value, full-text search, and vector search queries</li> <li>Observable queries, documents, databases, and replicators</li> <li>Binary document attachments (blobs)</li> <li>Peer-to-peer and cloud-to-edge data sync</li> </ul> <p>Kotbase provides full Enterprise and Community Edition API support for Android and JVM, native iOS and macOS, and experimental support for native Linux and Windows.</p>"},{"location":"active-peer/","title":"Active Peer","text":"<p>How to set up a replicator to connect with a listener and replicate changes using peer-to-peer sync</p> <p>Android enablers</p> <p>Allow Unencrypted Network Traffic</p> <p>To use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>Use Background Threads</p> <p>As with any network or file I/O activity, Couchbase Lite activities should not be performed on the UI thread. Always use a background thread.</p> <p>Code Snippets</p> <p>All code examples are indicative only. They demonstrate the basic concepts and approaches to using a feature. Use them as inspiration and adapt these examples to best practice when developing applications for your platform.</p>"},{"location":"active-peer/#introduction","title":"Introduction","text":"<p>This is an Enterprise Edition feature.</p> <p>This content provides sample code and configuration examples covering the implementation of Peer-to-Peer Sync over WebSockets. Specifically it covers the implementation of an Active Peer.</p> <p>This active peer (also referred to as a client and-or a replicator) will initiate the connection with a Passive Peer (also referred to as a server and-or listener) and participate in the replication of database changes to bring both databases into sync.</p> <p>Subsequent sections provide additional details and examples for the main configuration options.</p> <p>Secure Storage</p> <p>The use of TLS, its associated keys and certificates requires using secure storage to minimize the chances of a security breach. The implementation of this storage differs from platform to platform \u2014 see Using Secure Storage.</p>"},{"location":"active-peer/#configuration-summary","title":"Configuration Summary","text":"<p>You should configure and initialize a replicator for each Couchbase Lite database instance you want to sync. Example 1  shows the initialization and configuration process.</p> <p>Note</p> <p>As with any network or file I/O activity, Couchbase Lite activities should not be performed on the UI thread. Always use a background thread.</p> <p>Example 1. Replication configuration and initialization</p> <pre><code>val repl = Replicator(\n    // initialize the replicator configuration\n    ReplicatorConfiguration(URLEndpoint(\"wss://listener.com:8954\"))\n        .addCollections(\n            collections,\n            CollectionConfiguration(\n                conflictResolver = ReplicatorConfiguration.DEFAULT_CONFLICT_RESOLVER\n            )\n        ).apply {\n            // Set replicator type\n            type = ReplicatorType.PUSH_AND_PULL\n\n            // Configure Sync Mode\n            isContinuous = false // default value\n\n            // Configure Server Authentication --\n            // only accept self-signed certs\n            isAcceptOnlySelfSignedServerCertificate = true\n\n            // Configure the credentials the\n            // client will provide if prompted\n            authenticator = BasicAuthenticator(\"PRIVUSER\", \"let me in\".toCharArray())\n        }\n)\n\n// Optionally add a change listener\nval token = repl.addChangeListener { change -&gt;\n    val err: CouchbaseLiteException? = change.status.error\n    if (err != null) {\n        println(\"Error code ::  ${err.code}\\n$err\")\n    }\n}\n\n// Start replicator\nrepl.start(false)\n\nthis.replicator = repl\nthis.token = token\n</code></pre> <ol> <li>Get the listener\u2019s endpoint. Here we use a known URL, but it could be a URL established dynamically in a discovery    phase.</li> <li>Identify the collections from the local database to be used.</li> <li>Configure how the replication should perform Conflict Resolution.</li> <li>Configure how the client will authenticate the server. Here we say connect only to servers presenting a self-signed    certificate. By default, clients accept only servers presenting certificates that can be verified using the OS    bundled Root CA Certificates \u2014 see Authenticating the Listener.</li> <li>Configure the credentials the client will present to the server. Here we say to provide Basic Authentication    credentials. Other options are available \u2014 see Example 7.</li> <li>Initialize the replicator using your configuration object.</li> <li>Register an observer, which will notify you of changes to the replication status.</li> <li>Start the replicator.</li> </ol>"},{"location":"active-peer/#device-discovery","title":"Device Discovery","text":"<p>This phase is optional: If the listener is initialized on a well known URL endpoint (for example, a static IP address or well-known DNS address) then you can configure Active Peers to connect to those.</p> <p>Prior to connecting with a listener you may execute a peer discovery phase to dynamically discover peers.</p> <p>For the Active Peer this involves browsing-for and selecting the appropriate service using a zero-config protocol such as Network Service Discovery on Android or Bonjour on iOS.</p>"},{"location":"active-peer/#configure-replicator","title":"Configure Replicator","text":"<p>In this section Configure Target | Sync Mode | Retry Configuration | Authenticating the Listener | Client Authentication</p>"},{"location":"active-peer/#configure-target","title":"Configure Target","text":"<p>Initialize and define the replication configuration with local and remote database locations using the <code>ReplicatorConfiguration</code> object.</p> <p>The constructor provides the server\u2019s URL (including the port number and the name of the remote database to sync with).</p> <p>It is expected that the app will identify the IP address and URL and append the remote database name to the URL endpoint, producing for example: <code>wss://10.0.2.2:4984/travel-sample</code>.</p> <p>The URL scheme for WebSocket URLs uses <code>ws:</code> (non-TLS) or <code>wss:</code> (SSL/TLS) prefixes.</p> <p>Note</p> <p>On the Android platform, to use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>Add the database collections to sync along with the <code>CollectionConfiguration</code> for each to the <code>ReplicatorConfiguration</code>. Multiple collections can use the same configuration, or each their own as needed. A null configuration will use the default configuration values, found in <code>Defaults.Replicator</code>.</p> <p>Example 2. Add Target to Configuration</p> <pre><code>// initialize the replicator configuration\nval config = ReplicatorConfiguration(URLEndpoint(\"wss://10.0.2.2:8954/travel-sample\"))\n    .addCollections(collections)\n</code></pre> <p>Note use of the scheme prefix (<code>wss://</code> to ensure TLS encryption \u2014 strongly recommended in production \u2014 or <code>ws://</code>).</p>"},{"location":"active-peer/#sync-mode","title":"Sync Mode","text":"<p>Here we define the direction and type of replication we want to initiate.</p> <p>We use <code>ReplicatorConfiguration</code> class\u2019s <code>type</code> and <code>isContinuous</code> properties to tell the replicator:</p> <ul> <li>The type (or direction) of the replication: <code>PUSH_AND_PULL</code>; <code>PULL</code>; <code>PUSH</code></li> <li>The replication mode, that is either of:<ul> <li>Continuous \u2014 remaining active indefinitely to replicate changed documents (<code>isContinuous=true</code>).</li> <li>Ad-hoc \u2014 a one-shot replication of changed documents (<code>isContinuous=false</code>).</li> </ul> </li> </ul> <p>Example 3. Configure replicator type and mode</p> <pre><code>// Set replicator type\ntype = ReplicatorType.PUSH_AND_PULL,\n\n// Configure Sync Mode\ncontinuous = false, // default value\n</code></pre> <p>Tip</p> <p>Unless there is a solid use-case not to, always initiate a single <code>PUSH_AND_PULL</code> replication rather than identical separate <code>PUSH</code> and <code>PULL</code> replications.</p> <p>This prevents the replications generating the same checkpoint <code>docID</code> resulting in multiple conflicts.</p>"},{"location":"active-peer/#retry-configuration","title":"Retry Configuration","text":"<p>Couchbase Lite\u2019s replication retry logic assures a resilient connection.</p> <p>The replicator minimizes the chance and impact of dropped connections by maintaining a heartbeat; essentially pinging the listener at a configurable interval to ensure the connection remains alive.</p> <p>In the event it detects a transient error, the replicator will attempt to reconnect, stopping only when the connection is re-established, or the number of retries exceeds the retry limit (9 times for a single-shot replication and unlimited for a continuous replication).</p> <p>On each retry the interval between attempts is increased exponentially (exponential backoff) up to the maximum wait time limit (5 minutes).</p> <p>The REST API provides configurable control over this replication retry logic using a set of configurable properties \u2014 see Table 1.</p> <p>Table 1. Replication Retry Configuration Properties</p> Property Use cases Description <code>setHeartbeat()</code> <ul><li>Reduce to detect connection errors sooner</li><li>Align to load-balancer or proxy <code>keep-alive</code> interval \u2014 see Sync Gateway\u2019s topic Load Balancer - Keep Alive</li></ul> The interval (in seconds) between the heartbeat pulses.Default: The replicator pings the listener every 300 seconds. <code>setMaxAttempts()</code> Change this to limit or extend the number of retry attempts. The maximum number of retry attempts<ul><li>Set to zero (0) to use default values</li><li>Set to one (1) to prevent any retry attempt</li><li>The retry attempt count is reset when the replicator is able to connect and replicate</li><li>Default values are:<ul><li>Single-shot replication = 9;</li><li>Continuous replication = maximum integer value</li></ul></li><li>Negative values generate a Couchbase exception <code>InvalidArgumentException</code></li></ul> <code>setMaxAttemptWaitTime()</code> Change this to adjust the interval between retries. The maximum interval between retry attemptsWhile you can configure the maximum permitted wait time, the replicator\u2019s exponential backoff algorithm calculates each individual interval which is not configurable.<ul><li>Default value: 300 seconds (5 minutes)</li><li>Zero sets the maximum interval between retries to the default of 300 seconds</li><li>300 sets the maximum interval between retries to the default of 300 seconds</li><li>A negative value generates a Couchbase exception, <code>InvalidArgumentException</code></li></ul> <p>When necessary you can adjust any or all of those configurable values \u2014 see Example 4 for how to do this.</p> <p>Example 4. Configuring Replication Retries</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .apply {\n            //  other config params as required . .\n            heartbeat = 150\n            maxAttempts = 20\n            maxAttemptWaitTime = 600\n        }\n)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"active-peer/#authenticating-the-listener","title":"Authenticating the Listener","text":"<p>Define the credentials your app (the client) is expecting to receive from the server (listener) in order to ensure that the server is one it is prepared to interact with.</p> <p>Note that the client cannot authenticate the server if TLS is turned off. When TLS is enabled (listener\u2019s default) the client must authenticate the server. If the server cannot provide acceptable credentials then the connection will fail.</p> <p>Use <code>ReplicatorConfiguration</code> properties <code>setAcceptOnlySelfSignedServerCertificate</code> and <code>setPinnedServerCertificate</code>, to tell the replicator how to verify server-supplied TLS server certificates.</p> <ul> <li>If there is a pinned certificate, nothing else matters, the server cert must exactly match the pinned certificate.</li> <li>If there are no pinned certs and <code>setAcceptOnlySelfSignedServerCertificate</code> is <code>true</code> then any self-signed   certificate is accepted. Certificates that are not self-signed are rejected, no matter who signed them.</li> <li>If there are no pinned certificates and <code>setAcceptOnlySelfSignedServerCertificate</code> is <code>false</code> (default), the client   validates the server\u2019s certificates against the system CA certificates. The server must supply a chain of certificates   whose root is signed by one of the certificates in the system CA bundle.</li> </ul> <p>Example 5. Set Server TLS security</p> CA CertSelf-Signed CertPinned Certificate <p>Set the client to expect and accept only CA attested certificates.</p> <pre><code>// Configure Server Security\n// -- only accept CA attested certs\nacceptOnlySelfSignedServerCertificate = false,\n</code></pre> <p>This is the default. Only certificate chains with roots signed by a trusted CA are allowed. Self-signed certificates are not allowed.</p> <p>Set the client to expect and accept only self-signed certificates.</p> <pre><code>// Configure Server Authentication --\n// only accept self-signed certs\nacceptOnlySelfSignedServerCertificate = true,\n</code></pre> <p>Set this to <code>true</code> to accept any self-signed cert. Any certificates that are not self-signed are rejected.</p> <p>Set the client to expect and accept only a pinned certificate.</p> <pre><code>// Use the pinned certificate from the byte array (cert)\npinnedServerCertificate = TLSIdentity.getIdentity(\"Our Corporate Id\")\n    ?.certs?.firstOrNull()\n    ?: throw IllegalStateException(\"Cannot find corporate id\"),\n</code></pre> <p>Configure the pinned certificate using data from the byte array <code>cert</code></p>"},{"location":"active-peer/#client-authentication","title":"Client Authentication","text":"<p>Here we define the credentials that the client can present to the server if prompted to do so in order that the server can authenticate it.</p> <p>We use <code>ReplicatorConfiguration</code>'s <code>authenticator</code> property to define the authentication method to the replicator.</p>"},{"location":"active-peer/#basic-authentication","title":"Basic Authentication","text":"<p>Use the <code>BasicAuthenticator</code> to supply basic authentication credentials (username and password).</p> <p>Example 6. Basic Authentication</p> <p>This example shows basic authentication using username and password:</p> <pre><code>// Configure the credentials the\n// client will provide if prompted\nauthenticator = BasicAuthenticator(\"PRIVUSER\", \"let me in\".toCharArray())\n</code></pre>"},{"location":"active-peer/#certificate-authentication","title":"Certificate Authentication","text":"<p>Use the <code>ClientCertificateAuthenticator</code> to configure the client TLS certificates to be presented to the server, on connection. This applies only to the <code>URLEndpointListener</code>.</p> <p>Note</p> <p>The server (listener) must have <code>isTlsDisabled</code> set to <code>false</code> and have a <code>ListenerCertificateAuthenticator</code> configured, or it will never ask for this client\u2019s certificate.</p> <p>The certificate to be presented to the server will need to be signed by the root certificates or be valid based on the authentication callback set to the listener via <code>ListenerCertificateAuthenticator</code>.</p> <p>Example 7. Client Cert Authentication</p> <p>This example shows client certificate authentication using an identity from secure storage.</p> <pre><code>// Provide a client certificate to the server for authentication\nauthenticator = ClientCertificateAuthenticator(\n    TLSIdentity.getIdentity(\"clientId\")\n        ?: throw IllegalStateException(\"Cannot find client id\")\n)\n</code></pre> <ol> <li>Get an identity from secure storage and create a <code>TLSIdentity</code> object</li> <li>Set the authenticator to <code>ClientCertificateAuthenticator</code> and configure it to use the retrieved identity</li> </ol>"},{"location":"active-peer/#initialize-replicator","title":"Initialize Replicator","text":"<p>Use the <code>Replicator</code> class\u2019s <code>Replicator(ReplicatorConfiguration)</code> constructor, to initialize the replicator with the configuration you have defined. You can, optionally, add a change listener (see Monitor Sync) before starting the replicator running using <code>start()</code>.</p> <p>Example 8. Initialize and run replicator</p> <pre><code>// Create replicator\n// Consider holding a reference somewhere\n// to prevent the Replicator from being GCed\nval repl = Replicator(\n    // initialize the replicator configuration\n    ReplicatorConfiguration(URLEndpoint(\"wss://listener.com:8954\"))\n        .addCollections(collections)\n        .apply {\n            // Set replicator type\n            type = ReplicatorType.PUSH_AND_PULL\n\n            // Configure Sync Mode\n            isContinuous = false // default value\n\n            // set auto-purge behavior\n            // (here we override default)\n            isAutoPurgeEnabled = false\n\n            // Configure Server Authentication --\n            // only accept self-signed certs\n            isAcceptOnlySelfSignedServerCertificate = true\n\n            // Configure the credentials the\n            // client will provide if prompted\n            authenticator = BasicAuthenticator(\"PRIVUSER\", \"let me in\".toCharArray())\n        }\n)\n\n// Start replicator\nrepl.start(false)\n\nthis.replicator = repl\nthis.token = token\n</code></pre> <ol> <li>Initialize the replicator with the configuration</li> <li>Start the replicator</li> </ol>"},{"location":"active-peer/#monitor-sync","title":"Monitor Sync","text":"<p>In this section Change Listeners | Replicator Status | Documents Pending Push </p> <p>You can monitor a replication\u2019s status by using a combination of Change Listeners and the <code>replicator.status.activityLevel</code> property \u2014 see<code>activityLevel</code>. This enables you to know, for example, when the replication is actively transferring data and when it has stopped.</p>"},{"location":"active-peer/#change-listeners","title":"Change Listeners","text":"<p>Use this to monitor changes and to inform on sync progress; this is an optional step. You can add a replicator change listener at any point; it will report changes from the point it is registered.</p> <p>Tip</p> <p>Don\u2019t forget to save the token so you can remove the listener later</p> <p>Use the <code>Replicator</code> class to add a change listener as a callback with <code>Replicator.addChangeListener()</code> \u2014 see Example 9 . You will then be asynchronously notified of state changes.</p> <p>You can remove a change listener with <code>removeChangeListener(ListenerToken)</code>.</p>"},{"location":"active-peer/#using-kotlin-flows","title":"Using Kotlin Flows","text":"<p>Kotlin developers can take advantage of <code>Flow</code>s to monitor replicators.</p> <pre><code>fun replChangeFlowExample(repl: Replicator): Flow&lt;ReplicatorActivityLevel&gt; {\n    return repl.replicatorChangesFlow()\n        .map { it.status.activityLevel }\n}\n</code></pre>"},{"location":"active-peer/#replicator-status","title":"Replicator Status","text":"<p>You can use the <code>ReplicatorStatus</code> class to check the replicator status. That is, whether it is actively transferring data or if it has stopped \u2014 see Example 9.</p> <p>The returned <code>ReplicatorStatus</code> structure comprises:</p> <ul> <li><code>activityLevel</code> \u2014 <code>STOPPED</code>, <code>OFFLINE</code>,   <code>CONNECTING</code>, <code>IDLE</code>, or <code>BUSY</code> \u2014 see states described in Table 2</li> <li><code>progress</code><ul> <li><code>completed</code> \u2014 the total number of changes completed</li> <li><code>total</code> \u2014 the total number of changes to be processed</li> </ul> </li> <li><code>error</code> \u2014 the current error, if any</li> </ul> <p>Example 9. Monitor replication</p> Adding a Change ListenerUsing replicator.status <pre><code>val token = repl.addChangeListener { change -&gt;\n    val err: CouchbaseLiteException? = change.status.error\n    if (err != null) {\n        println(\"Error code :: ${err.code}\\n$err\")\n    }\n}\n</code></pre> <pre><code>repl.status.let {\n    val progress = it.progress\n    println(\n        \"The Replicator is ${\n            it.activityLevel\n        } and has processed ${\n            progress.completed\n        } of ${progress.total} changes\"\n    )\n}\n</code></pre>"},{"location":"active-peer/#replication-states","title":"Replication States","text":"<p>Table 2 shows the different states, or activity levels, reported in the API; and the meaning of each.</p> <p>Table 2. Replicator activity levels</p> State Meaning <code>STOPPED</code> The replication is finished or hit a fatal error. <code>OFFLINE</code> The replicator is offline as the remote host is unreachable. <code>CONNECTING</code> The replicator is connecting to the remote host. <code>IDLE</code> The replication caught up with all the changes available from the server. The <code>IDLE</code> state is only used in continuous replications. <code>BUSY</code> The replication is actively transferring data. <p>Note</p> <p>The replication change object also has properties to track the progress (<code>change.status.completed</code> and <code>change.status.total</code>). Since the replication occurs in batches the total count can vary through the course of a replication.</p>"},{"location":"active-peer/#replication-status-and-app-life-cycle","title":"Replication Status and App Life Cycle","text":""},{"location":"active-peer/#ios","title":"iOS","text":"<p>The following diagram describes the status changes when the application starts a replication, and when the application is being backgrounded or foregrounded by the OS. It applies to iOS only.</p> <p></p> <p>Additionally, on iOS, an app already in the background may be terminated. In this case, the <code>Database</code> and <code>Replicator</code> instances will be <code>null</code> when the app returns to the foreground. Therefore, as preventive measure, it is recommended to do a <code>null</code> check when the app enters the foreground, and to re-initialize the database and replicator if any of those are <code>null</code>.</p> <p>On other platforms, Couchbase Lite doesn\u2019t react to OS backgrounding or foregrounding events and replication(s) will continue running as long as the remote system does not terminate the connection and the app does not terminate. It is generally recommended to stop replications before going into the background otherwise socket connections may be closed by the OS and this may interfere with the replication process.</p>"},{"location":"active-peer/#other-platforms","title":"Other Platforms","text":"<p>Couchbase Lite replications will continue running until the app terminates, unless the remote system, or the application, terminates the connection.</p> <p>Note</p> <p>Recall that the Android OS may kill an application without warning. You should explicitly stop replication processes when they are no longer useful (for example, when the app is in the background and the replication is <code>IDLE</code>) to avoid socket connections being closed by the OS, which may interfere with the replication process.</p>"},{"location":"active-peer/#documents-pending-push","title":"Documents Pending Push","text":"<p>Tip</p> <p><code>Replicator.isDocumentPending()</code> is quicker and more efficient. Use it in preference to returning a list of pending document IDs, where possible.</p> <p>You can check whether documents are waiting to be pushed in any forthcoming sync by using either of the following API methods:</p> <ul> <li>Use the <code>Replicator.getPendingDocumentIds()</code> method, which returns a list of document IDs   that have local changes, but which have not yet been pushed to the server.   This can be very useful in tracking the progress of a push sync, enabling the app to provide a visual indicator to the   end user on its status, or decide when it is safe to exit.</li> <li>Use the <code>Replicator.isDocumentPending()</code> method   to quickly check whether an individual document is pending a push.</li> </ul> <p>Example 10. Use Pending Document ID API</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .setType(ReplicatorType.PUSH)\n)\n\nval pendingDocs = repl.getPendingDocumentIds(collection)\n\n// iterate and report on previously\n// retrieved pending docIds 'list'\nif (pendingDocs.isNotEmpty()) {\n    println(\"There are ${pendingDocs.size} documents pending\")\n\n    val firstDoc = pendingDocs.first()\n    repl.addChangeListener { change -&gt;\n        println(\"Replicator activity level is ${change.status.activityLevel}\")\n        try {\n            if (!repl.isDocumentPending(firstDoc)) {\n                println(\"Doc ID $firstDoc has been pushed\")\n            }\n        } catch (err: CouchbaseLiteException) {\n            println(\"Failed getting pending docs\\n$err\")\n        }\n    }\n\n    repl.start()\n    this.replicator = repl\n}\n</code></pre> <ol> <li><code>Replicator.getPendingDocumentIds()</code>    returns a list of the document IDs for all documents waiting to be pushed. This is a snapshot and may have changed by    the time the response is received and processed.</li> <li><code>Replicator.isDocumentPending()</code> returns    <code>true</code> if the document is waiting to be pushed, and <code>false</code> otherwise.</li> </ol>"},{"location":"active-peer/#stop-sync","title":"Stop Sync","text":"<p>Stopping a replication is straightforward. It is done using <code>stop()</code>. This initiates an asynchronous operation and so is not necessarily immediate. Your app should account for this potential delay before attempting any subsequent operations.</p> <p>You can find further information on database operations in Databases.</p> <p>Example 11. Stop replicator</p> <pre><code>// Stop replication.\nrepl.stop()\n</code></pre> <p>Here we initiate the stopping of the replication using the <code>stop()</code> method. It will stop any active change listener  once the replication is stopped.</p>"},{"location":"active-peer/#conflict-resolution","title":"Conflict Resolution","text":"<p>Unless you specify otherwise, Couchbase Lite\u2019s default conflict resolution policy is applied \u2014 see Handling Data Conflicts.</p> <p>To use a different policy, specify a conflict resolver using <code>conflictResolver</code> as shown in Example 12.</p> <p>For more complex solutions you can provide a custom conflict resolver - see Handling Data Conflicts.</p> <p>Example 12. Using conflict resolvers</p> Local WinsRemote WinsMerge <pre><code>val localWinsResolver: ConflictResolver = { conflict -&gt;\n    conflict.localDocument\n}\nconfig.conflictResolver = localWinsResolver\n</code></pre> <pre><code>val remoteWinsResolver: ConflictResolver = { conflict -&gt;\n    conflict.remoteDocument\n}\nconfig.conflictResolver = remoteWinsResolver\n</code></pre> <pre><code>val mergeConflictResolver: ConflictResolver = { conflict -&gt;\n    val localDoc = conflict.localDocument?.toMap()?.toMutableMap()\n    val remoteDoc = conflict.remoteDocument?.toMap()?.toMutableMap()\n\n    val merge: MutableMap&lt;String, Any?&gt;?\n    if (localDoc == null) {\n        merge = remoteDoc\n    } else {\n        merge = localDoc\n        if (remoteDoc != null) {\n            merge.putAll(remoteDoc)\n        }\n    }\n\n    if (merge == null) {\n        MutableDocument(conflict.documentId)\n    } else {\n        MutableDocument(conflict.documentId, merge)\n    }\n}\nconfig.conflictResolver = mergeConflictResolver\n</code></pre> <p>Just as a replicator may observe a conflict \u2014 when updating a document that has changed both in the local database and in a remote database \u2014 any attempt to save a document may also observe a conflict, if a replication has taken place since the local app retrieved the document from the database. To address that possibility, a version of the <code>Database.save()</code> method also takes a conflict resolver as shown in Example 13.</p> <p>The following code snippet shows an example of merging properties from the existing document (<code>curDoc</code>) into the one being saved (<code>newDoc</code>). In the event of conflicting keys, it will pick the key value from <code>newDoc</code>.</p> <p>Example 13. Merging document properties</p> <pre><code>val mutableDocument = database.getDocument(\"xyz\")?.toMutable() ?: return\nmutableDocument.setString(\"name\", \"apples\")\ndatabase.save(mutableDocument) { newDoc, curDoc -&gt;\n    if (curDoc == null) {\n        return@save false\n    }\n    val dataMap: MutableMap&lt;String, Any?&gt; = curDoc.toMap().toMutableMap()\n    dataMap.putAll(newDoc.toMap())\n    newDoc.setData(dataMap)\n    true\n}\n</code></pre> <p>For more on replicator conflict resolution see Handling Data Conflicts.</p>"},{"location":"active-peer/#delta-sync","title":"Delta Sync","text":"<p>If delta sync is enabled on the listener, then replication will use delta sync.</p>"},{"location":"blobs/","title":"Blobs","text":"<p>Couchbase Lite database data model concepts \u2014 blobs</p>"},{"location":"blobs/#introduction","title":"Introduction","text":"<p>Couchbase Lite uses blobs to store the contents of images, other media files and similar format files as binary objects.</p> <p>The blob itself is not stored in the document. It is held in a separate content-addressable store indexed from the document and retrieved only on-demand.</p> <p>When a document is synchronized, the Couchbase Lite replicator adds an <code>_attachments</code> dictionary to the document\u2019s properties if it contains a blob \u2014 see Figure 1.</p>"},{"location":"blobs/#blob-objects","title":"Blob Objects","text":"<p>The blob as an object appears in a document as dictionary property \u2014 see, for example avatar in Figure 1.</p> <p>Other properties include <code>length</code> (the length in bytes), and optionally <code>content_type</code> (typically, its MIME type).</p> <p>The blob\u2019s data (an image, audio or video content) is not stored in the document, but in a separate content-addressable store, indexed by the digest property \u2014 see Using Blobs.</p>"},{"location":"blobs/#constraints","title":"Constraints","text":"<ul> <li>Couchbase Lite   Blobs can be arbitrarily large. They are only read on demand, not when you load a document.</li> <li>Sync Gateway   The maximum content size is 20 MB per blob. If a document\u2019s blob is over 20 MB, the document will be replicated but   not the blob.</li> </ul>"},{"location":"blobs/#using-blobs","title":"Using Blobs","text":"<p>The Blob API lets you access the blob\u2019s data content as in-memory data (a <code>ByteArray</code>) or as a <code>Source</code> input stream.</p> <p>The code in Example 1 shows how you might add a blob to a document and save it to the database. Here we use <code>avatar</code> as the property key and a jpeg file as the blob data.</p> <p>Example 1. Working with blobs</p> <pre><code>// kotlinx-io multiplatform file system APIs are still in development\n// However, platform-specific implementations can be created in the meantime\nexpect fun getAsset(file: String): Source?\n\nval mDoc = MutableDocument()\n\ngetAsset(\"avatar.jpg\")?.use { source -&gt;\n  mDoc.setBlob(\"avatar\", Blob(\"image/jpeg\", source))\n  collection.save(mDoc)\n}\n\nval doc = collection.getDocument(mDoc.id)\nval bytes = doc?.getBlob(\"avatar\")?.content\n</code></pre> <ol> <li>Prepare a document to use for the example.</li> <li>Create the blob using the retrieved image and set <code>image/jpeg</code> as the blob MIME type.</li> <li>Add the blob to a document, using <code>avatar</code> as the property key.</li> <li>Saving the document generates a random access key for each blob stored in <code>digest</code> a SHA-1 encrypted property \u2014 see    Figure 1.</li> <li>Use the <code>avatar</code> key to retrieve the blob object later. Note, this is the identity of the blob assigned by us; the    replication auto-generates a blob for attachments and assigns its own name to it (for example, <code>blob_1</code>) \u2014 see    Figure 1. The <code>digest</code> key will be the same as generated when we saved the blob document.</li> </ol>"},{"location":"blobs/#syncing","title":"Syncing","text":"<p>When a document containing a blob object is synchronized, the Couchbase Lite replicator generates an <code>_attachments</code> dictionary with an auto-generated name for each blob attachment. This is different to the <code>avatar</code> key and is used internally to access the blob content.</p> <p>If you view a sync\u2019ed blob document in Couchbase Server Admin Console, you will see something similar to Figure 1, which shows the document with its generated <code>_attachments</code> dictionary, including the <code>digest</code>.</p> <p> </p> Figure 1. Sample Blob Document"},{"location":"changelog/","title":"Change Log","text":""},{"location":"changelog/#324-120","title":"3.2.4-1.2.0","text":"<p>24 Oct 2025</p> <ul> <li>Vector Search (#57) \u2014 Couchbase Lite 3.2 API (#54)<ul> <li>Android SDK</li> <li>Java SDK</li> <li>Objective-C SDK</li> <li>C SDK</li> </ul> </li> <li>Support 16 KB page sizes (#47)</li> <li>New log sink API (#55)</li> <li>Paging extensions now use AndroidX Paging directly (#52)</li> <li>Predictive model registration now available on Linux and Mingw platforms (#57)</li> <li>Migrate kotlinx-datetime to 0.7.1 (#48)<ul> <li><code>kotlinx.datetime.Instant</code> is now <code>kotlin.time.Instant</code> in the Kotbase API</li> <li>kotlinx-datetime is no longer an API dependency</li> </ul> </li> <li>Update other dependencies</li> <li>Fix some memory allocation bugs on Linux &amp; Mingw platforms (#58, #60)</li> </ul>"},{"location":"changelog/#3111-112","title":"3.1.11-1.1.2","text":"<p>1 Sep 2025</p> <ul> <li>Update Couchbase Lite dependency to 3.1.11 (JVM &amp; Android) &amp; 3.1.10 (Objective-C &amp; C) (#50)<ul> <li>Android SDK</li> <li>Java SDK</li> <li>Objective-C SDK</li> <li>C SDK</li> </ul> </li> <li>Add full sync API to database configuration (#49)</li> <li>Update to Kotlin 2.2.10</li> <li>Use AtomicFu compiler plugin (#44)</li> <li>Update dependencies</li> </ul>"},{"location":"changelog/#319-111","title":"3.1.9-1.1.1","text":"<p>28 Oct 2024</p> <ul> <li>Update Couchbase Lite dependency to 3.1.9 (#29)<ul> <li>Android SDK</li> <li>Java SDK</li> <li>Objective-C SDK</li> <li>C SDK</li> </ul> </li> <li>Update dependencies (#30)</li> </ul>"},{"location":"changelog/#313-110","title":"3.1.3-1.1.0","text":"<p>1 Feb 2023</p> <ul> <li>Scopes and Collections \u2014 Couchbase Lite 3.1 API (#11)<ul> <li>Android SDK v3.1.3</li> <li>Java SDK v3.1.3</li> <li>Objective-C SDK v3.1.4</li> <li>C SDK v3.1.3</li> </ul> </li> <li>Update to Kotlin 1.9.22 (8546e4b)</li> <li>Handle empty log domain set (00db837)</li> <li>Source-incompatible change: Convert <code>@Throws</code> getter functions to properties (#12)<ul> <li><code>Database.getIndexes()</code> -&gt; <code>Database.indexes</code></li> <li><code>Replicator.getPendingDocumentIds()</code> -&gt; <code>Replicator.pendingDocumentIds</code></li> </ul> </li> <li>Make <code>Expression</code>, <code>as</code>, and <code>from</code> query builder functions <code>infix</code> (#14)</li> </ul>"},{"location":"changelog/#ktx-extensions","title":"KTX extensions:","text":"<ul> <li>Add <code>Expression</code> math operator functions (148399d)</li> <li>Add <code>fetchContext</code> to <code>documentFlow</code>, default to <code>Dispatchers.IO</code> (2abe61a)</li> <li>Add <code>mutableArrayOf</code>, <code>mutableDictOf</code>, and <code>mutableDocOf</code>, collection and doc creation functions (#13)</li> <li><code>selectDistinct</code>, <code>from</code>, <code>as</code>, and <code>groupBy</code> convenience query builder functions (#14)</li> </ul>"},{"location":"changelog/#3015-101","title":"3.0.15-1.0.1","text":"<p>15 Dec 2023</p> <ul> <li>Make <code>Replicator</code> <code>AutoCloseable</code> (#2)</li> <li>Avoid memory leaks with <code>memScoped</code> <code>toFLString()</code> (#3)</li> <li>Update Couchbase Lite to 3.0.15 (#4):<ul> <li>Android SDK v3.0.15</li> <li>Java SDK v3.0.15</li> <li>Objective-C SDK v3.0.15</li> <li>C SDK v3.0.15</li> </ul> </li> <li>Update to Kotlin 1.9.21 (#5)</li> <li>K2 compiler compatibility (#7)</li> <li>Update kotlinx-serialization, kotlinx-datetime, and kotlinx-atomicfu (#8)</li> <li>Use default hierarchy template source set names (#9)</li> </ul>"},{"location":"changelog/#3012-100","title":"3.0.12-1.0.0","text":"<p>1 Nov 2023</p> <p>Initial public release</p> <p>Using Couchbase Lite:</p> <ul> <li>Android SDK v3.0.12</li> <li>Java SDK v3.0.12</li> <li>Objective-C SDK v3.0.12</li> <li>C SDK v3.0.12</li> </ul>"},{"location":"community/","title":"Community","text":"<p> Join the <code>#couchbase</code> channel of the Kotlin Slack.</p> <p> Browse the Couchbase Community Hub.</p> <p> Chat in the Couchbase Discord.</p> <p> Post in the Couchbase Forums.</p>"},{"location":"databases/","title":"Databases","text":"<p>Working with Couchbase Lite databases</p>"},{"location":"databases/#database-concepts","title":"Database Concepts","text":"<p>Databases created on Couchbase Lite can share the same hierarchical structure as Couchbase Server or Capella databases. This makes it easier to sync data between mobile applications and applications built using Couchbase Server or Capella.</p> <p> </p> Figure 1. Couchbase Lite Database Hierarchy <p>Although the terminology is different, the structure can be mapped to relational database terms:</p> <p>Table 1. Relational Database \u2192 Couchbase</p> Relational database Couchbase Database Database Schema Scope Table Collection <p>This structure gives you plenty of choices when it comes to partitioning your data. The most basic structure is to use the single default scope with a single default collection; or you could opt for a structure that allows you to split your collections into logical scopes.</p> <p> </p> Figure 2. Couchbase Lite Examples <p>Storing local configuration</p> <p>You may not need to sync all the data related for a particular application. You can set up a scope that syncs data, and a second scope that doesn\u2019t.</p> <p>One reason for doing this is to store local configuration data (such as the preferred screen orientation or keyboard layout). Since this information only relates to a particular device, there is no need to sync it:</p> <p> local data scope Contains information pertaining to the device. syncing data scope Contains information pertaining to the user, which can be synced back to the cloud for use on the web or another device. </p>"},{"location":"databases/#create-or-open-database","title":"Create or Open Database","text":"<p>You can create a new database and-or open an existing database, using the <code>Database</code> class. Just pass in a database name and optionally a <code>DatabaseConfiguration</code>  \u2014 see Example 1.</p> <p>Things to watch for include:</p> <ul> <li>If the named database does not exist in the specified, or default, location then a new one is created</li> <li>The database is created in a default location unless you specify a directory for it \u2014 see <code>DatabaseConfiguration</code> and <code>DatabaseConfiguration.setDirectory()</code></li> </ul> <p>Tip</p> <p>Best Practice is to always specify the path to the database explicitly.</p> <p>Typically, the default location is the application sandbox or current working directory.</p> <p>See also Finding a Database File.</p> <p>Example 1. Open or create a database</p> <pre><code>val database = Database(\n    \"my-db\",\n    DatabaseConfiguration()\n        .setDirectory(\"path/to/database\")\n)\n</code></pre> <p>Tip</p> <p><code>\"path/to/database\"</code> might be a platform-specific location. Use <code>expect</code>/<code>actual</code> or dependency injection to provide a platform-specific database path.</p>"},{"location":"databases/#close-database","title":"Close Database","text":"<p>You are advised to incorporate the closing of all open databases into your application workflow.</p> <p>Closing a database is simple, just use <code>Database.close()</code> \u2014 see Example 2. This also closes active replications, listeners and-or live queries connected to the database.</p> <p>Note</p> <p>Closing a database soon after starting a replication involving it can cause an exception as the asynchronous replicator (start) may not yet be connected.</p> <p>Example 2. Close a Database</p> <pre><code>database.close()\n</code></pre>"},{"location":"databases/#database-encryption","title":"Database Encryption","text":"<p>This is an Enterprise Edition feature.</p> <p>Kotbase includes the ability to encrypt Couchbase Lite databases. This allows mobile applications to secure the data at rest, when it is being stored on the device. The algorithm used to encrypt the database is 256-bit AES.</p>"},{"location":"databases/#enabling","title":"Enabling","text":"<p>To enable encryption, use <code>DatabaseConfiguration.setEncryptionKey()</code> to set the encryption key of your choice. Provide this encryption key every time the database is opened \u2014 see Example 3.</p> <p>Example 3. Configure Database Encryption</p> <pre><code>val db = Database(\n    \"my-db\",\n    DatabaseConfiguration()\n        .setEncryptionKey(EncryptionKey(\"PASSWORD\"))\n)\n</code></pre>"},{"location":"databases/#persisting","title":"Persisting","text":"<p>Couchbase Lite does not persist the key. It is the application\u2019s responsibility to manage the key and store it in a platform specific secure store such as Apple\u2019s Keychain or Android\u2019s Keystore.</p>"},{"location":"databases/#opening","title":"Opening","text":"<p>An encrypted database can only be opened with the same language SDK that was used to encrypt it in the first place. So a database encrypted with Kotbase on Android (which uses the Couchbase Lite Android SDK) and then exported, is readable only by Kotbase on Android or the Couchbase Lite Android SDK.</p>"},{"location":"databases/#changing","title":"Changing","text":"<p>To change an existing encryption key, open the database using its existing encryption-key and use <code>Database.changeEncryptionKey()</code> to set the required new encryption-key value.</p>"},{"location":"databases/#removing","title":"Removing","text":"<p>To remove encryption, open the database using its existing encryption-key and use <code>Database.changeEncryptionKey()</code> with a null value as the encryption key.</p>"},{"location":"databases/#finding-a-database-file","title":"Finding a Database File","text":""},{"location":"databases/#android","title":"Android","text":"<p>When the application is running on the Android emulator, you can locate the application\u2019s data folder and access the database file by using the <code>adb</code> CLI tools. For example, to list the different databases on the emulator, you can run the following commands.</p> <p>Example 4. List files</p> <pre><code>$ adb shell\n$ su\n$ cd /data/data/{APPLICATION_ID}/files\n$ ls\n</code></pre> <p>The <code>adb pull</code> command can be used to pull a specific database to your host machine.</p> <p>Example 5. Pull using adb command</p> <pre><code>$ adb root\n$ adb pull /data/data/{APPLICATION_ID}/files/{DATABASE_NAME}.cblite2 .\n</code></pre>"},{"location":"databases/#ios","title":"iOS","text":"<p>When the application is running on the iOS simulator, you can locate the application\u2019s sandbox directory using the OpenSim utility.</p>"},{"location":"databases/#database-maintenance","title":"Database Maintenance","text":"<p>From time to time it may be necessary to perform certain maintenance activities on your database, for example to compact the database file, removing unused documents and blobs no longer referenced by any documents.</p> <p>Couchbase Lite\u2019s API provides the <code>Database.performMaintenance()</code> method. The available maintenance operations, including compact are as shown in the enum <code>MaintenanceType</code> to accomplish this.</p> <p>This is a resource intensive operation and is not performed automatically. It should be run on-demand using the API. If in doubt, consult Couchbase support.</p>"},{"location":"databases/#command-line-tool","title":"Command Line Tool","text":"<p><code>cblite</code> is a command-line tool for inspecting and querying Couchbase Lite databases.</p> <p>You can download and build it from the couchbaselabs GitHub repository.</p>"},{"location":"databases/#troubleshooting","title":"Troubleshooting","text":"<p>You should use console logs as your first source of diagnostic information. If the information in the default logging level is insufficient you can focus it on database errors and generate more verbose messages \u2014 see Example 6.</p> <p>For more on using Couchbase logs \u2014 see Using Logs.</p> <p>Example 6. Increase Level of Database Log Messages</p> <pre><code>LogSinks.console = ConsoleLogSink(LogLevel.INFO, LogDomain.DATABASE)\n</code></pre>"},{"location":"differences/","title":"Differences from Java SDK","text":"<p>Kotbase's API aligns with the Couchbase Lite Java and Android KTX SDKs. Migrating existing Kotlin code can be as straightforward as changing the import package from <code>com.couchbase.lite</code> to <code>kotbase</code>, with some exceptions:</p> <ul> <li>Java callback functional interfaces are implemented as Kotlin function types.</li> <li><code>File</code>, <code>URL</code>, and <code>URI</code> APIs are represented as strings.</li> <li><code>Date</code> APIs use Kotlin's <code>Instant</code>.</li> <li><code>InputStream</code> APIs use kotlinx-io's <code>Source</code>.</li> <li><code>Executor</code> APIs use Kotlin's <code>CoroutineContext</code>.</li> <li>Certificate APIs are available as raw <code>ByteArray</code>s or in platform-specific code.</li> <li>There's no need to explicitly call <code>CouchbaseLite.init()</code>. Initialization functions can still be called with custom   parameters in JVM and Android platform code.</li> <li>Efforts have been made to detect and throw Kotlin exceptions for common error conditions, but <code>NSError</code> may still leak   through on Apple platforms. Please report any occurrences that may   deserve addressing.</li> <li>Some deprecated APIs are omitted.</li> <li>While not available in the Java SDK, as Java doesn't support operator overloading, <code>Fragment</code> subscript APIs are available in Kotbase, similar to Swift, Objective-C, and .NET.</li> <li>Configuration factory APIs from the Android KTX SDK have been deprecated in favor of using constructors directly,   which support Kotlin named arguments themselves.</li> </ul>"},{"location":"documents/","title":"Documents","text":"<p>Couchbase Lite concepts \u2014 Data model \u2014 Documents</p>"},{"location":"documents/#overview","title":"Overview","text":""},{"location":"documents/#document-structure","title":"Document Structure","text":"<p>In Couchbase Lite the term 'document' refers to an entry in the database. You can compare it to a record, or a row in a table.</p> <p>Each document has an ID or unique identifier. This ID is similar to a primary key in other databases.</p> <p>You can specify the ID programmatically. If you omit it, it will be automatically generated as a UUID.</p> <p>Note</p> <p>Couchbase documents are assigned to a Collection. The ID of a document must be unique within the Collection it is written to. You cannot change it after you have written the document.</p> <p>The document also has a value which contains the actual application data. This value is stored as a dictionary of key-value (k-v) pairs. The values can be made of up several different Data Types such as numbers, strings, arrays, and nested objects.</p>"},{"location":"documents/#data-encoding","title":"Data Encoding","text":"<p>The document body is stored in an internal, efficient, binary form called Fleece. This internal form can be easily converted into a manageable native dictionary format for manipulation in applications.</p> <p>Fleece data is stored in the smallest format that will hold the value whilst maintaining the integrity of the value.</p>"},{"location":"documents/#data-types","title":"Data Types","text":"<p>The <code>Document</code> class offers a set of property accessors for various scalar types, such as:</p> <ul> <li>Boolean</li> <li>Date</li> <li>Double</li> <li>Float</li> <li>Int</li> <li>Long</li> <li>String</li> </ul> <p>These accessors take care of converting to/from JSON encoding, and make sure you get the type you expect.</p> <p>In addition to these basic data types Couchbase Lite provides for the following:</p> <ul> <li>Dictionary represents a read-only key-value pair collection</li> <li>MutableDictionary represents a writeable key-value pair collection</li> <li>Array represents a readonly ordered collection of objects</li> <li>MutableArray represents a writeable collection of objects</li> <li>Blob represents an arbitrary piece of binary data</li> </ul>"},{"location":"documents/#json","title":"JSON","text":"<p>Couchbase Lite also provides for the direct handling of JSON data implemented in most cases by the provision of a <code>toJSON()</code> method on appropriate API classes (for example, on <code>MutableDocument</code>, <code>Dictionary</code>, <code>Blob</code>, and <code>Array</code>) \u2014 see Working with JSON Data.</p>"},{"location":"documents/#constructing-a-document","title":"Constructing a Document","text":"<p>An individual document often represents a single instance of an object in application code.</p> <p>You can consider a document as the equivalent of a 'row' in a relational table, with each of the document\u2019s attributes being equivalent to a 'column'.</p> <p>Documents can contain nested structures. This allows developers to express many-to-many relationships without requiring a reference or join table, and is naturally expressive of hierarchical data.</p> <p>Most apps will work with one or more documents, persisting them to a local database and optionally syncing them, either centrally or to the cloud.</p> <p>In this section we provide an example of how you might create a <code>hotel</code> document, which provides basic contact details and price data.</p> Data Model<pre><code>hotel: {\n  type: string (value = `hotel`)\n  name: string\n  address: dictionary {\n    street: string\n    city: string\n    state: string\n    country: string\n    code: string\n  }\n  phones: array\n  rate: float\n}\n</code></pre>"},{"location":"documents/#open-a-database","title":"Open a Database","text":"<p>First open your database. If the database does not already exist, Couchbase Lite will create it for you.</p> <p>Couchbase documents are assigned to a Collection. All the CRUD examples in this document operate on a <code>collection</code> object.</p> <pre><code>// Get the database (and create it if it doesn\u2019t exist).\nval config = DatabaseConfiguration()\nconfig.directory = \"path/to/db\"\nval database = Database(\"getting-started\", config)\nval collection = database.getCollection(\"myCollection\")\n    ?: throw IllegalStateException(\"collection not found\")\n</code></pre> <p>See Databases for more information</p>"},{"location":"documents/#create-a-document","title":"Create a Document","text":"<p>Now create a new document to hold your application\u2019s data.</p> <p>Use the mutable form, so that you can add data to the document.</p> <pre><code>// Create your new document\nval mutableDoc = MutableDocument()\n</code></pre> <p>For more on using Documents, see Document Initializers and Mutability.</p>"},{"location":"documents/#create-a-dictionary","title":"Create a Dictionary","text":"<p>Now create a mutable dictionary (<code>address</code>).</p> <p>Each element of the dictionary value will be directly accessible via its own key.</p> <pre><code>// Create and populate mutable dictionary\n// Create a new mutable dictionary and populate some keys/values\nval address = MutableDictionary()\naddress.setString(\"street\", \"1 Main st.\")\naddress.setString(\"city\", \"San Francisco\")\naddress.setString(\"state\", \"CA\")\naddress.setString(\"country\", \"USA\")\naddress.setString(\"code\", \"90210\")\n</code></pre> <p>Tip</p> <p>The Kotbase KTX extensions provide an idiomatic <code>MutableDictionary</code> creation function:</p> <pre><code>val address = mutableDictOf(\n    \"street\" to \"1 Main st.\",\n    \"city\" to \"San Francisco\",\n    \"state\" to \"CA\",\n    \"country\" to \"USA\",\n    \"code\" to \"90210\"\n)\n</code></pre> <p>Learn more about Using Dictionaries.</p>"},{"location":"documents/#create-an-array","title":"Create an Array","text":"<p>Since the hotel may have multiple contact numbers, provide a field (<code>phones</code>) as a mutable array.</p> <pre><code>// Create and populate mutable array\nval phones = MutableArray()\nphones.addString(\"650-000-0000\")\nphones.addString(\"650-000-0001\")\n</code></pre> <p>Tip</p> <p>The Kotbase KTX extensions provide an idiomatic <code>MutableArray</code> creation function:</p> <pre><code>val phones = mutableArrayOf(\n    \"650-000-0000\",\n    \"650-000-0001\"\n)\n</code></pre> <p>Learn more about Using Arrays.</p>"},{"location":"documents/#populate-a-document","title":"Populate a Document","text":"<p>Now add your data to the mutable document created earlier. Each data item is stored as a key-value pair.</p> <pre><code>// Initialize and populate the document\n\n// Add document type to document properties \nmutableDoc.setString(\"type\", \"hotel\")\n\n// Add hotel name string to document properties \nmutableDoc.setString(\"name\", \"Hotel Java Mo\")\n\n// Add float to document properties \nmutableDoc.setFloat(\"room_rate\", 121.75f)\n\n// Add dictionary to document's properties \nmutableDoc.setDictionary(\"address\", address)\n\n// Add array to document's properties \nmutableDoc.setArray(\"phones\", phones)\n</code></pre> <p>Note</p> <p>Couchbase recommends using a type attribute to define each logical document type.</p>"},{"location":"documents/#save-a-document","title":"Save a Document","text":"<p>Now persist the populated document to your Couchbase Lite database. This will auto-generate the document id.</p> <pre><code>// Save the document changes \ncollection.save(mutableDoc)\n</code></pre>"},{"location":"documents/#close-the-database","title":"Close the Database","text":"<p>With your document saved, you can now close our Couchbase Lite database.</p> <pre><code>// Close the database \ndatabase.close()\n</code></pre>"},{"location":"documents/#working-with-data","title":"Working with Data","text":""},{"location":"documents/#checking-a-documents-properties","title":"Checking a Document\u2019s Properties","text":"<p>To check whether a given property exists in the document, use the <code>Document.contains(key: String)</code> method.</p> <p>If you try to access a property which doesn\u2019t exist in the document, the call will return the default value for that getter method (0 for <code>Document.getInt()</code>, 0.0 for <code>Document.getFloat()</code>, etc.).</p>"},{"location":"documents/#date-accessors","title":"Date accessors","text":"<p>Couchbase Lite offers Date accessors as a convenience. Dates are a common data type, but JSON doesn\u2019t natively support them, so the convention is to store them as strings in ISO-8601 format.</p> <p>Example 1. Date Getter</p> <p>This example sets the date on the <code>createdAt</code> property and reads it back using the <code>Document.getDate()</code> accessor method.</p> <pre><code>doc.setValue(\"createdAt\", Clock.System.now())\nval date = doc.getDate(\"createdAt\")\n</code></pre>"},{"location":"documents/#using-dictionaries","title":"Using Dictionaries","text":"<p>API References</p> <ul> <li>Dictionary</li> <li>MutableDictionary</li> </ul> <p>Example 2. Read Only</p> <pre><code>// NOTE: No error handling, for brevity (see getting started)\nval document = collection.getDocument(\"doc1\")\n\n// Getting a dictionary from the document's properties\nval dict = document?.getDictionary(\"address\")\n\n// Access a value with a key from the dictionary\nval street = dict?.getString(\"street\")\n\n// Iterate dictionary\ndict?.forEach { key -&gt;\n    println(\"Key $key = ${dict.getValue(key)}\")\n}\n\n// Create a mutable copy\nval mutableDict = dict?.toMutable()\n</code></pre> <p>Example 3. Mutable</p> <pre><code>// NOTE: No error handling, for brevity (see getting started)\n\n// Create a new mutable dictionary and populate some keys/values\nval mutableDict = MutableDictionary()\nmutableDict.setString(\"street\", \"1 Main st.\")\nmutableDict.setString(\"city\", \"San Francisco\")\n\n// Add the dictionary to a document's properties and save the document\nval mutableDoc = MutableDocument(\"doc1\")\nmutableDoc.setDictionary(\"address\", mutableDict)\ncollection.save(mutableDoc)\n</code></pre>"},{"location":"documents/#using-arrays","title":"Using Arrays","text":"<p>API References</p> <ul> <li>Array</li> <li>MutableArray</li> </ul> <p>Example 4. Read Only</p> <pre><code>// NOTE: No error handling, for brevity (see getting started)\n\nval document = collection.getDocument(\"doc1\")\n\n// Getting a phones array from the document's properties\nval array = document?.getArray(\"phones\")\n\n// Get element count\nval count = array?.count\n\n// Access an array element by index\nval phone = array?.getString(1)\n\n// Iterate array\narray?.forEachIndexed { index, item -&gt;\n    println(\"Row $index = $item\")\n}\n\n// Create a mutable copy\nval mutableArray = array?.toMutable()\n</code></pre> <p>Example 5. Mutable</p> <pre><code>// NOTE: No error handling, for brevity (see getting started)\n\n// Create a new mutable array and populate data into the array\nval mutableArray = MutableArray()\nmutableArray.addString(\"650-000-0000\")\nmutableArray.addString(\"650-000-0001\")\n\n// Set the array to document's properties and save the document\nval mutableDoc = MutableDocument(\"doc1\")\nmutableDoc.setArray(\"phones\", mutableArray)\ncollection.save(mutableDoc)\n</code></pre>"},{"location":"documents/#using-blobs","title":"Using Blobs","text":"<p>For more on working with blobs, see Blobs.</p>"},{"location":"documents/#document-initializers","title":"Document Initializers","text":"<p>You can use the following methods/initializers:</p> <ul> <li>Use the <code>MutableDocument()</code> initializer to   create a new document where the document ID is randomly generated by the database.</li> <li>Use the <code>MutableDocument(id: String?)</code>   initializer to create a new document with a specific ID.</li> <li>Use the <code>Collection.getDocument()</code> method to get a   document. If the document doesn\u2019t exist in the collection, the method will return <code>null</code>. You can use this behavior to   check if a document with a given ID already exists in the collection.</li> </ul> <p>Example 6. Persist a document</p> <pre><code>val doc = MutableDocument()\ndoc.apply {\n    setString(\"type\", \"task\")\n    setString(\"owner\", \"todo\")\n    setDate(\"createdAt\", Clock.System.now())\n}\ncollection.save(doc)\n</code></pre> <p>Tip</p> <p>The Kotbase KTX extensions provide a document builder DSL:</p> <pre><code>val doc = MutableDocument {\n    \"type\" to \"task\"\n    \"owner\" to \"todo\"\n    \"createdAt\" to Clock.System.now()\n}\ndatabase.save(doc)\n</code></pre>"},{"location":"documents/#mutability","title":"Mutability","text":"<p>By default, a document is immutable when it is read from the database. Use <code>Document.toMutable()</code> to create an updatable instance of the document.</p> <p>Example 7. Make a mutable document</p> <p>Changes to the document are persisted to the database when the <code>save</code> method is called.</p> <pre><code>collection.getDocument(\"xyz\")?.toMutable()?.let {\n    it.setString(\"name\", \"apples\")\n    collection.save(it)\n}\n</code></pre> <p>Note</p> <p>Any user change to the value of reserved keys (<code>_id</code>, <code>_rev</code>, or <code>_deleted</code>) will be detected when a document is saved and will result in an exception (Error Code 5 \u2014 <code>CorruptRevisionData</code>) \u2014 see also Document Constraints.</p>"},{"location":"documents/#batch-operations","title":"Batch operations","text":"<p>If you\u2019re making multiple changes to a database at once, it\u2019s faster to group them together. The following example persists a few documents in batch.</p> <p>Example 8. Batch operations</p> <pre><code>database.inBatch {\n    for (i in 0..9) {\n        val doc = MutableDocument()\n        doc.apply {\n            setValue(\"type\", \"user\")\n            setValue(\"name\", \"user $i\")\n            setBoolean(\"admin\", false)\n        }\n        collection.save(doc)\n        println(\"saved user document: ${doc.getString(\"name\")}\")\n    }\n}\n</code></pre> <p>At the local level this operation is still transactional: no other <code>Database</code> instances, including ones managed by the replicator, can make changes during the execution of the block, and other instances will not see partial changes. But Couchbase Mobile is a distributed system, and due to the way replication works, there\u2019s no guarantee that Sync Gateway or other devices will receive your changes all at once.</p>"},{"location":"documents/#document-change-events","title":"Document change events","text":"<p>You can register for document changes. The following example registers for changes to the document with ID <code>user.john</code> and prints the <code>verified_account</code> property when a change is detected.</p> <p>Example 9. Document change events</p> <pre><code>collection.addDocumentChangeListener(\"user.john\") { change -&gt;\n    collection.getDocument(change.documentID)?.let {\n        println(\"Status: ${it.getString(\"verified_account\")}\")\n    }\n}\n</code></pre>"},{"location":"documents/#using-kotlin-flows","title":"Using Kotlin Flows","text":"<p>Kotlin users can also take advantage of <code>Flow</code>s to monitor for changes.</p> <p>The following methods show how to watch for document changes in a given collection or for changes to a specific document.</p> Collection ChangesDocument Changes <pre><code>val collChanges: Flow&lt;List&lt;String&gt;&gt; = collection.collectionChangeFlow()\n    .map { it.documentIDs }\n</code></pre> <pre><code>val docChanges: Flow&lt;DocumentChange&gt; = collection.documentChangeFlow(\"1001\")\n    .mapNotNull { change -&gt;\n        change.takeUnless {\n            collection.getDocument(it.documentID)?.getString(\"owner\").equals(owner)\n        }\n    }\n</code></pre>"},{"location":"documents/#document-expiration","title":"Document Expiration","text":"<p>Document expiration allows users to set the expiration date for a document. When the document expires, it is purged from the database. The purge is not replicated to Sync Gateway.</p> <p>Example 10. Set document expiration</p> <p>This example sets the TTL for a document to 1 day from the current time.</p> <pre><code>// Purge the document one day from now\ncollection.setDocumentExpiration(\n    \"doc123\",\n    Clock.System.now() + 1.days\n)\n\n// Reset expiration\ncollection.setDocumentExpiration(\"doc1\", null)\n\n// Query documents that will be expired in less than five minutes\nval query = QueryBuilder\n    .select(SelectResult.expression(Meta.id))\n    .from(DataSource.collection(collection))\n    .where(\n        Meta.expiration.lessThan(\n            Expression.longValue((Clock.System.now() + 5.minutes).toEpochMilliseconds())\n        )\n    )\n</code></pre>"},{"location":"documents/#document-constraints","title":"Document Constraints","text":"<p>Couchbase Lite APIs do not explicitly disallow the use of attributes with the underscore prefix at the top level of document. This is to facilitate the creation of documents for use either in local only mode where documents are not synced, or when used exclusively in peer-to-peer sync.</p> <p>Note</p> <p>\"_id\", :\"_rev\" and \"_sequence\" are reserved keywords and must not be used as top-level attributes \u2014 see Example  11.</p> <p>Users are cautioned that any attempt to sync such documents to Sync Gateway will result in an error. To be future-proof, you are advised to avoid creating such documents. Use of these attributes for user-level data may result in undefined system behavior.</p> <p>For more guidance \u2014 see Sync Gateway - data modeling guidelines</p> <p>Example 11. Reserved Keys List</p> <ul> <li>_attachments</li> <li>_deleted <sup>1</sup></li> <li>_id <sup>1</sup></li> <li>_removed</li> <li>_rev <sup>1</sup></li> <li>_sequence</li> </ul>"},{"location":"documents/#working-with-json-data","title":"Working with JSON Data","text":"<p>In this section Arrays | Blobs | Dictionaries | Documents | Query Results as JSON</p> <p>The <code>toJSON()</code> typed-accessor means you can easily work with JSON data, native and Couchbase Lite objects.</p>"},{"location":"documents/#arrays","title":"Arrays","text":"<p>Convert an <code>Array</code> to and from JSON using the <code>toJSON()</code> and <code>toList()</code> methods \u2014 see Example 12.</p> <p>Additionally, you can:</p> <ul> <li>Initialize a <code>MutableArray</code> using data supplied as a JSON string. This is done using the   <code>MutableArray(json: String)</code> constructor \u2014 see   Example 12.</li> <li>Set data with a JSON string using <code>setJSON()</code>.</li> </ul> <p>Example 12. Arrays as JSON strings</p> <pre><code>// JSON String -- an Array (3 elements. including embedded arrays)\nval jsonString = \"\"\"[{\"id\":\"1000\",\"type\":\"hotel\",\"name\":\"Hotel Ted\",\"city\":\"Paris\",\"country\":\"France\",\"description\":\"Undefined description for Hotel Ted\"},{\"id\":\"1001\",\"type\":\"hotel\",\"name\":\"Hotel Fred\",\"city\":\"London\",\"country\":\"England\",\"description\":\"Undefined description for Hotel Fred\"},{\"id\":\"1002\",\"type\":\"hotel\",\"name\":\"Hotel Ned\",\"city\":\"Balmain\",\"country\":\"Australia\",\"description\":\"Undefined description for Hotel Ned\",\"features\":[\"Cable TV\",\"Toaster\",\"Microwave\"]}]\"\"\"\n\n// initialize array from JSON string\nval mArray = MutableArray(jsonString)\n\n// Create and save new document using the array\nfor (i in 0 ..&lt; mArray.count) {\n    mArray.getDictionary(i)?.apply {\n        println(getString(\"name\") ?: \"unknown\")\n        collection.save(MutableDocument(getString(\"id\"), toMap()))\n    }\n}\n\n// Get an array from the document as a JSON string\ncollection.getDocument(\"1002\")?.getArray(\"features\")?.apply {\n    // Print its elements\n    for (feature in toList()) {\n        println(\"$feature\")\n    }\n    println(toJSON())\n}\n</code></pre>"},{"location":"documents/#blobs","title":"Blobs","text":"<p>Convert a <code>Blob</code> to JSON using the <code>toJSON()</code> method \u2014 see Example 13.</p> <p>You can use <code>isBlob()</code> to check whether a given dictionary object is a blob or not \u2014 see Example 13.</p> <p>Note that the blob object must first be saved to the database (generating the required metadata) before you can use the <code>toJSON()</code> method.</p> <p>Example 13. Blobs as JSON strings</p> <pre><code>val thisBlob = collection.getDocument(\"thisdoc-id\")!!.toMap()\nif (!Blob.isBlob(thisBlob)) {\n    return\n}\nval blobType = thisBlob[\"content_type\"].toString()\nval blobLength = thisBlob[\"length\"] as Number?\n</code></pre> <p>See also: Blobs</p>"},{"location":"documents/#dictionaries","title":"Dictionaries","text":"<p>Convert a <code>Dictionary</code> to and from JSON using the <code>toJSON()</code> and <code>toMap()</code> methods \u2014 see Example 14.</p> <p>Additionally, you can:</p> <ul> <li>Initialize a <code>MutableDictionary</code> using data supplied as a JSON string. This is done using the   <code>MutableDictionary(json: String)</code>   constructor \u2014 see Example 14.</li> <li>Set data with a JSON string using <code>setJSON()</code>.</li> </ul> <p>Example 14. Dictionaries as JSON strings</p> <pre><code>val jsonString = \"\"\"{\"id\":\"1002\",\"type\":\"hotel\",\"name\":\"Hotel Ned\",\"city\":\"Balmain\",\"country\":\"Australia\",\"description\":\"Undefined description for Hotel Ned\",\"features\":[\"Cable TV\",\"Toaster\",\"Microwave\"]}\"\"\"\n\nval mDict = MutableDictionary(jsonString)\nprintln(\"$mDict\")\nprintln(\"Details for: ${mDict.getString(\"name\")}\")\nmDict.forEach { key -&gt;\n    println(key + \" =&gt; \" + mDict.getValue(key))\n}\n</code></pre>"},{"location":"documents/#documents","title":"Documents","text":"<p>Convert a <code>Document</code> to and from JSON strings using the <code>toJSON()</code> and <code>toMap()</code> methods \u2014 see Example 15.</p> <p>Additionally, you can:</p> <ul> <li>Initialize a <code>MutableDocument</code> using data supplied as a JSON string. This is done using the   <code>MutableDocument(id: String?, json: String)</code> constructor \u2014 see Example 15.</li> <li>Set data with a JSON string using <code>setJSON()</code>.</li> </ul> <p>Example 15. Documents as JSON strings</p> <pre><code>QueryBuilder\n    .select(SelectResult.expression(Meta.id).`as`(\"metaId\"))\n    .from(DataSource.collection(srcColl))\n    .execute()\n    .forEach {\n        it.getString(\"metaId\")?.let { thisId -&gt;\n            srcColl.getDocument(thisId)?.toJSON()?.let { json -&gt;\n                println(\"JSON String = $json\")\n                val hotelFromJSON = MutableDocument(thisId, json)\n                dstColl.save(hotelFromJSON)\n                dstColl.getDocument(thisId)?.toMap()?.forEach { e -&gt;\n                    println(\"${e.key} =&gt; ${e.value}\")\n                }\n            }\n        }\n    }\n</code></pre>"},{"location":"documents/#query-results-as-json","title":"Query Results as JSON","text":"<p>Convert a query <code>Result</code> to a JSON string using its <code>toJSON()</code> accessor method. The JSON string can easily be serialized or used as required in your application. See Example 16 for a working example using kotlinx-serialization.</p> <p>Example 16. Using JSON Results</p> <pre><code>// Uses kotlinx-serialization JSON processor\n@Serializable\ndata class Hotel(val id: String, val type: String, val name: String)\n\nval hotels = mutableListOf&lt;Hotel&gt;()\n\nval query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"type\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n\n        // Get result as JSON string\n        val json = it.toJSON()\n\n        // Get JsonObject map from JSON string\n        val mapFromJsonString = Json.decodeFromString&lt;JsonObject&gt;(json)\n\n        // Use created JsonObject map\n        val hotelId = mapFromJsonString[\"id\"].toString()\n        val hotelType = mapFromJsonString[\"type\"].toString()\n        val hotelName = mapFromJsonString[\"name\"].toString()\n\n        // Get custom object from JSON string\n        val hotel = Json.decodeFromString&lt;Hotel&gt;(json)\n        hotels.add(hotel)\n    }\n}\n</code></pre>"},{"location":"documents/#json-string-format","title":"JSON String Format","text":"<p>If your query selects ALL then the JSON format will be:</p> <pre><code>{\n  database-name: {\n    key1: \"value1\",\n    keyx: \"valuex\"\n  }\n}\n</code></pre> <p>If your query selects a sub-set of available properties then the JSON format will be:</p> <pre><code>{\n  key1: \"value1\",\n  keyx: \"valuex\"\n}\n</code></pre> <ol> <li> <p>Any change to this reserved key will be detected when it is saved and will result in a Couchbase exception (Error Code 5 \u2014 <code>CorruptRevisionData</code>)\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"full-text-search/","title":"Full Text Search","text":"<p>Couchbase Lite database data querying concepts \u2014 full text search</p>"},{"location":"full-text-search/#overview","title":"Overview","text":"<p>To run a full-text search (FTS) query, you must create a full-text index on the expression being matched. Unlike regular queries, the index is not optional.</p> <p>You can choose to use SQL++ or <code>QueryBuilder</code> syntaxes to create and use FTS indexes.</p> <p>The following examples use the data model introduced in Indexing. They create and use an FTS index built from the hotel\u2019s <code>overview</code> text.</p>"},{"location":"full-text-search/#sql","title":"SQL++","text":""},{"location":"full-text-search/#create-index","title":"Create Index","text":"<p>SQL++ provides a configuration object to define Full Text Search indexes \u2014 <code>FullTextIndexConfiguration</code>.</p> <p>Example 1. Using SQL++'s FullTextIndexConfiguration</p> <pre><code>collection.createIndex(\n    \"overviewFTSIndex\",\n    FullTextIndexConfiguration(\"overview\")\n)\n</code></pre>"},{"location":"full-text-search/#use-index","title":"Use Index","text":"<p>Full-text search is enabled using the SQL++ <code>match()</code> function.</p> <p>With the index created, you can construct and run a full-text search (FTS) query using the indexed properties.</p> <p>The index will omit a set of common words, to avoid words like \"I\", \"the\", and \"an\" from overly influencing your queries. See full list of these stop words.</p> <p>The following example finds all hotels mentioning Michigan in their <code>overview</code> text.</p> <p>Example 2. Using SQL++ Full Text Search</p> <pre><code>val ftsQuery = database.createQuery(\n    \"SELECT _id, overview FROM _ WHERE MATCH(overviewFTSIndex, 'michigan') ORDER BY RANK(overviewFTSIndex)\"\n)\nftsQuery.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        println(\"${it.getString(\"id\")}: ${it.getString(\"overview\")}\")\n    }\n}\n</code></pre>"},{"location":"full-text-search/#querybuilder","title":"QueryBuilder","text":""},{"location":"full-text-search/#create-index_1","title":"Create Index","text":"<p>The following example creates an FTS index on the <code>overview</code> property.</p> <p>Example 3. Using the IndexBuilder method</p> <pre><code>collection.createIndex(\n    \"overviewFTSIndex\",\n    IndexBuilder.fullTextIndex(FullTextIndexItem.property(\"overview\"))\n)\n</code></pre>"},{"location":"full-text-search/#use-index_1","title":"Use Index","text":"<p>With the index created, you can construct and run a full-text search (FTS) query using the indexed properties.</p> <p>The following example finds all hotels mentioning Michigan in their <code>overview</code> text.</p> <p>Example 4. Using QueryBuilder Full Text Search</p> <pre><code>val ftsQuery = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"overview\")\n    )\n    .from(DataSource.collection(collection))\n    .where(FullTextFunction.match(\"overviewFTSIndex\", \"michigan\"))\n\nftsQuery.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        println(\"${it.getString(\"Meta.id\")}: ${it.getString(\"overview\")}\")\n    }\n}\n</code></pre>"},{"location":"full-text-search/#operation","title":"Operation","text":"<p>In the examples above, the pattern to match is a word, the full-text search query matches all documents that contain the word \"michigan\" in the value of the <code>doc.overview</code> property.</p> <p>Search is supported for all languages that use whitespace to separate words.</p> <p>Stemming, which is the process of fuzzy matching parts of speech, like \"fast\" and \"faster\", is supported in the following languages: Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish and Turkish.</p>"},{"location":"full-text-search/#pattern-matching-formats","title":"Pattern Matching Formats","text":"<p>As well as providing specific words or strings to match against, you can provide the pattern to match in these formats.</p>"},{"location":"full-text-search/#prefix-queries","title":"Prefix Queries","text":"<p>The query expression used to search for a term prefix is the prefix itself with a \"*\" character appended to it.</p> <p>Example 5. Prefix query</p> <p>Query for all documents containing a term with the prefix \"lin\".</p> <pre><code>\"lin*\"\n</code></pre> <p>This will match:</p> <ul> <li>All documents that contain \"linux\"</li> <li>And \u2026 those that contain terms \"linear\", \"linker\", \"linguistic\", and so on.</li> </ul>"},{"location":"full-text-search/#overriding-the-property-name","title":"Overriding the Property Name","text":"<p>Normally, a token or token prefix query is matched against the document property specified as the left-hand side of the <code>match</code> operator. This may be overridden by specifying a property name followed by a \":\" character before a basic term query. There may be space between the \":\" and the term to query for, but not between the property name and the \":\" character.</p> <p>Example 6. Override indexed property name</p> <p>Query the database for documents for which the term \"linux\" appears in the document title, and the term \"problems\" appears in either the title or body of the document.</p> <pre><code>'title:linux problems'\n</code></pre>"},{"location":"full-text-search/#phrase-queries","title":"Phrase Queries","text":"<p>A phrase query is one that retrieves all documents containing a nominated set of terms or term prefixes in a specified order with no intervening tokens.</p> <p>Phrase queries are specified by enclosing a space separated sequence of terms or term prefixes in double quotes (\").</p> <p>Example 7. Phrase query</p> <p>Query for all documents that contain the phrase \"linux applications\".</p> <pre><code>\"linux applications\"\n</code></pre>"},{"location":"full-text-search/#near-queries","title":"NEAR Queries","text":"<p>A NEAR query is a query that returns documents that contain two or more nominated terms or phrases within a specified proximity of each other (by default with 10 or less intervening terms). A NEAR query is specified by putting the keyword \"NEAR\" between two phrases, tokens or token prefix queries. To specify a proximity other than the default, an operator of the form \"NEAR/&lt;number&gt;\" may be used, where &lt;number&gt; is the maximum number of intervening terms allowed.</p> <p>Example 8. Near query</p> <p>Search for a document that contains the phrase \"replication\" and the term \"database\" with not more than 2 terms separating the two.</p> <pre><code>\"database NEAR/2 replication\"\n</code></pre>"},{"location":"full-text-search/#and-or-not-query-operators","title":"AND, OR &amp; NOT Query Operators","text":"<p>The enhanced query syntax supports the AND, OR and NOT binary set operators. Each of the two operands to an operator may be a basic FTS query, or the result of another AND, OR or NOT set operation. Operators must be entered using capital letters. Otherwise, they are interpreted as basic term queries instead of set operators.</p> <p>Example 9. Using And, Or and Not</p> <p>Return the set of documents that contain the term \"couchbase\", and the term \"database\".</p> <pre><code>\"couchbase AND database\"\n</code></pre>"},{"location":"full-text-search/#operator-precedence","title":"Operator Precedence","text":"<p>When using the enhanced query syntax, parenthesis may be used to specify the precedence of the various operators.</p> <p>Example 10. Operator precedence</p> <p>Query for the set of documents that contains the term \"linux\", and at least one of the phrases \"couchbase database\" and \"sqlite library\".</p> <pre><code>'(\"couchbase database\" OR \"sqlite library\") AND \"linux\"'\n</code></pre>"},{"location":"full-text-search/#ordering-results","title":"Ordering Results","text":"<p>It\u2019s very common to sort full-text results in descending order of relevance. This can be a very difficult heuristic to define, but Couchbase Lite comes with a ranking function you can use.</p> <p>In the <code>OrderBy</code> array, use a string of the form <code>Rank(X)</code>, where <code>X</code> is the property or expression being searched, to represent the ranking of the result.</p>"},{"location":"getting-started/","title":"Build and Run","text":"<p>Build and run a starter app using Kotbase</p>"},{"location":"getting-started/#introduction","title":"Introduction","text":"<p>The Getting Started app is a very basic Kotlin Multiplatform app that demonstrates using Kotbase in a shared Kotlin module with native apps on each of the supported platforms.</p> <p>You can access the <code>getting-started</code> and <code>getting-started-compose</code> projects in the git repository under examples.</p> <p>Quick Steps</p> <ol> <li>Get the project and open it in Android Studio</li> <li>Build it</li> <li>Run any of the platform apps</li> <li>Enter some input and press \"Run database work\"    The log output, in the app's UI or console panel, will show output similar to that in Figure 1</li> <li>That\u2019s it.</li> </ol> <p>Figure 1: Example app output</p> <pre><code>01-13 11:35:03.733 I/SHARED_KOTLIN: Database created: Database{@@0x9645222: 'desktopApp-db'}\n01-13 11:35:03.742 I/SHARED_KOTLIN: Collection created: desktopApp-db@@x7fba7630dcb0._default.example-coll\n01-13 11:35:03.764 I/DESKTOP_APP: Created document :: 83b6acb4-21ba-4834-aee4-2419dcea1114\n01-13 11:35:03.767 I/SHARED_KOTLIN: Retrieved document:\n01-13 11:35:03.767 I/SHARED_KOTLIN: Document ID :: 83b6acb4-21ba-4834-aee4-2419dcea1114\n01-13 11:35:03.767 I/SHARED_KOTLIN: Learning :: Kotlin\n01-13 11:35:03.768 I/DESKTOP_APP: Updated document :: 83b6acb4-21ba-4834-aee4-2419dcea1114\n01-13 11:35:03.785 I/SHARED_KOTLIN: Number of rows :: 1\n01-13 11:35:03.789 I/SHARED_KOTLIN: Document ID :: 83b6acb4-21ba-4834-aee4-2419dcea1114\n01-13 11:35:03.790 I/SHARED_KOTLIN: Document :: {\"language\":\"Kotlin\",\"version\":2.0,\"platform\":\"JVM 21.0.1\",\"input\":\"Hello, Kotbase!\"}\n</code></pre>"},{"location":"getting-started/#getting-started-app","title":"Getting Started App","text":"<p>The Getting Started app shows examples of the essential Couchbase Lite CRUD operations, including:</p> <ul> <li>Create a database</li> <li>Create a collection</li> <li>Create a document</li> <li>Retrieve a document</li> <li>Update a document</li> <li>Query documents</li> <li>Create and run a replicator</li> </ul> <p>Whilst no exemplar of a real application, it will give you a good idea how to get started using Kotbase and Kotlin Multiplatform.</p>"},{"location":"getting-started/#shared-kotlin-native-ui","title":"Shared Kotlin + Native UI","text":"<p>The <code>getting-started</code> version demonstrates using shared Kotlin code using Kotbase together with native app UIs.</p> <p>The Kotbase database examples are in the <code>shared</code> module, which is shared between each of the platform apps.</p>"},{"location":"getting-started/#android-app","title":"Android App","text":"<p>The Android app is in the <code>androidApp</code> module. It uses XML views for its UI.</p> Run Android StudioCommand Line <p>Run the <code>androidApp</code> run configuration.</p> <p>Install<pre><code>./gradlew :androidApp:installDebug\n</code></pre> Run<pre><code>adb shell am start -n dev.kotbase.gettingstarted/.MainActivity\n</code></pre></p>"},{"location":"getting-started/#ios-app","title":"iOS App","text":"<p>The iOS app is in the <code>iosApp</code> directory. It is an Xcode project and uses SwiftUI for its UI.</p> Run Android StudioXcode <p>With the Kotlin Multiplatform Mobile plugin run the <code>iosApp</code> run configuration.</p> <p>Open <code>iosApp/iosApp.xcodeproj</code> and run the <code>iosApp</code> scheme.</p>"},{"location":"getting-started/#jvm-desktop-app","title":"JVM Desktop App","text":"<p>The JVM desktop app is in the <code>desktopApp</code> module. It uses Compose UI for its UI.</p> Run Android StudioCommand Line <p>Run the <code>desktopApp</code> run configuration.</p> <pre><code>./gradlew :desktopApp:run\n</code></pre>"},{"location":"getting-started/#native-cli-app","title":"Native CLI App","text":"<p>The native app is in the <code>cliApp</code> module. It uses a command-line interface (CLI) on macOS, Linux, and Windows.</p> <p>The app takes two command-line arguments, first the \"input\" value, written to the document on update, and second true or false for whether to run the replicator. These arguments can also be passed as gradle properties.</p> Run Android StudioCommand Line <p>Run the <code>cliApp</code> run configuration.</p> <p><pre><code>./gradlew :cliApp:runDebugExecutableNative -PinputValue=\"\" -Preplicate=false\n</code></pre> or Build<pre><code>./gradlew :cliApp:linkDebugExecutableNative\n</code></pre> Run<pre><code>cliApp/build/bin/native/debugExecutable/cliApp.kexe \"&lt;input value&gt;\" &lt;true|false&gt;\n</code></pre></p>"},{"location":"getting-started/#share-everything-in-kotlin","title":"Share Everything in Kotlin","text":"<p>The <code>getting-started-compose</code> version demonstrates sharing the entirety of the application code in Kotlin, including the UI with Compose Multiplatform.</p> <p>The entire compose app is a single Kotlin multiplatform module, encompassing all platforms, with an additional Xcode project for the iOS app.</p>"},{"location":"getting-started/#android-app_1","title":"Android App","text":"Run Android StudioCommand Line <p>Run the <code>androidApp</code> run configuration.</p> <p>Install<pre><code>./gradlew :composeApp:installDebug\n</code></pre> Start<pre><code>adb shell am start -n dev.kotbase.gettingstarted.compose/.MainActivity\n</code></pre></p>"},{"location":"getting-started/#ios-app_1","title":"iOS App","text":"Run Android StudioXcode <p>With the Kotlin Multiplatform Mobile plugin run the <code>iosApp</code> run configuration.</p> <p>Open <code>iosApp/iosApp.xcworkspace</code> and run the <code>iosApp</code> scheme.</p> <p>Important</p> <p>Be sure to open <code>iosApp.xcworkspace</code> and not <code>iosApp.xcodeproj</code>. The <code>getting-started-compose</code> <code>iosApp</code> uses CocoaPods and the CocoaPods Gradle plugin to add the <code>shared</code> library dependency. The <code>.xcworkspace</code> includes the CocoaPods dependencies.</p> <p>Note</p> <p>Compose Multiplatform no longer requires CocoaPods for copying resources since version 1.5.0. However, the <code>getting-started-compose</code> example still uses CocoaPods for linking the Couchbase Lite framework. See the <code>getting-started</code> version for an example of how to link the Couchbase Lite framework without using CocoaPods.</p>"},{"location":"getting-started/#jvm-desktop-app_1","title":"JVM Desktop App","text":"Run Android StudioCommand Line <p>Run the <code>desktopApp</code> run configuration.</p> <pre><code>./gradlew :composeApp:run\n</code></pre>"},{"location":"getting-started/#sync-gateway-replication","title":"Sync Gateway Replication","text":"<p>Using the apps with Sync Gateway and Couchbase Server obviously requires you have, or install, working versions of both. See also \u2014 Install Sync Gateway</p> <p>Once you have Sync Gateway configured, update the <code>ReplicatorConfiguration</code> in the app with the server's URL endpoint and authentication credentials.</p>"},{"location":"getting-started/#kotlin-multiplatform-tips","title":"Kotlin Multiplatform Tips","text":""},{"location":"getting-started/#calling-platform-specific-apis","title":"Calling Platform-specific APIs","text":"<p>The apps utilize the Kotlin Multiplatform <code>expect</code>/<code>actual</code> feature to populate the created document with the platform the app is running on.</p> <p>See common <code>expect fun getPlatform()</code> and <code>actual fun getPlatform()</code> for Android, iOS, JVM, Linux, macOS, and Windows.</p>"},{"location":"getting-started/#using-coroutines-in-swift","title":"Using Coroutines in Swift","text":"<p>The <code>getting-started</code> app uses KMP-NativeCoroutines to consume Kotlin <code>Flow</code>s in Swift. See <code>@NativeCoroutines</code> annotation in Kotlin and <code>asyncSequence(for:)</code> in Swift code.</p> <p>SKIE is another solution, which generates Swift code for enhanced Swift\u2013Kotlin interop, including coroutines. It's used in the Kotbase Notes example app described below.</p>"},{"location":"getting-started/#going-further","title":"Going Further","text":"<p>For an example of a full-featured MVVM architected Kotlin Multiplatform app, including data synchronization, see the Kotbase Notes app. This example includes:</p> <ul> <li>Support for Android, iOS, and JVM desktop platforms.</li> <li>Shared data, domain, presentation, and UI logic.</li> <li>Platform-specific utility functions via <code>expect</code>/<code>actual</code>.</li> <li>Platform-specific lifecycle management for data sync.</li> <li>Dependency injection via Koin.</li> <li>JSON serialization via kotlinx-serialization.</li> <li>HTTP client via Ktor.</li> <li>Enhanced Swift interoperability via SKIE.</li> </ul>"},{"location":"getting-started/#kotbase-library-source","title":"Kotbase Library Source","text":"<p>The apps can get the Kotbase library dependency either from its published Maven artifact or build the library locally from the source repository. Set the <code>useLocalLib</code> property in gradle.properties to <code>true</code> to build the library from source, otherwise the published artifact from Maven Central will be used.</p>"},{"location":"handling-data-conflicts/","title":"Handling Data Conflicts","text":"<p>Couchbase Lite Database Sync \u2014 handling conflict between data changes</p>"},{"location":"handling-data-conflicts/#causes-of-conflicts","title":"Causes of Conflicts","text":"<p>Document conflicts can occur if multiple changes are made to the same version of a document by multiple peers in a distributed system. For Couchbase Mobile, this can be a Couchbase Lite or Sync Gateway database instance.</p> <p>Such conflicts can occur after either of the following events:</p> <ul> <li>A replication saves a document change \u2014 in which case the change with the most-revisions wins (unless one change   is a delete). See Conflicts when Replicating</li> <li>An application saves a document change directly to a database instance \u2014 in which case, last write wins, unless   one change is a delete \u2014 see Conflicts when Updating</li> </ul> <p>Note</p> <p>Deletes always win. So, in either of the above cases, if one of the changes was a delete then that change wins.</p> <p>The following sections discuss each scenario in more detail.</p> <p>Dive deeper \u2026</p> <p>Read more about Document Conflicts and Automatic Conflict Resolution in Couchbase Mobile.</p>"},{"location":"handling-data-conflicts/#conflicts-when-replicating","title":"Conflicts when Replicating","text":"<p>There\u2019s no practical way to prevent a conflict when incompatible changes to a document are be made in multiple instances of an app. The conflict is realized only when replication propagates the incompatible changes to each other.</p> <p>Example 1. A typical replication conflict scenario</p> <ol> <li>Molly uses her device to create DocumentA.</li> <li>Replication syncs DocumentA to Naomi\u2019s device.</li> <li>Molly uses her device to apply ChangeX to DocumentA.</li> <li>Naomi uses her device to make a different change, ChangeY, to DocumentA.</li> <li>Replication syncs ChangeY to Molly\u2019s device.    This device already has ChangeX putting the local document in conflict.</li> <li>Replication syncs ChangeX to Naomi\u2019s device.    This device already has ChangeY and now Naomi\u2019s local document is in conflict.</li> </ol>"},{"location":"handling-data-conflicts/#automatic-conflict-resolution","title":"Automatic Conflict Resolution","text":"<p>Note</p> <p>The rules only apply to conflicts caused by replication. Conflict resolution takes place exclusively during pull replication, while push replication remains unaffected.</p> <p>Couchbase Lite uses the following rules to handle conflicts such as those described in A typical replication conflict scenario:</p> <ul> <li>If one of the changes is a deletion:   A deleted document (that is, a tombstone) always wins over a document update.</li> <li>If both changes are document changes:   The change with the most revisions will win.   Since each change creates a revision with an ID prefixed by an incremented version number, the winner is the change   with the highest version number.</li> </ul> <p>The result is saved internally by the Couchbase Lite replicator. Those rules describe the internal behavior of the replicator. For additional control over the handling of conflicts, including when a replication is in progress, see Custom Conflict Resolution.</p>"},{"location":"handling-data-conflicts/#custom-conflict-resolution","title":"Custom Conflict Resolution","text":"<p>Starting in Couchbase Lite 2.6, application developers who want more control over how document conflicts are handled can use custom logic to select the winner between conflicting revisions of a document.</p> <p>If a custom conflict resolver is not provided, the system will automatically resolve conflicts as discussed in Automatic Conflict Resolution, and as a consequence there will be no conflicting revisions in the database.</p> <p>Caution</p> <p>While this is true of any user defined functions, app developers must be strongly cautioned against writing sub-optimal custom conflict handlers that are time consuming and could slow down the client\u2019s save operations.</p> <p>To implement custom conflict resolution during replication, you must implement the following steps:</p> <ol> <li>Conflict Resolver</li> <li>Configure the Replicator</li> </ol>"},{"location":"handling-data-conflicts/#conflict-resolver","title":"Conflict Resolver","text":"<p>Apps have the following strategies for resolving conflicts:</p> <ul> <li>Local Wins: The current revision in the database wins.</li> <li>Remote Wins: The revision pulled from the remote endpoint through replication wins.</li> <li>Merge: Merge the content bodies of the conflicting revisions.</li> </ul> <p>Example 2. Using conflict resolvers</p> Local WinsRemote WinsMerge <pre><code>val localWinsResolver: ConflictResolver = { conflict -&gt;\n    conflict.localDocument\n}\nconfig.conflictResolver = localWinsResolver\n</code></pre> <pre><code>val remoteWinsResolver: ConflictResolver = { conflict -&gt;\n    conflict.remoteDocument\n}\nconfig.conflictResolver = remoteWinsResolver\n</code></pre> <pre><code>val mergeConflictResolver: ConflictResolver = { conflict -&gt;\n    val localDoc = conflict.localDocument?.toMap()?.toMutableMap()\n    val remoteDoc = conflict.remoteDocument?.toMap()?.toMutableMap()\n\n    val merge: MutableMap&lt;String, Any?&gt;?\n    if (localDoc == null) {\n        merge = remoteDoc\n    } else {\n        merge = localDoc\n        if (remoteDoc != null) {\n            merge.putAll(remoteDoc)\n        }\n    }\n\n    if (merge == null) {\n        MutableDocument(conflict.documentId)\n    } else {\n        MutableDocument(conflict.documentId, merge)\n    }\n}\nconfig.conflictResolver = mergeConflictResolver\n</code></pre> <p>When a <code>null</code> document is returned by the resolver, the conflict will be resolved as a document deletion.</p>"},{"location":"handling-data-conflicts/#important-guidelines-and-best-practices","title":"Important Guidelines and Best Practices","text":"<p>Points of Note:</p> <ul> <li>If you have multiple replicators, it is recommended that instead of distinct resolvers, you should use a unified   conflict resolver across all replicators. Failure to do so could potentially lead to data loss under exception cases   or if the app is terminated (by the user or an app crash) while there are pending conflicts.</li> <li>If the document ID of the document returned by the resolver does not correspond to the document that is in conflict   then the replicator will log a warning message.</li> </ul> <p>Important</p> <p>Developers are encouraged to review the warnings and fix the resolver to return a valid document ID.</p> <ul> <li>If a document from a different database is returned, the replicator will treat it as an error. A document replication   event will be posted with an error and an error message will be   logged.</li> </ul> <p>Important</p> <p>Apps are encouraged to observe such errors and take appropriate measures to fix the resolver function.</p> <ul> <li>When the replicator is stopped, the system will attempt to resolve outstanding and pending conflicts before stopping.   Hence, apps should expect to see some delay when attempting to stop the replicator depending on the number of   outstanding documents in the replication queue and the complexity of the resolver function.</li> <li>If there is an exception thrown in the <code>ConflictResolver</code>   function, the exception will be caught and handled:<ul> <li>The conflict to resolve will be skipped. The pending conflicted documents will be resolved when the replicator is   restarted.</li> <li>The exception will be reported in the warning logs.</li> <li>The exception will be reported in the document replication event.</li> </ul> </li> </ul> <p>Important</p> <p>While the system will handle exceptions in the manner specified above, it is strongly encouraged for the resolver function to catch exceptions and handle them in a way appropriate to their needs.</p>"},{"location":"handling-data-conflicts/#configure-the-replicator","title":"Configure the Replicator","text":"<p>The implemented custom conflict resolver can be registered on the <code>ReplicatorConfiguration</code> object. The default value of the <code>conflictResolver</code> is <code>null</code>. When the value is <code>null</code>, the default conflict resolution will be applied.</p> <p>Example 3. A Conflict Resolver</p> <pre><code>val collectionConfig = CollectionConfiguration(conflictResolver = localWinsResolver)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(srcCollections, collectionConfig)\n)\n\n// Start the replicator\n// (be sure to hold a reference somewhere that will prevent it from being GCed)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"handling-data-conflicts/#conflicts-when-updating","title":"Conflicts when Updating","text":"<p>When updating a document, you need to consider the possibility of update conflicts. Update conflicts can occur when you try to update a document that\u2019s been updated since you read it.</p> <p>Example 4. How Updating May Cause Conflicts</p> <p>Here\u2019s a typical sequence of events that would create an update conflict:</p> <ol> <li>Your code reads the document\u2019s current properties, and constructs a modified copy to save.</li> <li>Another thread (perhaps the replicator) updates the document, creating a new revision with different properties.</li> <li>Your code updates the document with its modified properties, for example using    <code>Collection.save(MutableDocument)</code>.</li> </ol>"},{"location":"handling-data-conflicts/#automatic-conflict-resolution_1","title":"Automatic Conflict Resolution","text":"<p>In Couchbase Lite, by default, the conflict is automatically resolved and only one document update is stored in the database. The Last-Write-Win (LWW) algorithm is used to pick the winning update. So in effect, the changes from step 2 would be overwritten and lost.</p> <p>If the probability of update conflicts is high in your app, and you wish to avoid the possibility of overwritten data, the <code>save()</code> and <code>delete()</code> APIs provide additional method signatures with concurrency control:</p> <p>Save operations</p> <p><code>Collection.save(MutableDocument, ConcurrencyControl)</code> \u2014 attempts to save the document with a concurrency control.</p> <p>The <code>ConcurrencyControl</code> parameter has two possible values:</p> <ul> <li><code>LAST_WRITE_WINS</code> (default): The last operation wins if there is a conflict.</li> <li><code>FAIL_ON_CONFLICT</code>: The operation will fail if there is a conflict.   In this case, the app can detect the error that is being thrown, and handle it by re-reading the document, making the   necessary conflict resolution, then trying again.</li> </ul> <p>Delete operations</p> <p>As with save operations, delete operations also have two method signatures, which specify how to handle a possible conflict:</p> <ul> <li><code>Collection.delete(Document)</code>: The last write will win if   there is a conflict.</li> <li><code>Collection.delete(Document, ConcurrencyControl)</code>: attempts   to delete the document with a concurrency control, with the same options described above.</li> </ul>"},{"location":"handling-data-conflicts/#custom-conflict-handlers","title":"Custom Conflict Handlers","text":"<p>Developers can hook a conflict handler when saving a document, so they can easily handle the conflict in a single save method call.</p> <p>To implement custom conflict resolution when saving a document, apps must call the save method with a conflict handler block (<code>Collection.save(MutableDocument, ConflictHandler)</code>).</p> <p>The following code snippet shows an example of merging properties from the existing document (<code>curDoc</code>) into the one being saved (<code>newDoc</code>). In the event of conflicting keys, it will pick the key value from <code>newDoc</code>.</p> <p>Example 5. Merging document properties</p> <pre><code>val mutableDocument = collection.getDocument(\"xyz\")?.toMutable() ?: return\nmutableDocument.setString(\"name\", \"apples\")\ncollection.save(mutableDocument) { newDoc, curDoc -&gt;\n    if (curDoc == null) {\n        return@save false\n    }\n    val dataMap: MutableMap&lt;String, Any?&gt; = curDoc.toMap().toMutableMap()\n    dataMap.putAll(newDoc.toMap())\n    newDoc.setData(dataMap)\n    true\n}\n</code></pre>"},{"location":"indexing/","title":"Indexing","text":"<p>Couchbase Lite database data model concepts - indexes</p>"},{"location":"indexing/#introduction","title":"Introduction","text":"<p>Querying documents using a pre-existing database index is much faster because an index narrows down the set of documents to examine \u2014 see the Query Troubleshooting topic.</p> <p>When planning the indexes you need for your database, remember that while indexes make queries faster, they may also:</p> <ul> <li>Make writes slightly slower, because each index must be updated whenever a document is updated</li> <li>Make your Couchbase Lite database slightly larger</li> </ul> <p>Too many indexes may hurt performance. Optimal performance depends on designing and creating the right indexes to go along with your queries.</p> <p>Constraints</p> <p>Couchbase Lite does not currently support partial value indexes; indexes with non-property expressions. You should only index with properties that you plan to use in the query.</p>"},{"location":"indexing/#creating-a-new-index","title":"Creating a new index","text":"<p>You can use SQL++ or <code>QueryBuilder</code> syntaxes to create an index.</p> <p>Example 2 creates a new index for the type and name properties, shown in this data model:</p> <p>Example 1. Data Model</p> <pre><code>{\n  \"_id\": \"hotel123\",\n  \"type\": \"hotel\",\n  \"name\": \"The Michigander\",\n  \"overview\": \"Ideally situated for exploration of the Motor City and the wider state of Michigan. Tripadvisor rated the hotel ...\",\n  \"state\": \"Michigan\"\n}\n</code></pre>"},{"location":"indexing/#sql","title":"SQL++","text":"<p>The code to create the index will look something like this:</p> <p>Example 2. Create index</p> <pre><code>collection.createIndex(\n    \"TypeNameIndex\",\n    ValueIndexConfiguration(\"type\", \"name\")\n)\n</code></pre>"},{"location":"indexing/#querybuilder","title":"QueryBuilder","text":"<p>Tip</p> <p>See the QueryBuilder topic to learn more about <code>QueryBuilder</code>.</p> <p>The code to create the index will look something like this:</p> <p>Example 3. Create index with QueryBuilder</p> <pre><code>collection.createIndex(\n    \"TypeNameIndex\",\n    IndexBuilder.valueIndex(\n        ValueIndexItem.property(\"type\"),\n        ValueIndexItem.property(\"name\")\n    )\n)\n</code></pre>"},{"location":"indexing/#partial-index","title":"Partial Index","text":"<p>Couchbase Lite 3.2.2 introduces support for Partial Index - Partial Value and Partial Full-Text Indexes. The Partial Index can create a smaller index, potentially improving index and query performance. You can use Partial Index to specify a <code>WHERE</code> clause in your index configuration. If a where clause is specified, the database will index a document only when the where clause condition is met.</p> <p>Couchbase\u2019s query optimizer uses SQLite\u2019s Partial Index rules about queries using Partial Indexes to determine whether to use partial index in the query or not.</p> <p>Example 4. Couchbase and SQLite\u2019s Partial Index Rules</p> <p>In general, Couchbase Lite follows the two rules, with a modification to the second rule.</p> <p>Below is a summary of the two rules where:</p> <ul> <li><code>X</code> - The expression in the <code>WHERE</code> clause of a given Partial Index.</li> <li><code>W</code> - The expression in the <code>WHERE</code> clause of a given query.</li> </ul> <p>A query can use the Partial Index if the following two rules are satisfied:</p> <ol> <li>If <code>W</code> is AND-connected terms, and <code>X</code> is OR-connected terms and if any terms of <code>W</code> appears as a term of <code>X</code>,    the partial index is allowed to be used.</li> <li>If a term in <code>X</code> is of the form <code>\"z IS NOT MISSING\"</code> and if a term in <code>W</code> is a comparison operator on <code>z</code> other    than <code>\"IS\"</code>, the partial index is allowed to be used. The operators include <code>=</code>, <code>==</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>,    <code>&lt;&gt;</code>, <code>IN</code>, <code>LIKE</code>, and <code>BETWEEN</code>.</li> </ol> <p>Important</p> <p>If <code>X</code> is in the form of <code>\"z is NOT NULL\"</code> or <code>\"z is VALUED\"</code>, the first rule must be satisfied.</p> <p>For example, let the partial index be <code>c IS NOT NULL</code> when creating a partial index on collection named <code>col1</code> in the default scope.</p> <p>Then any query that uses operators <code>=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>&lt;&gt;</code>, <code>IN</code>, <code>LIKE</code>, or <code>BETWEEN</code> on column <code>c</code> would be usable with the partial index, because those comparison operators are only true if <code>c</code> is not <code>NULL</code>.</p> <p>The following query could use the partial index:</p> <pre><code>SELECT * FROM col1 WHERE b=456 AND c&lt;&gt;0;  -- uses partial index\n</code></pre> <p>Whereas the next query can not use the partial index:</p> <pre><code>SELECT * FROM col1 WHERE b=456;  -- cannot use partial index\n</code></pre>"},{"location":"indexing/#partial-value-index","title":"Partial Value Index","text":"<p>Partial Value Index is a form of Partial Index in which a value is used in the <code>WHERE</code> clause and the query is selected by the query optimizer.</p> <pre><code>val config = ValueIndexConfiguration(\"city\").apply {\n    where = \"type = \\\"hotel\\\"\"\n}\ncollection.createIndex(\"HotelCityIndex\", config)\n</code></pre>"},{"location":"indexing/#partial-full-text-index","title":"Partial Full-Text Index","text":"<p>A key difference between a Partial Value Index and a Partial Full-Text Index is that a Partial Full-Text Index is not selected by SQLite\u2019s query optimizer. Instead, it\u2019s explicitly selected by the SQL++ <code>match(indexName, terms)</code> function, which runs a Full-Text Search query using the indexed properties. This means that a Partial Full-Text Index will always be used when the <code>match()</code> function is invoked, regardless of other predicates in the WHERE clause. For details, see Full-Text Search.</p> <pre><code>val config = FullTextIndexConfiguration(\"description\").apply {\n    where = \"type = \\\"hotel\\\"\"\n}\ncollection.createIndex(\"HotelDescIndex\", config)\n</code></pre>"},{"location":"indexing/#array-indexing","title":"Array Indexing","text":"<p>Couchbase Lite 3.2.1 introduces functionality to optimize querying arrays. Array UNNEST to unpack arrays within a document to allow joins with the parent object, and array indexes for indexing unnested array\u2019s values to allow more efficient queries with <code>UNNEST</code>.</p>"},{"location":"indexing/#the-array-index","title":"The Array Index","text":"<p>An array index is a new type of the index for indexing nested array\u2019s properties to allow querying with the <code>UNNEST</code> more efficiently.</p> <p>Below is an example array index configuration:</p> <pre><code>val config: IndexConfiguration = ArrayIndexConfiguration(\"contacts\", \"type\")\n</code></pre>"},{"location":"indexing/#array-index-syntax","title":"Array Index Syntax","text":"<p>The syntax for array index configuration is shown below:</p> Name Is Optional? Description <code>path</code> Path to the array to be indexed. Use <code>[]</code> to represent a property that is an array of each nested array level. For a single array or the last level array, the <code>[]</code> is optional. For instance <code>contacts[].phones</code> to specify an array of phones within each contact. <code>expressions</code> An optional array of strings where each string represents values within the array to be indexed. In N1QL/SQL++ syntax, these expressions are separated by commas. In JSON syntax, as supported by Couchbase Lite for C, the expressions are represented as a JSON array. If the array specified by the path contains scalar values, the expressions should be left unset or set to null."},{"location":"indexing/#using-array-indexes-with-unnest","title":"Using Array Indexes with UNNEST","text":"<p>For the following examples, you can assume we are querying results from the following document, shown below:</p> <pre><code>{\n  \"Name\": \"Sam\",\n  \"contacts\": [\n    {\n      \"type\": \"primary\",\n      \"address\": { \"street\": \"1 St\", \"city\": \"San Pedro\", \"state\": \"CA\" },\n      \"phones\": [\n        { \"type\": \"home\", \"number\": \"310-123-4567\" },\n        { \"type\": \"mobile\", \"number\": \"310-123-6789\" }\n      ]\n    },\n    {\n      \"type\": \"secondary\",\n      \"address\": { \"street\": \"5 St\", \"city\": \"Seattle\", \"state\": \"WA\" },\n      \"phones\": [\n        { \"type\": \"home\", \"number\": \"206-123-4567\" },\n        { \"type\": \"mobile\", \"number\": \"206-123-6789\" }\n      ]\n    }\n  ],\n  \"likes\": [\"soccer\", \"travel\"]\n}\n</code></pre> <p>Using the document above you can perform queries on a single nested array like so:</p> <pre><code>SELECT name, interest FROM _ UNNEST likes as interest WHERE interest = \"travel\"\n</code></pre> <p>The query above produces the following output from the document:</p> <pre><code>{ \"name\": \"Sam\", \"like\": \"travel\" }\n</code></pre> <p>You can also perform the same operation using array indexes like so:</p> <pre><code>collection.createIndex(\"myindex\", ArrayIndexConfiguration(\"likes\"))\n</code></pre> <p>You can perform similar operations on nested arrays:</p> <pre><code>SELECT name, contact.type, phone.number\nFROM profiles\nUNNEST contacts as contact\nUNNEST contact.phones as phone\nWHERE phone.type = \"mobile\"\n</code></pre> <p>The query produces the following output:</p> <pre><code>{ \"name\": \"Sam\", \"type\": \"primary\", \"number\": \"310-123-6789\" }\n{ \"name\": \"Sam\", \"type\": \"secondary\", \"number\": \"206-123-6789\" }\n</code></pre> <p>The output demonstrates retrieval of both primary and secondary contact numbers listed as type <code>\"mobile\"</code>.</p> <p>Here\u2019s an example of creating an array index on a nested array containing dictionary values:</p> <pre><code>collection.createIndex(\n    \"myindex\",\n    ArrayIndexConfiguration(\"contacts[].phones\", \"type\")\n)\n</code></pre> <p>The above snippet creates an array index to allow you to iterate through <code>contacts[].phones[].type</code> in the document, namely <code>\"home\"</code> and <code>\"mobile\"</code>.</p> <p>Important</p> <p>Array literals are not supported in CBL 3.2. Attempting to create a query with array literals will return an error.</p>"},{"location":"installation/","title":"Installation","text":"<p>Add the Kotbase dependency to your Kotlin Multiplatform project in the commonMain source set dependencies of your shared module's build.gradle.kts:</p> Enterprise EditionCommunity Edition build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-ee:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre> build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre> <p>Note</p> <p>The Couchbase Lite Community Edition is free and open source. The Enterprise Edition is free for development and testing, but requires a license from Couchbase for production use. See Community vs Enterprise Edition.</p> <p>Kotbase is published to Maven Central. The Couchbase Lite Enterprise Edition dependency additionally requires the Couchbase Maven repository.</p> Enterprise EditionCommunity Edition build.gradle.kts<pre><code>repositories {\n    mavenCentral()\n    maven(\"https://mobile.maven.couchbase.com/maven2/dev/\")\n}\n</code></pre> build.gradle.kts<pre><code>repositories {\n    mavenCentral()\n}\n</code></pre>"},{"location":"installation/#native-platforms","title":"Native Platforms","text":"<p>Native platform targets should additionally link to the Couchbase Lite dependency native binary. See Supported Platforms for more details.</p>"},{"location":"installation/#linux","title":"Linux","text":"<p>Targeting JVM running on Linux or native Linux, both require a specific version of the libicu dependency. (You will see an error such as <code>libLiteCore.so: libicuuc.so.71: cannot open shared object file: No such file or directory</code> indicating the expected version.) If the required version isn't available from your distribution's package manager, you can download it from GitHub.</p>"},{"location":"installation/#vector-search","title":"Vector Search","text":"<p>This is an Enterprise Edition feature.</p> <p>Enterprise users can also download the Couchbase Lite Vector Search extension library.</p> <p>Note</p> <p>To use Vector Search, you must have Couchbase Lite installed and add the Vector Search extension to your Couchbase Lite application. Vector Search is available only for 64-bit architectures and Intel processors that support the Advanced Vector Extensions 2 (AVX2) instruction set. To verify whether your device supports the AVX2 instructions set, follow these instructions.</p>"},{"location":"installation/#install-extension-libraries","title":"Install Extension Libraries","text":"<p>Install the Vector Search library for each of the platforms your KMP project targets.</p>"},{"location":"installation/#android","title":"Android","text":"build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        ...\n        androidMain.dependencies {\n            // All standard 64-bit ARM architectures\n            implementation(\"com.couchbase.lite:couchbase-lite-android-vector-search-arm64:1.0.0\")\n            // For x86_64 architectures\n            implementation(\"com.couchbase.lite:couchbase-lite-android-vector-search-x86_64:1.0.0\")\n        }\n    }\n}\n</code></pre>"},{"location":"installation/#java","title":"Java","text":"build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        ...\n        jvmMain.dependencies {\n            implementation(\"com.couchbase.lite:couchbase-lite-java-vector-search:1.0.0\")\n        }\n    }\n}\n</code></pre>"},{"location":"installation/#ios-macos","title":"iOS + macOS","text":"Direct DownloadCocoaPodsSwift Package Manager <ol> <li>Download the binaries from here \u2014 binary download link.</li> <li>Unpack the download zip file into your Xcode project location.</li> <li>Select your target settings in Xcode and drag CouchbaseLiteVectorSearch.xcframework from your Finder to the    Frameworks, Libraries, and Embedded Content section.</li> <li>Start using Couchbase Lite Vector Search with Kotbase in your project.</li> </ol> <p>The Kotlin CocoaPods Gradle plugin can be used to generate a Podspec for your project that includes the <code>CouchbaseLiteVectorSearch</code> dependency. Use <code>linkOnly = true</code> to link the dependency without generating Kotlin Objective-C interop:</p> build.gradle.kts<pre><code>plugins {\n    kotlin(\"multiplatform\")\n    kotlin(\"native.cocoapods\")\n}\n\nkotlin {\n    cocoapods {\n        ...\n        pod(\"CouchbaseLiteVectorSearch\", version = \"1.0.0\", linkOnly = true)\n    }\n}\n</code></pre> <p>Note</p> <p>Using Swift Package Manager to install <code>CouchbaseLiteVectorSearch</code> requires Xcode 12+.</p> <p>You can add <code>CouchbaseLiteVectorSearch</code> to your app using Swift Package Manger (SPM).</p> <ol> <li>Open the project to which you are going to <code>add CouchbaseLiteVectorSearch</code></li> <li>Open the Project Editor to add a dependency.<ol> <li>In Project Navigator:    Select your XCode project file (for example, <code>HostApp</code> in the example)    Xcode opens the Project Editor pane</li> <li>In the Project Editor pane:    Select Project &gt; Swift Packages and [+] to add the dependency    Xcode opens the Choose Package Repository dialog</li> <li>In the Choose Package Repository dialog:    Enter the appropriate Couchbase Lite URL, [Next] to continue    For Vector Search: https://github.com/couchbase/couchbase-lite-vector-search-spm.git</li> <li>Enter the required Version (1.0.0) and [Next] to continue</li> <li>[Finish] to close the Choose Package Repository dialog</li> </ol> </li> </ol> <p>Xcode displays the name, version and URL of the added <code>CouchbaseLiteVectorSearch</code> package.</p>"},{"location":"installation/#linux-mingw","title":"Linux + Mingw","text":"<p>Before you can use Vector Search, you must download and install the Vector Search library to the location in your project where the library can be accessed and loaded at run time. The Vector Search extension for the C platform ships with supported prebuilt libraries containing the required dependencies.</p> <p>You need to set the <code>CBLITE_VECTOR_SEARCH_LIB_PATH</code> environment variable to the extension location instead of installing the libraries yourself. If this environment variable is not set, then Kotbase will attempt to find the library in the current directory.</p>"},{"location":"installation/#enable-extension","title":"Enable Extension","text":"<p>Enable the vector search extension using the following snippet:</p> <pre><code>Extension.enableVectorSearch()\n</code></pre> <p>Important</p> <p>You must enable the extension before you open your database.</p>"},{"location":"integrate-custom-listener/","title":"Integrate Custom Listener","text":"<p>Couchbase Lite database peer-to-peer sync \u2014 integrate a custom-built listener</p>"},{"location":"integrate-custom-listener/#overview","title":"Overview","text":"<p>This is an Enterprise Edition feature.</p> <p>This content covers how to integrate a custom <code>MessageEndpointListener</code> solution with Couchbase Lite to handle the data transfer, which is the sending and receiving of data. Where applicable, we discuss how to integrate Couchbase Lite into the workflow.</p> <p>The following sections describe a typical Peer-to-Peer workflow.</p>"},{"location":"integrate-custom-listener/#peer-discovery","title":"Peer Discovery","text":"<p>Peer discovery is the first step. The communication framework will generally include a peer discovery API for devices to advertise themselves on the network and to browse for other peers.</p> <p></p>"},{"location":"integrate-custom-listener/#active-peer","title":"Active Peer","text":"<p>The first step is to initialize the Couchbase Lite database.</p>"},{"location":"integrate-custom-listener/#passive-peer","title":"Passive Peer","text":"<p>In addition to initializing the database, the Passive Peer must initialize the <code>MessageEndpointListener</code>. The <code>MessageEndpointListener</code> acts as a listener for incoming connections.</p> <pre><code>val listener = MessageEndpointListener(\n    MessageEndpointListenerConfiguration(collections, ProtocolType.MESSAGE_STREAM)\n)\n</code></pre>"},{"location":"integrate-custom-listener/#peer-selection-and-connection-setup","title":"Peer Selection and Connection Setup","text":"<p>Once a peer device is found, the application code must decide whether it should establish a connection with that peer. This step includes inviting a peer to a session and peer authentication.</p> <p>This is handled by the Communication Framework.</p> <p></p> <p>Once the remote peer has been authenticated, the next step is to connect with that peer and initialize the <code>MessageEndpoint</code> API.</p>"},{"location":"integrate-custom-listener/#replication-setup","title":"Replication Setup","text":""},{"location":"integrate-custom-listener/#active-peer_1","title":"Active Peer","text":"<p>When the connection is established, the Active Peer must instantiate a <code>MessageEndpoint</code> object corresponding to the remote peer.</p> <pre><code>// The delegate must implement the `MessageEndpointDelegate` protocol.\nval messageEndpoint = MessageEndpoint(\"UID:123\", \"active\", ProtocolType.MESSAGE_STREAM, delegate)\n</code></pre> <p>The <code>MessageEndpoint</code> constructor takes the following arguments:</p> <ol> <li><code>uid</code>: A unique ID that represents the remote Active Peer.</li> <li><code>target</code>: This represents the remote Passive Peer and could be any suitable representation of the remote peer. It    could be an ID, URL, etc. If using the Multipeer Connectivity Framework, this could be the <code>MCPeerID</code>.</li> <li><code>protocolType</code>: Specifies the kind of transport you intend to implement. There are two options:<ul> <li>The default (<code>MESSAGE_STREAM</code>) means that you want to \"send a series of messages\", or in other words the   Communication Framework will control the formatting of messages so that there are clear boundaries between   messages.</li> <li>The alternative (<code>BYTE_STREAM</code>) means that you just want to send raw bytes over the stream and Couchbase should   format for you to ensure that messages get delivered in full.   Typically, the Communication Framework will handle message assembly and disassembly, so you would use the   <code>MESSAGE_STREAM</code> option in most cases.</li> </ul> </li> <li><code>delegate</code>: The delegate that will implement the <code>MessageEndpointDelegate</code> protocol, which is a factory for    <code>MessageEndpointConnection</code>.</li> </ol> <p>Then, a <code>Replicator</code> is instantiated with the initialized <code>MessageEndpoint</code> as the target.</p> <pre><code>// Create the replicator object.\nval repl = Replicator(\n    ReplicatorConfiguration(messageEndpoint)\n        .addCollections(collections)\n)\n\n// Start the replication.\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>Next, Couchbase Lite will call back the application code through the <code>MessageEndpointDelegate</code> lambda. When the application receives the callback, it must create an instance of <code>MessageEndpointConnection</code> and return it.</p> <pre><code>/* implementation of MessageEndpointDelegate */\nval delegate: MessageEndpointDelegate = { endpoint -&gt;\n    ActivePeerConnection()\n}\n</code></pre> <p>Next, Couchbase Lite will call back the application code through the <code>MessageEndpointConnection.open()</code> method.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun open(connection: ReplicatorConnection, completion: MessagingCompletion) {\n    replicatorConnection = connection\n    completion(true, null)\n}\n</code></pre> <p>The connection argument is then set on an instance variable. The application code must keep track of every <code>ReplicatorConnection</code> associated with every <code>MessageEndpointConnection</code>.</p> <p>The <code>MessageError</code> argument in the completion block specifies whether the error is recoverable or not. If it is a recoverable error, the replicator will begin a retry process, creating a new <code>MessageEndpointConnection</code> instance.</p>"},{"location":"integrate-custom-listener/#passive-peer_1","title":"Passive Peer","text":"<p>After connection establishment on the Passive Peer, the first step is to initialize a new <code>MessageEndpointConnection</code> and pass it to the listener. This message tells the listener to accept incoming data from that peer.</p> <pre><code>/* implements MessageEndpointConnection */\nval connection = PassivePeerConnection()\nlistener?.accept(connection)\n</code></pre> <p><code>listener</code> is the instance of the <code>MessageEndpointListener</code> that was created in the first step (Peer Discovery ).</p> <p>Couchbase Lite will call the application code back through the <code>MessageEndpointConnection.open()</code> method.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun open(connection: ReplicatorConnection, completion: MessagingCompletion) {\n    replicatorConnection = connection\n    completion(true, null)\n}\n</code></pre> <p>The connection argument is then set on an instance variable. The application code must keep track of every <code>ReplicatorConnection</code> associated with every <code>MessageEndpointConnection</code>.</p> <p>At this point, the connection is established, and both peers are ready to exchange data.</p>"},{"location":"integrate-custom-listener/#pushpull-replication","title":"Push/Pull Replication","text":"<p>Typically, an application needs to send data and receive data. The directionality of the replication could be any of the following:</p> <ul> <li>Push only: The data is pushed from the local database to the remote database.</li> <li>Pull only: The data is pulled from the remote database to the local database.</li> <li>Push and Pull: The data is exchanged both ways.</li> </ul> <p>Usually, the remote is a Sync Gateway database identified through a URL. In Peer-to-Peer syncing, the remote is another Couchbase Lite database.</p> <p></p> <p>The replication lifecycle is handled through the <code>MessageEndpointConnection</code>.</p>"},{"location":"integrate-custom-listener/#active-peer_2","title":"Active Peer","text":"<p>When Couchbase Lite calls back the application code through the <code>MessageEndpointConnection.send()</code> method, you should send that data to the other peer using the Communication Framework.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun send(message: Message, completion: MessagingCompletion) {\n    /* send the data to the other peer */\n    /* ... */\n    /* call the completion handler once the message is sent */\n    completion(true, null)\n}\n</code></pre> <p>Once the data is sent, call the completion block to acknowledge the completion. You can use the <code>MessageError</code> in the completion block to specify whether the error is recoverable. If it is a recoverable error, the replicator will begin a retry process, creating a new <code>MessageEndpointConnection</code>.</p> <p>When data is received from the Passive Peer via the Communication Framework, you call the <code>ReplicatorConnection.receive()</code> method.</p> <pre><code>replicatorConnection?.receive(message)\n</code></pre> <p>The <code>ReplicatorConnection</code>\u2019s <code>receive()</code> method is called. Which then processes the data to persist to the local database.</p>"},{"location":"integrate-custom-listener/#passive-peer_2","title":"Passive Peer","text":"<p>As in the case of the Active Peer, the Passive Peer must implement the <code>MessageEndpointConnection.send()</code> method to send data to the other peer.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun send(message: Message, completion: MessagingCompletion) {\n    /* send the data to the other peer */\n    /* ... */\n    /* call the completion handler once the message is sent */\n    completion(true, null)\n}\n</code></pre> <p>Once the data is sent, call the completion block to acknowledge the completion. You can use the <code>MessageError</code> in the completion block to specify whether the error is recoverable. If it is a recoverable error, the replicator will begin a retry process, creating a new <code>MessageEndpointConnection</code>.</p> <p>When data is received from the Active Peer via the Communication Framework, you call the <code>ReplicatorConnection.receive()</code> method.</p> <pre><code>replicatorConnection?.receive(message)\n</code></pre>"},{"location":"integrate-custom-listener/#connection-teardown","title":"Connection Teardown","text":"<p>When a peer disconnects from a peer-to-peer network, all connected peers are notified. The disconnect notification is a good opportunity to close and remove a replication connection. The steps to tear down the connection are slightly different depending on whether the active or passive peer disconnects first. We will cover each case below.</p>"},{"location":"integrate-custom-listener/#initiated-by-active-peer","title":"Initiated by Active Peer","text":""},{"location":"integrate-custom-listener/#active-peer_3","title":"Active Peer","text":"<p>When an Active Peer disconnects, it must call the <code>ReplicatorConnection.close()</code> method.</p> <pre><code>fun disconnect() {\n    replicatorConnection?.close(null)\n    replicatorConnection = null\n}\n</code></pre> <p>Then, Couchbase Lite will call back your code through the <code>MessageEndpointConnection.close()</code> to allow the application to disconnect with the Communication Framework.</p> <pre><code>override fun close(error: Exception?, completion: MessagingCloseCompletion) {\n    /* disconnect with communications framework */\n    /* ... */\n    /* call completion handler */\n    completion()\n}\n</code></pre>"},{"location":"integrate-custom-listener/#passive-peer_3","title":"Passive Peer","text":"<p>When the Passive Peer receives the corresponding disconnect notification from the Communication Framework, it must call the <code>ReplicatorConnection.close()</code> method.</p> <pre><code>replicatorConnection?.close(null)\n</code></pre> <p>Then, Couchbase Lite will call back your code through the <code>MessageEndpointConnection.close()</code> to allow the application to disconnect with the Communication Framework.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun close(error: Exception?, completion: MessagingCloseCompletion) {\n    /* disconnect with communications framework */\n    /* ... */\n    /* call completion handler */\n    completion()\n}\n</code></pre>"},{"location":"integrate-custom-listener/#initiated-by-passive-peer","title":"Initiated by Passive Peer","text":""},{"location":"integrate-custom-listener/#passive-peer_4","title":"Passive Peer","text":"<p>When the Passive Peer disconnects, it must class the <code>MessageEndpointListener.closeAll()</code> method.</p> <pre><code>listener?.closeAll()\n</code></pre> <p>Then, Couchbase Lite will call back your code through the <code>MessageEndpointConnection.close()</code> to allow the application to disconnect with the Communication Framework.</p> <pre><code>/* implementation of MessageEndpointConnection */\noverride fun close(error: Exception?, completion: MessagingCloseCompletion) {\n    /* disconnect with communications framework */\n    /* ... */\n    /* call completion handler */\n    completion()\n}\n</code></pre>"},{"location":"integrate-custom-listener/#active-peer_4","title":"Active Peer","text":"<p>When the Active Peer receives the corresponding disconnect notification from the Communication Framework, it must call the <code>ReplicatorConnection.close()</code> method.</p> <pre><code>fun disconnect() {\n    replicatorConnection?.close(null)\n    replicatorConnection = null\n}\n</code></pre> <p>Then, Couchbase Lite will call back your code through the <code>MessageEndpointConnection.close()</code> to allow the application to disconnect with the Communication Framework.</p> <pre><code>override fun close(error: Exception?, completion: MessagingCloseCompletion) {\n    /* disconnect with communications framework */\n    /* ... */\n    /* call completion handler */\n    completion()\n}\n</code></pre>"},{"location":"intra-device-sync/","title":"Intra-device Sync","text":"<p>Couchbase Lite Database Sync - Synchronize changes between databases on the same device</p>"},{"location":"intra-device-sync/#overview","title":"Overview","text":"<p>This is an Enterprise Edition feature.</p> <p>Couchbase Lite supports replication between two local databases at the database, scope, or collection level. This allows a Couchbase Lite replicator to store data on secondary storage. It is useful in scenarios when a user\u2019s device is damaged and its data is moved to a different device.</p> <p>Example 1. Replication between Local Databases</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(DatabaseEndpoint(targetDb))\n        .setType(ReplicatorType.PUSH)\n        .addCollection(srcCollection)\n)\n\n// Start the replicator\nrepl.start()\n// (be sure to hold a reference somewhere that will prevent it from being GCed)\nthis.replicator = repl\n</code></pre>"},{"location":"kermit/","title":"Kermit","text":"<p>Kotbase Kermit is a Couchbase Lite custom logger which logs to Kermit. Kermit can direct its logs to any number of log outputs, including the console.</p>"},{"location":"kermit/#installation","title":"Installation","text":"Enterprise EditionCommunity Edition build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-ee-kermit:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre> build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-kermit:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre>"},{"location":"kermit/#usage","title":"Usage","text":"<pre><code>// Disable default console logs and log to Kermit\nLogSinks.console = ConsoleLogSink(LogLevel.NONE)\nLogSinks.custom = CustomLogSink(LogLevel.WARNING, logSink = KermitCouchbaseLiteLogSink(kermit))\n</code></pre>"},{"location":"kotlin-extensions/","title":"Kotlin Extensions","text":"<p>Couchbase Lite \u2014 Kotlin support</p>"},{"location":"kotlin-extensions/#introduction","title":"Introduction","text":"<p>In addition to implementing the full Couchbase Lite Java SDK API, Kotbase also provides some additional APIs available in the Couchbase Lite Android KTX SDK, which includes a number of Kotlin-specific extensions.</p> <p>This includes:</p> <ul> <li>Change Flows that monitor key Couchbase Lite objects for change using Kotlin features such as, coroutines and Flows.</li> </ul> <p>Note</p> <p>The configuration factory APIs from the Couchbase Lite Android KTX SDK have been deprecated in Kotbase in favor of using constructors directly, which support Kotlin named arguments themselves, or properties can be accessed using the <code>apply</code> scope function. These APIs will be removed in a future release.</p> <p>Additionally, while not available in the Java SDK, as Java doesn't support operator overloading, Kotbase adds support for <code>Fragment</code> subscript APIs, similar to Couchbase Lite Swift, Objective-C, and .NET.</p>"},{"location":"kotlin-extensions/#change-flows","title":"Change Flows","text":"<p>These wrappers use Flows to monitor for changes.</p>"},{"location":"kotlin-extensions/#collection-change-flow","title":"Collection Change Flow","text":"<p>Use the <code>Collection.collectionChangeFlow()</code> to monitor collection change events.</p> In UseDefinition <pre><code>scope.launch {\n    collection.collectionChangeFlow()\n        .map { it.documentIDs }\n        .collect { docIds: List&lt;String&gt; -&gt;\n            // handle changes\n        }\n}\n</code></pre> <pre><code>fun Collection.collectionChangeFlow(\n    coroutineContext: CoroutineContext? = null\n): Flow&lt;CollectionChange&gt;\n</code></pre>"},{"location":"kotlin-extensions/#document-change-flow","title":"Document Change Flow","text":"<p>Use <code>Collection.documentChangeFlow()</code> to monitor changes to a document.</p> In UseDefinition <pre><code>scope.launch {\n    collection.documentChangeFlow(\"1001\")\n        .map { it.collection.getDocument(it.documentID)?.getString(\"lastModified\") }\n        .collect { lastModified: String? -&gt;\n            // handle document changes\n        }\n}\n</code></pre> <pre><code>fun Collection.documentChangeFlow(\n    documentId: String, \n    coroutineContext: CoroutineContext? = null\n): Flow&lt;DocumentChange&gt;\n</code></pre>"},{"location":"kotlin-extensions/#replicator-change-flow","title":"Replicator Change Flow","text":"<p>Use <code>Replicator.replicatorChangeFlow()</code> to monitor replicator changes.</p> In UseDefinition <pre><code>scope.launch {\n    repl.replicatorChangesFlow()\n        .map { it.status.activityLevel }\n        .collect { activityLevel: ReplicatorActivityLevel -&gt;\n            // handle replicator changes\n        }\n}\n</code></pre> <pre><code>fun Replicator.replicatorChangesFlow(\n    coroutineContext: CoroutineContext? = null\n): Flow&lt;ReplicatorChange&gt;\n</code></pre>"},{"location":"kotlin-extensions/#document-replicator-change-flow","title":"Document Replicator Change Flow","text":"<p>Use <code>Replicator.documentReplicationFlow()</code> to monitor document changes during replication.</p> In UseDefinition <pre><code>scope.launch {\n    repl.documentReplicationFlow()\n        .map { it.documents }\n        .collect { docs: List&lt;ReplicatedDocument&gt; -&gt;\n            // handle replicated documents\n        }\n}\n</code></pre> <pre><code>fun Replicator.documentReplicationFlow(\n    coroutineContext: CoroutineContext? = null\n): Flow&lt;DocumentReplication&gt;\n</code></pre>"},{"location":"kotlin-extensions/#query-change-flow","title":"Query Change Flow","text":"<p>Use <code>Query.queryChangeFlow()</code> to monitor changes to a query.</p> In UseDefinition <pre><code>scope.launch {\n    query.queryChangeFlow()\n        .mapNotNull { change -&gt;\n            val err = change.error\n            if (err != null) {\n                throw err\n            }\n            change.results?.allResults()\n        }\n        .collect { results: List&lt;Result&gt; -&gt;\n            // handle query results\n        }\n}\n</code></pre> <pre><code>fun Query.queryChangeFlow(\n    coroutineContext: CoroutineContext? = null\n): Flow&lt;QueryChange&gt;\n</code></pre>"},{"location":"kotlin-extensions/#fragment-subscripts","title":"Fragment Subscripts","text":"<p>Kotbase uses Kotlin's indexed access operator to implement Couchbase Lite's <code>Fragment</code> subscript APIs for <code>Database</code>, <code>Collection</code>, <code>Document</code>, <code>Array</code>, <code>Dictionary</code>, and <code>Result</code>, for concise, type-safe, and null-safe access to arbitrary values in a nested JSON object. <code>MutableDocument</code>, <code>MutableArray</code>, and <code>MutableDictionary</code> also support the <code>MutableFragment</code> APIs for mutating values.</p> <p>Supported types can get <code>Fragment</code> or <code>MutableFragment</code> objects by either index or key. <code>Fragment</code> objects represent an arbitrary entry in a key path, themselves supporting subscript access to nested values.</p> <p>Finally, the typed optional value at the end of a key path can be accessed or set with the <code>Fragment</code> properties, e.g. <code>array</code>, <code>dictionary</code>, <code>string</code>, <code>int</code>, <code>date</code>, etc.</p> <p>Subscript API examples</p> <pre><code>val db = Database(\"db\")\nval coll = db.defaultCollection\nval doc = coll[\"doc-id\"]       // DocumentFragment\ndoc.exists                     // true or false\ndoc.document                   // \"doc-id\" Document from Database\ndoc[\"array\"].array             // Array value from \"array\" key\ndoc[\"array\"][0].string         // String value from first Array item\ndoc[\"dict\"].dictionary         // Dictionary value from \"dict\" key\ndoc[\"dict\"][\"num\"].int         // Int value from Dictionary \"num\" key\ncoll[\"milk\"][\"exp\"].date       // Instant value from \"exp\" key from \"milk\" Document\nval newDoc = MutableDocument(\"new-id\")\nnewDoc[\"name\"].value = \"Sally\" // set \"name\" value\n</code></pre>"},{"location":"ktx/","title":"KTX","text":"<p>The KTX extensions include the excellent Kotlin extensions by MOLO17, as well as other convenience functions for composing queries, mapping query results, creating documents, and observing change <code>Flow</code>s.</p>"},{"location":"ktx/#installation","title":"Installation","text":"Enterprise EditionCommunity Edition build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-ee-ktx:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre> build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-ktx:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre>"},{"location":"ktx/#usage","title":"Usage","text":""},{"location":"ktx/#querybuilder-extensions","title":"QueryBuilder extensions","text":"<p>The syntax for building a query is more straight-forward thanks to Kotlin's <code>infix</code> function support.</p> <pre><code>select(all()) from collection where { \"type\" equalTo \"user\" }\n</code></pre> <p>Or just a bunch of fields:</p> <pre><code>select(\"name\", \"surname\") from collection where { \"type\" equalTo \"user\" }\n</code></pre> <p>Or if you also want the document ID:</p> <pre><code>select(Meta.id, all()) from collection where { \"type\" equalTo \"user\" }\nselect(Meta.id, \"name\", \"surname\") from collection where { \"type\" equalTo \"user\" }\n</code></pre> <p>You can even do more powerful querying:</p> <pre><code>select(\"name\", \"type\")\n    .from(collection)\n    .where {\n        ((\"type\" equalTo \"user\") and (\"name\" equalTo \"Damian\")) or\n        ((\"type\" equalTo \"pet\") and (\"name\" like \"Kitt\"))\n    }\n    .orderBy { \"name\".ascending() }\n    .limit(10)\n</code></pre> <p>There are also convenience extensions for performing <code>SELECT COUNT(*)</code> queries:</p> <pre><code>val query = selectCount() from collection where { \"type\" equalTo \"user\" }\nval count = query.execute().countResult()\n</code></pre>"},{"location":"ktx/#document-builder-dsl","title":"Document builder DSL","text":"<p>For creating a <code>MutableDocument</code> ready to be saved, you can use a Kotlin builder DSL:</p> <pre><code>val document = MutableDocument {\n    \"name\" to \"Damian\"\n    \"surname\" to \"Giusti\"\n    \"age\" to 24\n    \"pets\" to listOf(\"Kitty\", \"Kitten\", \"Kitto\")\n    \"type\" to \"user\"\n}\n\ncollection.save(document)\n</code></pre>"},{"location":"ktx/#collection-creation-functions","title":"Collection creation functions","text":"<p>You can create a <code>MutableArray</code> or <code>MutableDictionary</code> using idiomatic <code>vararg</code> functions:</p> <pre><code>mutableArrayOf(\"hello\", 42, true)\nmutableDictOf(\"key1\" to \"value1\", \"key2\" to 2, \"key3\" to null)\n</code></pre> <p>The similar <code>mutableDocOf</code> function allows nesting dictionary types, unlike the <code>MutableDocument</code> DSL:</p> <pre><code>mutableDocOf(\n    \"string\" to \"hello\",\n    \"number\" to 42,\n    \"array\" to mutableArrayOf(1, 2, 3),\n    \"dict\" to mutableDictOf(\"key\" to \"value\")\n)\n</code></pre>"},{"location":"ktx/#flow-support","title":"Flow support","text":"<p>Supplementing the <code>Flow</code> APIs from Couchbase Lite Android KTX present in the base couchbase-lite modules, Kotbase KTX adds some additional useful <code>Flow</code> APIs.</p>"},{"location":"ktx/#query-flow","title":"Query Flow","text":"<p><code>Query.asFlow()</code> builds on top of <code>Query.queryChangeFlow()</code> to emit non-null <code>ResultSet</code>s and throw any <code>QueryChange</code> errors.</p> <pre><code>select(all())\n    .from(collection)\n    .where { \"type\" equalTo \"user\" }\n    .asFlow()\n    .collect { value: ResultSet -&gt; \n        // consume ResultSet\n    }\n</code></pre>"},{"location":"ktx/#document-flow","title":"Document Flow","text":"<p>Unlike <code>Collection.documentChangeFlow()</code>, which only emits <code>DocumentChange</code>s, <code>Collection.documentFlow()</code> handles the common use case of getting the initial document state and observing changes from the collection, enabling reactive UI patterns.</p> <pre><code>collection.documentFlow(\"userProfile\")\n    .collect { doc: Document? -&gt;\n        // consume Document\n    }\n</code></pre>"},{"location":"ktx/#resultset-model-mapping","title":"ResultSet model mapping","text":""},{"location":"ktx/#map-delegation","title":"Map delegation","text":"<p>Thanks to <code>Map</code> delegation, mapping a <code>ResultSet</code> to a Kotlin class has never been so easy.</p> <p>The library provides the <code>ResultSet.toObjects()</code> and <code>Query.asObjectsFlow()</code> extensions for helping to map results given a factory lambda.</p> <p>Such factory lambdas accept a <code>Map&lt;String, Any?&gt;</code> and return an instance of a certain type. Those requirements fit perfectly with a <code>Map</code>-delegated class.</p> <pre><code>class User(map: Map&lt;String, Any?&gt;) {\n    val name: String by map\n    val surname: String by map\n    val age: Int by map\n}\n\nval users: List&lt;User&gt; = query.execute().toObjects(::User)\n\nval usersFlow: Flow&lt;List&lt;User&gt;&gt; = query.asObjectsFlow(::User)\n</code></pre>"},{"location":"ktx/#json-deserialization","title":"JSON deserialization","text":"<p>Kotbase KTX also provides extensions for mapping documents from a JSON string to Kotlin class. This works well together with a serialization library, like kotlinx-serialization, to decode the JSON string to a Kotlin object.</p> <pre><code>@Serializable\nclass User(\n    val name: String,\n    val surname: String,\n    val age: Int\n)\n\nval users: List&lt;User&gt; = query.execute().toObjects { json: String -&gt;\n    Json.decodeFromString&lt;User&gt;(json)\n}\n\nval usersFlow: Flow&lt;List&lt;User&gt;&gt; = query.asObjectsFlow { json: String -&gt;\n    Json.decodeFromString&lt;User&gt;(json)\n}\n</code></pre>"},{"location":"ktx/#replicator-extensions","title":"Replicator extensions","text":"<p>For the Android platform, you can bind the <code>Replicator</code> <code>start()</code> and <code>stop()</code> methods to be performed automatically when your <code>Lifecycle</code>-enabled component gets resumed or paused.</p> <pre><code>// Binds the Replicator to the Application lifecycle.\nreplicator.bindToLifecycle(ProcessLifecycleOwner.get().lifecycle)\n</code></pre> <pre><code>// Binds the Replicator to the Activity/Fragment lifecycle.\n// inside an Activity or Fragment...\noverride fun onCreate(savedInstanceState: Bundle?) {\n    replicator.bindToLifecycle(lifecycle)\n}\n</code></pre> <p>That's it! The <code>Replicator</code> will be automatically started when your component passes the <code>ON_RESUME</code> state, and it will be stopped when the component passes the <code>ON_PAUSED</code> state. As you may imagine, no further action will be made after the <code>ON_DESTROY</code> state.</p>"},{"location":"legacy-logging-api/","title":"Legacy Logging API","text":"<p>Couchbase Lite \u2014 Using Logs for Troubleshooting</p> <p>Constraints</p> <p>The retrieval of logs from the device is out of scope of this feature.</p>"},{"location":"legacy-logging-api/#introduction","title":"Introduction","text":"<p>Couchbase Lite provides a robust Logging API \u2014 see API References for <code>Log</code>, <code>FileLogger</code>, and <code>LogFileConfiguration</code> \u2014 which make debugging and troubleshooting easier during development and in production. It delivers flexibility in terms of how logs are generated and retained, whilst also maintaining the level of logging required by Couchbase Support for investigation of issues.</p> <p>Log output is split into the following streams:</p> <ul> <li>Console based logging   You can independently configure and control console logs, which provides a convenient method of accessing diagnostic   information during debugging scenarios. With console logging, you can fine-tune diagnostic output to suit specific   debug scenarios and capture them for Couchbase Support for the investigation of issues.</li> <li>File based logging   Here logs are written to separate log files, filtered by log level, with each log level supporting individual   retention policies.</li> <li>Custom logging   For greater flexibility you can implement a custom logging class using the <code>Logger</code> interface.</li> </ul> <p>In all instances, you control what is logged and at what level using the <code>Log</code> class.</p>"},{"location":"legacy-logging-api/#console-based-logging","title":"Console based logging","text":"<p>Console based logging is often used to facilitate troubleshooting during development.</p> <p>Console logs are your go-to resource for diagnostic information. You can easily fine-tune their diagnostic content to meet the needs of a particular debugging scenario, perhaps by increasing the verbosity and-or choosing to focus on messages from a specific domain; to better focus on the problem area.</p> <p>Changes to console logging are independent of file logging, so you can make changes without compromising any file logging streams. It is enabled by default. To change default settings use the <code>Database.log</code> property to set the required values \u2014 see Example 1 .</p> <p>You will primarily use <code>log.console</code> and <code>ConsoleLogger</code> to control console logging.</p> <p>Example 1. Change Console Logging Settings</p> <p>This example enables and defines console-based logging settings.</p> <pre><code>Database.log.console.domains = LogDomain.ALL_DOMAINS\nDatabase.log.console.level = LogLevel.VERBOSE\n</code></pre> <ol> <li>Define the required domain; here we turn on logging for all available domains \u2014 see <code>ConsoleLogger.domains</code> and enum <code>LogDomain</code>.</li> <li>Here we turn on the most verbose log level \u2014 see <code>ConsoleLogger.level</code> and enum <code>LogLevel</code>.    To disable logging for the specified <code>LogDomain</code>s set the <code>LogLevel</code> to <code>NONE</code>.</li> </ol>"},{"location":"legacy-logging-api/#file-based-logging","title":"File based logging","text":"<p>File based logging is disabled by default \u2014 see Example 2 for how to enable it.</p> <p>You will primarily use <code>Log.file</code> and <code>FileLogger</code> to control file-based logging.</p>"},{"location":"legacy-logging-api/#formats","title":"Formats","text":"<p>Available file based logging formats:</p> <ul> <li>Binary \u2014 most efficient for storage and performance. It is the default for file based logging.&lt;br.   Use this format and a decoder, such as cbl-log, to view them \u2014 see Decoding binary logs.</li> <li>Plaintext</li> </ul>"},{"location":"legacy-logging-api/#configuration","title":"Configuration","text":"<p>As with console logging you can set the log level \u2014 see the <code>FileLogger</code> class.</p> <p>With file based logging you can also use the <code>LogFileConfiguration</code> class\u2019s properties to specify the:</p> <ul> <li>Path to the directory to store the log files</li> <li>Log file format   The default is binary. You can override that where necessary and output a plain text log.</li> <li>Maximum number of rotated log files to keep</li> <li>Maximum size of the log file (bytes). Once this limit is exceeded a new log file is started.</li> </ul> <p>Example 2. Enabling file logging</p> <pre><code>Database.log.file.apply {\n    config = LogFileConfiguration(directory = \"temp/cbl-logs\").apply {\n        maxSize = 10240\n        maxRotateCount = 5\n        usesPlaintext = false\n    }\n    level = LogLevel.INFO\n}\n</code></pre> <ol> <li>Set the log file directory</li> <li>Change the max rotation count from the default (1) to 5 Note this means six files may exist at any one time; the five rotated log files, plus the active log file</li> <li>Set the maximum size (bytes) for our log file</li> <li>Select the binary log format (included for reference only as this is the default)</li> <li>Increase the log output level from the default (<code>WARNING</code>) to <code>INFO</code> \u2014 see <code>FileLogger.level</code></li> </ol> <p>Tip</p> <p><code>\"temp/cbl-logs\"</code> might be a platform-specific location. Use <code>expect</code>/<code>actual</code> or dependency injection to provide a platform-specific log file path.</p>"},{"location":"legacy-logging-api/#custom-logging","title":"Custom logging","text":"<p>Couchbase Lite allows for the registration of a callback function to receive Couchbase Lite log messages, which may be logged using any external logging framework.</p> <p>To do this, apps must implement the <code>Logger</code> interface \u2014 see Example 3  \u2014 and enable custom logging using <code>Log.custom</code> \u2014 see Example 4.</p> <p>Example 3. Implementing logger interface</p> <p>Here we introduce the code that implements the <code>Logger</code> interface.</p> <pre><code>class LogTestLogger(override val level: LogLevel) : Logger {\n    override fun log(level: LogLevel, domain: LogDomain, message: String) {\n        // this method will never be called if param level &lt; this.level\n        // handle the message, for example piping it to a third party framework\n    }\n}\n</code></pre> <p>Example 4. Enabling custom logging</p> <p>This example show how to enable the custom logger from Example 3.</p> <pre><code>// this custom logger will not log an event with a log level &lt; WARNING\nDatabase.log.custom = LogTestLogger(LogLevel.WARNING) \n</code></pre> <p>Here we set the custom logger with a level of <code>WARNING</code>. The custom logger is called with every log and may choose to filter it, using its configured level.</p>"},{"location":"legacy-logging-api/#decoding-binary-logs","title":"Decoding binary logs","text":"<p>You can use the cbl-log tool to decode binary log files \u2014 see Example 5.</p> <p>Example 5. Using the cbl-log tool</p> macOSCentOSWindows <p>Download the cbl-log tool using <code>wget</code>.</p> console<pre><code>wget https://packages.couchbase.com/releases/couchbase-lite-log/3.0.0/couchbase-lite-log-3.0.0-macos.zip\n</code></pre> <p>Extract the downloaded zip file.</p> console<pre><code>unzip couchbase-lite-log-3.0.0-macos.zip\n</code></pre> <p>Navigate to the bin directory and run the <code>cbl-log</code> executable.</p> console<pre><code>./cbl-log logcat LOGFILE &lt;OUTPUT_PATH&gt;\n</code></pre> <p>Download the cbl-log tool using <code>wget</code>.</p> console<pre><code>wget https://packages.couchbase.com/releases/couchbase-lite-log/3.0.0/couchbase-lite-log-3.0.0-centos.zip\n</code></pre> <p>Extract the downloaded zip file.</p> console<pre><code>unzip couchbase-lite-log-3.0.0-centos.zip\n</code></pre> <p>Navigate to the bin directory and run the <code>cbl-log</code> executable.</p> console<pre><code>./cbl-log logcat LOGFILE &lt;OUTPUT_PATH&gt;\n</code></pre> <p>Download the cbl-log tool using PowerShell.</p> PowerShell<pre><code>Invoke-WebRequest https://packages.couchbase.com/releases/couchbase-lite-log/3.0.0/couchbase-lite-log-3.0.0-windows.zip -OutFile couchbase-lite-log-3.0.0-windows.zip\n</code></pre> <p>Extract the downloaded zip file.</p> PowerShell<pre><code>Expand-Archive -Path couchbase-lite-log-3.0.0-windows.zip -DestinationPath .\n</code></pre> <p>Run the cbl-log executable.</p> PowerShell<pre><code>.\\cbl-log.exe logcat LOGFILE &lt;OUTPUT_PATH&gt;\n</code></pre>"},{"location":"license/","title":"License","text":"<p>Copyright 2022-2024 Jeff Lockhart</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <p> http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"license/#third-party-licenses","title":"Third Party Licenses","text":"<ul> <li>AndroidX</li> <li>Couchbase Lite</li> <li>Dokka</li> <li>Kermit</li> <li>KorIO</li> <li>Kotlin</li> <li>kotlinx-atomicfu</li> <li>kotlinx-binary-compatibility-validator</li> <li>kotlinx-coroutines</li> <li>kotlinx-datetime</li> <li>kotlinx-io</li> <li>kotlinx-serialization</li> <li>Material for MkDocs</li> <li>Mike</li> <li>MkDocs</li> <li>MkDocs Macros Plugin</li> <li>MockK</li> <li>MOLO17 Couchbase Lite Kotlin</li> <li>Stately</li> <li>vanniktech gradle-maven-publish-plugin</li> </ul>"},{"location":"live-queries/","title":"Live Queries","text":"<p>Couchbase Lite database data querying concepts \u2014 live queries</p>"},{"location":"live-queries/#activating-a-live-query","title":"Activating a Live Query","text":"<p>A live query is a query that, once activated, remains active and monitors the database for changes; refreshing the result set whenever a change occurs. As such, it is a great way to build reactive user interfaces \u2014 especially table/list views \u2014 that keep themselves up to date.</p> <p>So, a simple use case may be: A replicator running and pulling new data from a server, whilst a live-query-driven UI automatically updates to show the data without the user having to manually refresh. This helps your app feel quick and responsive.</p> <p>To activate a live query, just add a change listener to the query statement. It will be immediately active. When a change is detected the query automatically runs, and posts the new query result to any observers (change listeners).</p> <p>Example 1. Starting a Live Query</p> <pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection)) \n\n// Adds a query change listener.\n// Changes will be posted on the main queue.\nval token = query.addChangeListener { change -&gt;\n    change.results?.let { rs -&gt;\n        rs.forEach {\n            println(\"results: ${it.keys}\")\n            /* Update UI */\n        }\n    } \n}\n</code></pre> <ol> <li>Build the query statements.</li> <li>Activate the live query by attaching a listener. Save the token in order to detach the listener and stop the query    later \u2014 see Example 2.</li> </ol> <p>Example 2. Stop a Live Query</p> <pre><code>token.remove()\n</code></pre> <p>Here we use the change lister token from Example 1 to remove the listener. Doing so stops the live query.</p>"},{"location":"live-queries/#using-kotlin-flows","title":"Using Kotlin Flows","text":"<p>Kotlin developers also have the option of using <code>Flow</code>s to feed query changes to the UI.</p> <p>Define a live query as a <code>Flow</code> and activate a collector in the view creation function.</p> <pre><code>fun watchQuery(query: Query): Flow&lt;List&lt;Result&gt;&gt; {\n    return query.queryChangeFlow()\n        .mapNotNull { change -&gt;\n            val err = change.error\n            if (err != null) {\n               throw err\n            }\n            change.results?.allResults()\n        }\n}\n</code></pre>"},{"location":"n1ql-query-builder-differences/","title":"SQL++ QueryBuilder Differences","text":"<p>Differences between Couchbase Lite\u2019s QueryBuilder and SQL++ for Mobile</p> <p>Couchbase Lite\u2019s SQL++ for Mobile supports all QueryBuilder features, except Predictive Query and Index. See Table 1 for the features supported by SQL++ but not by QueryBuilder.</p> <p>Table 1. QueryBuilder Differences</p> Category Components Conditional Operator <code>CASE(WHEN \u2026 THEN \u2026 ELSE \u2026)</code> Array Functions <code>ARRAY_AGG</code> <code>ARRAY_AVG</code> <code>ARRAY_COUNT</code> <code>ARRAY_IFNULL</code> <code>ARRAY_MAX</code> <code>ARRAY_MIN</code> <code>ARRAY_SUM</code> Conditional Functions <code>IFMISSING</code> <code>IFMISSINGORNULL</code> <code>IFNULL</code> <code>MISSINGIF</code> <code>NULLIF</code> <code>Match</code> <code>Functions</code> <code>DIV</code> <code>IDIV</code> <code>ROUND_EVEN</code> Pattern Matching Functions <code>REGEXP_CONTAINS</code> <code>REGEXP_LIKE</code> <code>REGEXP_POSITION</code> <code>REGEXP_REPLACE</code> Type Checking Functions <code>ISARRAY</code> <code>ISATOM</code> <code>ISBOOLEAN</code> <code>ISNUMBER</code> <code>ISOBJECT</code> <code>ISSTRING</code> <code>TYPE</code> Type Conversion Functions <code>TOARRAY</code> <code>TOATOM</code> <code>TOBOOLEAN</code> <code>TONUMBER</code> <code>TOOBJECT</code> <code>TOSTRING</code>"},{"location":"n1ql-query-strings/","title":"SQL++ Query Strings","text":"<p>How to use SQL++ query strings to build effective queries with Kotbase</p> <p>Note</p> <p>The examples used in this topic are based on the Travel Sample app and data introduced in the Couchbase Mobile Workshop tutorial.</p>"},{"location":"n1ql-query-strings/#introduction","title":"Introduction","text":"<p>Developers using Kotbase can provide SQL++ query strings using the SQL++ Query API. This API uses query statements of the form shown in Example 2.</p> <p>The structure and semantics of the query format are based on that of Couchbase Server\u2019s SQL++ query language \u2014 see SQL++ Reference Guide and SQL++ Data Model.</p>"},{"location":"n1ql-query-strings/#running","title":"Running","text":"<p>The database can create a query object with the SQL++ string. See Query Result Sets for how to work with result sets.</p> <p>Example 1. Running a SQL++ Query</p> <pre><code>val query = database.createQuery(\n    \"SELECT META().id AS id FROM _ WHERE type = \\\"hotel\\\"\"\n)\nreturn query.execute().use { rs -&gt; rs.allResults() }\n</code></pre> <p>We are accessing the current database using the shorthand notation <code>_</code> \u2014 see the <code>FROM</code> clause for more on data source selection and Query Parameters for more on parameterized queries.</p>"},{"location":"n1ql-query-strings/#query-format","title":"Query Format","text":"<p>The API uses query statements of the form shown in Example 2.</p> <p>Example 2. Query Format</p> <pre><code>SELECT ____\nFROM 'data-source'\nWHERE ____,\nJOIN ____\nGROUP BY ____\nORDER BY ____\nLIMIT ____\nOFFSET ____\n</code></pre> <p>Query Components</p> Component Description SELECT statement The document properties that will be returned in the result set FROM The data source to be queried WHERE statement The query criteriaThe <code>SELECT</code>ed properties of documents matching this criteria will be returned in the result set JOIN statement The criteria for joining multiple documents GROUP BY statement The criteria used to group returned items in the result set ORDER BY statement The criteria used to order the items in the result set LIMIT statement The maximum number of results to be returned OFFSET statement The number of results to be skipped before starting to return results <p>Tip</p> <p>We recommend working through the SQL++ Tutorials to build your SQL++ skills.</p>"},{"location":"n1ql-query-strings/#select-statement","title":"SELECT statement","text":""},{"location":"n1ql-query-strings/#purpose","title":"Purpose","text":"<p>Projects the result returned by the query, identifying the columns it will contain.</p>"},{"location":"n1ql-query-strings/#syntax","title":"Syntax","text":"<p>Example 3. SQL++ Select Syntax</p> <pre><code>select = SELECT _ ( DISTINCT | ALL )? selectResult\n\nselectResults = selectResult ( _ ',' _ selectResult )*\n\nselectResult = expression ( _ (AS)? columnAlias )?\n\ncolumnAlias = IDENTIFIER\n</code></pre>"},{"location":"n1ql-query-strings/#arguments","title":"Arguments","text":"<ol> <li>The select clause begins with the <code>SELECT</code> keyword.<ul> <li>The optional <code>ALL</code> argument is used to specify that the query should return ALL results (the default).</li> <li>The optional <code>DISTINCT</code> argument specifies that the query should remove duplicated results.</li> </ul> </li> <li><code>selectResults</code> is a list of columns projected in the query result. Each column is an expression which could be a    property expression or any expressions or functions. You can use the wildcard <code>*</code> to select all columns \u2014 see Select    Wildcard.</li> <li>Use the optional <code>AS</code> argument to provide an alias name for a property. Each property can be aliased by putting the    <code>AS &lt;alias name&gt;</code> after the column name.</li> </ol>"},{"location":"n1ql-query-strings/#select-wildcard","title":"Select Wildcard","text":"<p>When using the <code>SELECT *</code> option the column name (key) of the SQL++ string is one of:</p> <ul> <li>The alias name if one was specified</li> <li>The data source name (or its alias if provided) as specified in the <code>FROM</code> clause.</li> </ul> <p>This behavior is inline with that of Couchbase Server SQL++ \u2014 see example in Table 1.</p> <p>Table 1. Example Column Names for SELECT *</p> Query Column Name <code>SELECT * AS data FROM _</code> <code>data</code> <code>SELECT * FROM _</code> <code>_</code> <code>SELECT * FROM _default</code> <code>_default</code> <code>SELECT * FROM db</code> <code>db</code> <code>SELECT * FROM db AS store</code> <code>store</code>"},{"location":"n1ql-query-strings/#example","title":"Example","text":"<p>Example 4. SELECT properties</p> <pre><code>SELECT *\n\nSELECT db.* AS data\n\nSELECT name fullName\n\nSELECT db.name fullName\n\nSELECT DISTINCT address.city\n</code></pre> <ol> <li>Use the <code>*</code> wildcard to select all properties.</li> <li>Select all properties from the <code>db</code> data source. Give the object an alias name of <code>data</code>.</li> <li>Select a pair of properties.</li> <li>Select a specific property from the db data source.</li> <li>Select the property item <code>city</code> from its parent property <code>address</code>.</li> </ol> <p>See Query Result Sets for more on processing query results.</p>"},{"location":"n1ql-query-strings/#from","title":"FROM","text":""},{"location":"n1ql-query-strings/#purpose_1","title":"Purpose","text":"<p>Specifies the data source, or sources, and optionally applies an alias (<code>AS</code>). It is mandatory.</p>"},{"location":"n1ql-query-strings/#syntax_1","title":"Syntax","text":"<pre><code>FROM dataSource\n      (optional JOIN joinClause )\n</code></pre>"},{"location":"n1ql-query-strings/#datasource","title":"Datasource","text":"<p>A datasource can be:</p> <ul> <li>&lt; database-name &gt; : default collection</li> <li>_ (underscore) : default collection</li> <li>&lt; scope-name &gt;.&lt; collection-name &gt; : a collection in a scope</li> <li>&lt; collection-name &gt; : a collection in the default scope</li> </ul>"},{"location":"n1ql-query-strings/#arguments_1","title":"Arguments","text":"<ol> <li>Here <code>dataSource</code> is the database name against which the query is to run or the .. Use <code>AS</code> to    give the database an alias you can use within the query.    To use the current database, without specifying a name, use <code>_</code> as the datasource. <li><code>JOIN joinclause</code> \u2014 use this optional argument to link data sources \u2014 see <code>JOIN</code> statement.</li>"},{"location":"n1ql-query-strings/#example_1","title":"Example","text":"<p>Example 5. FROM clause</p> <pre><code>SELECT name FROM db\nSELECT name FROM scope.collection\nSELECT store.name FROM db AS store\nSELECT store.name FROM db store\nSELECT name FROM _\nSELECT store.name FROM _ AS store\nSELECT store.name FROM _ store\n</code></pre>"},{"location":"n1ql-query-strings/#join-statement","title":"JOIN statement","text":""},{"location":"n1ql-query-strings/#purpose_2","title":"Purpose","text":"<p>The <code>JOIN</code> clause enables you to select data from multiple data sources linked by criteria specified in the <code>JOIN</code> statement.</p> <p>Currently only self-joins are supported. For example to combine airline details with route details, linked by the airline id \u2014 see Example 6.</p>"},{"location":"n1ql-query-strings/#syntax_2","title":"Syntax","text":"<pre><code>joinClause = ( join )*\n\njoin = joinOperator _ dataSource _  (constraint)?\n\njoinOperator = ( LEFT (OUTER)? | INNER | CROSS )? JOIN\n\ndataSource = databaseName ( ( AS | _ )? databaseAlias )?\n\nconstraint ( ON expression )?\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_2","title":"Arguments","text":"<ol> <li>The join clause starts with a <code>JOIN</code> operator followed by the data source.</li> <li>Five <code>JOIN</code> operators are supported: <code>JOIN</code>, <code>LEFT JOIN</code>, <code>LEFT OUTER JOIN</code>, <code>INNER JOIN</code>, and <code>CROSS JOIN</code>.    Note: <code>JOIN</code> and <code>INNER JOIN</code> are the same, <code>LEFT JOIN</code> and <code>LEFT OUTER JOIN</code> are the same.</li> <li>The join constraint starts with the <code>ON</code> keyword followed by the expression that defines the joining constraints.</li> </ol>"},{"location":"n1ql-query-strings/#example_2","title":"Example","text":"<pre><code>SELECT db.prop1, other.prop2 FROM db JOIN db AS other ON db.key = other.key\n\nSELECT db.prop1, other.prop2 FROM db LEFT JOIN db other ON db.key = other.key\n\nSELECT * FROM route r JOIN airline a ON r.airlineid = meta(a).id WHERE a.country = \"France\"\n</code></pre> <p>Example 6. Using JOIN to Combine Document Details</p> <p>This example JOINS the document of type <code>route</code> with documents of type <code>airline</code> using the document ID (<code>_id</code>) on the airline document and <code>airlineid</code> on the route document.</p> <pre><code>SELECT * FROM travel-sample r JOIN travel-sample a ON r.airlineid = a.meta.id WHERE a.country = \"France\"\n</code></pre>"},{"location":"n1ql-query-strings/#array-unnest","title":"Array UNNEST","text":""},{"location":"n1ql-query-strings/#purpose_3","title":"Purpose","text":"<p>You can use <code>UNNEST</code> in queries to unpack arrays within a document into individual rows. This functionality makes it possible to join them with its parent object in the query.</p> <p><code>UNNEST</code> is used within the <code>FROM</code> clause and can be chained to perform multi-level <code>UNNEST</code>.</p> <p>You can also use a new type of index, the Array Index, to allow querying with <code>UNNEST</code> more efficiently.</p> <p>Note</p> <p>Couchbase Lite currently supports inner <code>UNNEST</code> only.</p>"},{"location":"n1ql-query-strings/#syntax_3","title":"Syntax","text":"<p>The syntax for <code>UNNEST</code> is shown below:</p> <pre><code>unnestClause = UNNEST expr ( \u2018AS\u2019? alias)?\n</code></pre> <p>Caution</p> <p><code>\"unnest\"</code> will be defined as a new keyword in the SQL++ syntax. You cannot use the term as an identifier for a property name or data source unless you escape it using backticks.</p>"},{"location":"n1ql-query-strings/#examples","title":"Examples","text":"<p>For examples of using Array Indexes in conjunction with <code>UNNEST</code>, see Array Index.</p> <p>We are also accessing the current database using the shorthand notation <code>_</code> \u2014 see the FROM clause for more on data source selection and Query Parameters for more on parameterized queries.</p> <p>The following examples will use the example JSON document below to query results from:</p> <pre><code>{\n  \"Name\": \"Sam\",\n  \"contacts\": [\n    {\n      \"type\": \"primary\",\n      \"address\": { \"street\": \"1 St\", \"city\": \"San Pedro\", \"state\": \"CA\" },\n      \"phones\": [\n        { \"type\": \"home\", \"number\": \"310-123-4567\" },\n        { \"type\": \"mobile\", \"number\": \"310-123-6789\" }\n      ]\n    },\n    {\n      \"type\": \"secondary\",\n      \"address\": { \"street\": \"5 St\", \"city\": \"Seattle\", \"state\": \"WA\" },\n      \"phones\": [\n        { \"type\": \"home\", \"number\": \"206-123-4567\" },\n        { \"type\": \"mobile\", \"number\": \"206-123-6789\" }\n      ]\n    }\n  ],\n  \"likes\": [\"soccer\", \"travel\"]\n}\n</code></pre> <p>Using the document above we can perform queries on a single nested array like so:</p> <pre><code>SELECT name, interest FROM _ UNNEST likes as interest WHERE interest = \"travel\"\n</code></pre> <p>The query above will produce the following output from the document:</p> <pre><code>{ \"name\": \"Sam\", \"like\": \"travel\" }\n</code></pre> <p>You can perform similar operations on nested arrays:</p> <pre><code>SELECT name, contact.type, phone.number\nFROM profiles\nUNNEST contacts as contact\nUNNEST contact.phones as phone\nWHERE phone.type = \"mobile\"\n</code></pre> <p>The query above will then produce the following output:</p> <pre><code>{ \"name\": \"Sam\", \"type\": \"primary\", \"number\": \"310-123-6789\" }\n{ \"name\": \"Sam\", \"type\": \"secondary\", \"number\": \"206-123-6789\" }\n</code></pre> <p>The output demonstrates retrieval of both primary and secondary contact numbers listed as type <code>\"mobile\"</code>.</p> <p>Important</p> <p>Array literals are not supported in CBL 3.2. Attempting to create a query with array literals will return an error.</p>"},{"location":"n1ql-query-strings/#where-statement","title":"WHERE statement","text":""},{"location":"n1ql-query-strings/#purpose_4","title":"Purpose","text":"<p>Specifies the selection criteria used to filter results.</p> <p>As with SQL, use the <code>WHERE</code> statement to choose which documents are returned by your query.</p>"},{"location":"n1ql-query-strings/#syntax_4","title":"Syntax","text":"<pre><code>where = WHERE expression\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_3","title":"Arguments","text":"<p><code>WHERE</code> evaluates <code>expression</code> to a <code>BOOLEAN</code> value. You can chain any number of expressions in order to implement sophisticated filtering capabilities.</p> <p>See also \u2014 Operators for more on building expressions and Query Parameters for more on parameterized queries.</p>"},{"location":"n1ql-query-strings/#examples_1","title":"Examples","text":"<pre><code>SELECT name FROM db WHERE department = 'engineer' AND group = 'mobile'\n</code></pre>"},{"location":"n1ql-query-strings/#group-by-statement","title":"GROUP BY statement","text":""},{"location":"n1ql-query-strings/#purpose_5","title":"Purpose","text":"<p>Use <code>GROUP BY</code> to arrange values in groups of one or more properties.</p>"},{"location":"n1ql-query-strings/#syntax_5","title":"Syntax","text":"<pre><code>groupBy = grouping _( having )?\n\ngrouping = GROUP BY expression( _ ',' _ expression )*\n\nhaving = HAVING expression\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_4","title":"Arguments","text":"<ol> <li>The group by clause starts with the <code>GROUP BY</code> keyword followed by one or more expressions.</li> <li><code>grouping</code> \u2014 the group by clause is normally used together with the aggregate functions (e.g. <code>COUNT</code>, <code>MAX</code>, <code>MIN</code>,    <code>SUM</code>, <code>AVG</code>).</li> <li><code>having</code> \u2014 allows you to filter the result based on aggregate functions \u2014 for example, <code>HAVING count(empnum)&gt;100</code>.</li> </ol>"},{"location":"n1ql-query-strings/#examples_2","title":"Examples","text":"<pre><code>SELECT COUNT(empno), city FROM db GROUP BY city\n\nSELECT COUNT(empno), city FROM db GROUP BY city HAVING COUNT(empno) &gt; 100\n\nSELECT COUNT(empno), city FROM db GROUP BY city HAVING COUNT(empno) &gt; 100 WHERE state = 'CA'\n</code></pre>"},{"location":"n1ql-query-strings/#order-by-statement","title":"ORDER BY statement","text":""},{"location":"n1ql-query-strings/#purpose_6","title":"Purpose","text":"<p>Sort query results based on a given expression result.</p>"},{"location":"n1ql-query-strings/#syntax_6","title":"Syntax","text":"<pre><code>orderBy = ORDER BY ordering ( _ ',' _ ordering )*\n\nordering = expression ( _ order )?\n\norder = ( ASC / DESC )\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_5","title":"Arguments","text":"<ol> <li><code>orderBy</code> \u2014 The order by clause starts with the <code>ORDER BY</code> keyword followed by the ordering clause.</li> <li><code>ordering</code> \u2014 The ordering clause specifies the properties or expressions to use for ordering the results.</li> <li><code>order</code> \u2014 In each ordering clause, the sorting direction is specified using the optional <code>ASC</code> (ascending) or <code>DESC</code>    (descending) directives. Default is <code>ASC</code>.</li> </ol>"},{"location":"n1ql-query-strings/#examples_3","title":"Examples","text":"<p>Example 7. Simple usage</p> <pre><code>SELECT name FROM db  ORDER BY name\n\nSELECT name FROM db  ORDER BY name DESC\n\nSELECT name, score FROM db  ORDER BY name ASC, score DESC\n</code></pre>"},{"location":"n1ql-query-strings/#limit-statement","title":"LIMIT statement","text":""},{"location":"n1ql-query-strings/#purpose_7","title":"Purpose","text":"<p>Specifies the maximum number of results to be returned by the query.</p>"},{"location":"n1ql-query-strings/#syntax_7","title":"Syntax","text":"<pre><code>limit = LIMIT expression\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_6","title":"Arguments","text":"<p>The limit clause starts with the <code>LIMIT</code> keyword followed by an expression that will be evaluated as a number.</p>"},{"location":"n1ql-query-strings/#examples_4","title":"Examples","text":"<p>Example 8. Simple usage</p> <pre><code>SELECT name FROM db LIMIT 10\n</code></pre> <p>Return only 10 results</p>"},{"location":"n1ql-query-strings/#offset-statement","title":"OFFSET statement","text":""},{"location":"n1ql-query-strings/#purpose_8","title":"Purpose","text":"<p>Specifies the number of results to be skipped by the query.</p>"},{"location":"n1ql-query-strings/#syntax_8","title":"Syntax","text":"<pre><code>offset = OFFSET expression\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_7","title":"Arguments","text":"<p>The offset clause starts with the <code>OFFSET</code> keyword followed by an expression that will be evaluated as a number that represents the number of results ignored before the query begins returning results.</p>"},{"location":"n1ql-query-strings/#examples_5","title":"Examples","text":"<p>Example 9. Simple usage</p> <pre><code>SELECT name FROM db OFFSET 10\n\nSELECT name FROM db  LIMIT 10 OFFSET 10\n</code></pre> <ol> <li>Ignore first 10 results</li> <li>Ignore first 10 results then return the next 10 results</li> </ol>"},{"location":"n1ql-query-strings/#expressions","title":"Expressions","text":"<p>In this section Literals | Identifiers | Property Expressions | Any and Every Expressions | Parameter Expressions | Parenthesis Expressions</p> <p>Expressions are references to identifiers that resolve to values. Categories of expression comprise the elements covered in this section (see above), together with Operators and Functions, which are covered in their own sections.</p>"},{"location":"n1ql-query-strings/#literals","title":"Literals","text":"<p>Boolean | Numeric | String | NULL | MISSING | Array | Dictionary</p>"},{"location":"n1ql-query-strings/#boolean","title":"Boolean","text":""},{"location":"n1ql-query-strings/#purpose_9","title":"Purpose","text":"<p>Represents a true or false value.</p>"},{"location":"n1ql-query-strings/#syntax_9","title":"Syntax","text":"<p><code>TRUE</code> | <code>FALSE</code></p>"},{"location":"n1ql-query-strings/#example_3","title":"Example","text":"<pre><code>SELECT value FROM db  WHERE value = true\nSELECT value FROM db  WHERE value = false\n</code></pre>"},{"location":"n1ql-query-strings/#numeric","title":"Numeric","text":""},{"location":"n1ql-query-strings/#purpose_10","title":"Purpose","text":"<p>Represents a numeric value. Numbers may be signed or unsigned digits. They have optional fractional and exponent components.</p>"},{"location":"n1ql-query-strings/#syntax_10","title":"Syntax","text":"<pre><code>'-'? (('.' DIGIT+) | (DIGIT+ ('.' DIGIT*)?)) ( [Ee] [-+]? DIGIT+ )? WB\n\nDIGIT = [0-9]\n</code></pre>"},{"location":"n1ql-query-strings/#example_4","title":"Example","text":"<pre><code>SELECT value FROM db  WHERE value = 10\nSELECT value FROM db  WHERE value = 0\nSELECT value FROM db WHERE value = -10\nSELECT value FROM db WHERE value = 10.25\nSELECT value FROM db WHERE value = 10.25e2\nSELECT value FROM db WHERE value = 10.25E2\nSELECT value FROM db WHERE value = 10.25E+2\nSELECT value FROM db WHERE value = 10.25E-2\n</code></pre>"},{"location":"n1ql-query-strings/#string","title":"String","text":""},{"location":"n1ql-query-strings/#purpose_11","title":"Purpose","text":"<p>The string literal represents a string or sequence of characters.</p>"},{"location":"n1ql-query-strings/#syntax_11","title":"Syntax","text":"<pre><code>\"characters\" | 'characters'\n</code></pre> <p>The string literal can be double-quoted as well as single-quoted.</p>"},{"location":"n1ql-query-strings/#example_5","title":"Example","text":"<pre><code>SELECT firstName, lastName FROM db WHERE middleName = \"middle\"\nSELECT firstName, lastName FROM db WHERE middleName = 'middle'\n</code></pre>"},{"location":"n1ql-query-strings/#null","title":"NULL","text":""},{"location":"n1ql-query-strings/#purpose_12","title":"Purpose","text":"<p>The literal <code>NULL</code> represents an empty value.</p>"},{"location":"n1ql-query-strings/#syntax_12","title":"Syntax","text":"<pre><code>NULL\n</code></pre>"},{"location":"n1ql-query-strings/#example_6","title":"Example","text":"<pre><code>SELECT firstName, lastName FROM db WHERE middleName IS NULL\n</code></pre>"},{"location":"n1ql-query-strings/#missing","title":"MISSING","text":""},{"location":"n1ql-query-strings/#purpose_13","title":"Purpose","text":"<p>The <code>MISSING</code> literal represents a missing name-value pair in a document.</p>"},{"location":"n1ql-query-strings/#syntax_13","title":"Syntax","text":"<pre><code>MISSING\n</code></pre>"},{"location":"n1ql-query-strings/#example_7","title":"Example","text":"<pre><code>SELECT firstName, lastName FROM db WHERE middleName IS MISSING\n</code></pre>"},{"location":"n1ql-query-strings/#array","title":"Array","text":""},{"location":"n1ql-query-strings/#purpose_14","title":"Purpose","text":"<p>Represents an Array.</p>"},{"location":"n1ql-query-strings/#syntax_14","title":"Syntax","text":"<pre><code>arrayLiteral = '[' _ (expression ( _ ',' _ e2:expression )* )? ']'\n</code></pre>"},{"location":"n1ql-query-strings/#example_8","title":"Example","text":"<pre><code>SELECT [\"a\", \"b\", \"c\"] FROM _\nSELECT [ property1, property2, property3] FROM _\n</code></pre>"},{"location":"n1ql-query-strings/#dictionary","title":"Dictionary","text":""},{"location":"n1ql-query-strings/#purpose_15","title":"Purpose","text":"<p>Represents a dictionary literal.</p>"},{"location":"n1ql-query-strings/#syntax_15","title":"Syntax","text":"<pre><code>dictionaryLiteral = '{' _ ( STRING_LITERAL ':' e:expression\n  ( _ ',' _ STRING_LITERAL ':' _ expression )* )?\n   '}'\n</code></pre>"},{"location":"n1ql-query-strings/#example_9","title":"Example","text":"<pre><code>SELECT { 'name': 'James', 'department': 10 } FROM db\nSELECT { 'name': 'James', 'department': dept } FROM db\nSELECT { 'name': 'James', 'phones': ['650-100-1000', '650-100-2000'] } FROM db\n</code></pre>"},{"location":"n1ql-query-strings/#identifiers","title":"Identifiers","text":""},{"location":"n1ql-query-strings/#purpose_16","title":"Purpose","text":"<p>Identifiers provide symbolic references. Use them for example to identify: column alias names, database names, database alias names, property names, parameter names, function names, and FTS index names.</p>"},{"location":"n1ql-query-strings/#syntax_16","title":"Syntax","text":"<pre><code>&lt;[a-zA-Z_] [a-zA-Z0-9_$]*&gt; _ | \"`\" ( [^`] | \"``\"   )* \"`\"  _\n</code></pre> <p>The identifier allows a-z, A-Z, 0-9, _ (underscore), and $ character. The identifier is case-sensitive.</p> <p>Tip</p> <p>To use other characters in the identifier, surround the identifier with the backtick ` character.</p>"},{"location":"n1ql-query-strings/#example_10","title":"Example","text":"<p>Example 10. Identifiers</p> <pre><code>SELECT * FROM _\n\nSELECT * FROM `db-1`\n\nSELECT key FROM db\n\nSELECT key$1 FROM db_1\n\nSELECT `key-1` FROM db\n</code></pre> <p>Use of backticks allows a hyphen as part of the identifier name.</p>"},{"location":"n1ql-query-strings/#property-expressions","title":"Property Expressions","text":""},{"location":"n1ql-query-strings/#purpose_17","title":"Purpose","text":"<p>The property expression is used to reference a property in a document.</p>"},{"location":"n1ql-query-strings/#syntax_17","title":"Syntax","text":"<pre><code>property = '*'| dataSourceName '.' _ '*'  | propertyPath\n\npropertyPath = propertyName (\n    ('.' _ propertyName ) |\n    ('[' _ INT_LITERAL _ ']' _  )\n    )*\n\npropertyName = IDENTIFIER\n</code></pre> <ol> <li>Prefix the property expression with the data source name or alias to indicate its origin.</li> <li>Use dot syntax to refer to nested properties in the propertyPath.</li> <li>Use bracket (<code>[index]</code>) syntax to refer to an item in an array.</li> <li>Use the asterisk (<code>*</code>) character to represents all properties. This can only be used in the result list of the    <code>SELECT</code> clause.</li> </ol>"},{"location":"n1ql-query-strings/#example_11","title":"Example","text":"<p>Example 11. Property Expressions</p> <pre><code>SELECT *\n  FROM db\n  WHERE contact.name = \"daniel\"\n\nSELECT db.*\n  FROM db\n  WHERE collection.contact.name = \"daniel\"\n\nSELECT collection.contact.address.city\n  FROM scope.collection\n  WHERE collection.contact.name = \"daniel\"\n\nSELECT contact.address.city\n  FROM scope.collection\n  WHERE contact.name = \"daniel\"\n\nSELECT contact.address.city, contact.phones[0]\n  FROM db\n  WHERE contact.name = \"daniel\"\n</code></pre>"},{"location":"n1ql-query-strings/#any-and-every-expressions","title":"Any and Every Expressions","text":""},{"location":"n1ql-query-strings/#purpose_18","title":"Purpose","text":"<p>Evaluates expressions over items in an array object.</p>"},{"location":"n1ql-query-strings/#syntax_18","title":"Syntax","text":"<pre><code>arrayExpression = \n  anyEvery _ variableName \n     _ IN  _ expression \n       _ SATISFIES _ expression \n    END \n\nanyEvery = anyOrSome AND EVERY | anyOrSome | EVERY\n\nanyOrSome = ANY | SOME\n</code></pre> <ol> <li>The array expression starts with <code>ANY/SOME</code>, <code>EVERY</code>, or <code>ANY/SOME AND EVERY</code>, each of which has a different function    as described below, and is terminated by <code>END</code><ul> <li><code>ANY/SOME</code>: Returns <code>TRUE</code> if at least one item in the array satisfies the expression, otherwise returns <code>FALSE</code>.   NOTE: <code>ANY</code> and <code>SOME</code> are interchangeable.</li> <li><code>EVERY</code>: Returns <code>TRUE</code> if all items in the array satisfies the expression, otherwise return <code>FALSE</code>. If the array   is empty, returns <code>TRUE</code>.</li> <li><code>ANY/SOME AND EVERY</code>: Same as <code>EVERY</code> but returns <code>FALSE</code> if the array is empty.</li> </ul> </li> <li>The variable name represents each item in the array.</li> <li>The <code>IN</code> keyword is used for specifying the array to be evaluated.</li> <li>The <code>SATISFIES</code> keyword is used for evaluating each item in the array.</li> <li><code>END</code> terminates the array expression.</li> </ol>"},{"location":"n1ql-query-strings/#example_12","title":"Example","text":"<p>Example 12. ALL and Every Expressions</p> <pre><code>SELECT name\n  FROM db\n  WHERE ANY v\n          IN contacts\n          SATISFIES v.city = 'San Mateo'\n        END\n</code></pre>"},{"location":"n1ql-query-strings/#parameter-expressions","title":"Parameter Expressions","text":""},{"location":"n1ql-query-strings/#purpose_19","title":"Purpose","text":"<p>Parameter expressions specify a value to be assigned from the parameter map presented when executing the query.</p> <p>Note</p> <p>If parameters are specified in the query string, but the parameter and value mapping is not specified in the query object, an error will be thrown when executing the query.</p>"},{"location":"n1ql-query-strings/#syntax_19","title":"Syntax","text":"<pre><code>$IDENTIFIER\n</code></pre>"},{"location":"n1ql-query-strings/#examples_6","title":"Examples","text":"<p>Example 13. Parameter Expression</p> <pre><code>SELECT name\n  FROM db\n  WHERE department = $department\n</code></pre> <p>Example 14. Using a Parameter</p> <pre><code>val query = database.createQuery($$\"SELECT name WHERE department = $department\")\nquery.parameters = Parameters().setValue(\"department\", \"E001\")\nval result = query.execute()\n</code></pre> <p>The query resolves to <code>SELECT name WHERE department = \"E001\"</code></p>"},{"location":"n1ql-query-strings/#parenthesis-expressions","title":"Parenthesis Expressions","text":""},{"location":"n1ql-query-strings/#purpose_20","title":"Purpose","text":"<p>Use parentheses to group expressions together to make them more readable or to establish operator precedences.</p>"},{"location":"n1ql-query-strings/#example_13","title":"Example","text":"<p>Example 15. Parenthesis Expression</p> <pre><code>-- Establish the desired operator precedence; do the addition before the multiplication\nSELECT (value1 + value2) * value 3\n  FROM db\n\nSELECT *\n  FROM db\n  WHERE ((value1 + value2) * value3) + value4 = 10\n\nSELECT *\n  FROM db\n  -- Clarify the conditional grouping\n  WHERE (value1 = value2)\n     OR (value3 = value4)\n</code></pre>"},{"location":"n1ql-query-strings/#operators","title":"Operators","text":"<p>In this section Binary Operators | Unary Operators | COLLATE Operators | CONDITIONAL Operator</p>"},{"location":"n1ql-query-strings/#binary-operators","title":"Binary Operators","text":"<p>Maths | Comparison Operators | Logical Operators | String Operator</p>"},{"location":"n1ql-query-strings/#maths","title":"Maths","text":"<p>Table 2. Maths Operators</p> Op Desc Example <code>+</code> Add <code>WHERE v1 + v2 = 10</code> <code>-</code> Subtract <code>WHERE v1 - v2 = 10</code> <code>*</code> Multiply <code>WHERE v1 * v2 = 10</code> <code>/</code> Divide \u2014 see note \u00b9 <code>WHERE v1 / v2 = 10</code> <code>%</code> Modulo <code>WHERE v1 % v2 = 0</code> <p>\u00b9 If both operands are integers, integer division is used, but if one is a floating number, then float division is used. This differs from Server SQL++, which performs float division regardless. Use DIV(x, y) to force float division in CBL SQL++.</p>"},{"location":"n1ql-query-strings/#comparison-operators","title":"Comparison Operators","text":""},{"location":"n1ql-query-strings/#purpose_21","title":"Purpose","text":"<p>The comparison operators are used in the <code>WHERE</code> statement to specify the condition on which to match documents.</p> <p>Table 3. Comparison Operators</p> Op Desc Example <code>=</code> or <code>==</code> Equals <code>WHERE v1 = v2</code><code>WHERE v1 == v2</code> <code>!=</code> or <code>&lt;&gt;</code> Not Equal to <code>WHERE v1 != v2</code><code>WHERE v1 &lt;&gt; v2</code> <code>&gt;</code> Greater than <code>WHERE v1 &gt; v2</code> <code>&gt;=</code> Greater than or equal to <code>WHERE v1 &gt;= v2</code> <code>&gt;</code> Less than <code>WHERE v1 &lt; v2</code> <code>&gt;=</code> Less than or equal to <code>WHERE v1 \u21d0 v2</code> <code>IN</code> Returns <code>TRUE</code> if the value is in the list or array of values specified by the right hand side expression; Otherwise returns <code>FALSE</code>. <code>WHERE \"James\" IN contactsList</code> <code>LIKE</code> String wildcard pattern matching \u00b2 comparison. Two wildcards are supported:<ul><li><code>%</code> Matches zero or more characters.</li><li><code>_</code> Matches a single character.</li></ul> <code>WHERE name LIKE 'a%'</code><code>WHERE name LIKE '%a'</code><code>WHERE name LIKE '%or%'</code><code>WHERE name LIKE 'a%o%'</code><code>WHERE name LIKE '%_r%'</code><code>WHERE name LIKE '%a_%'</code><code>WHERE name LIKE '%a__%'</code><code>WHERE name LIKE 'aldo'</code> <code>MATCH</code> String matching using FTS see Full Text Search Functions <code>WHERE v1-index MATCH \"value\"</code> <code>BETWEEN</code> Logically equivalent to <code>v1&gt;=X and v1&lt;=Y</code> <code>WHERE v1 BETWEEN 10 and 100</code> <code>IS NULL</code> \u00b3 Equal to <code>NULL</code> <code>WHERE v1 IS NULL</code> <code>IS NOT NULL</code> Not equal to <code>NULL</code> <code>WHERE v1 IS NOT NULL</code> <code>IS MISSING</code> Equal to <code>MISSING</code> <code>WHERE v1 IS MISSING</code> <code>IS NOT MISSING</code> Not equal to <code>MISSING</code> <code>WHERE v1 IS NOT MISSING</code> <code>IS VALUED</code> <code>IS NOT NULL AND MISSING</code> <code>WHERE v1 IS VALUED</code> <code>IS NOT VALUED</code> <code>IS NULL OR MISSING</code> <code>WHERE v1 IS NOT VALUED</code> <p>\u00b2 Matching is case-insensitive for ASCII characters, case-sensitive for non-ASCII.</p> <p>\u00b3 Use of <code>IS</code> and <code>IS NOT</code> is limited to comparing <code>NULL</code> and <code>MISSING</code> values (this encompasses <code>VALUED</code>). This is  different from <code>QueryBuilder</code>, in which they operate as equivalents of <code>==</code> and <code>!=</code>.</p> <p>Table 4. Comparing NULL and MISSING values using IS</p> OP NON-NULL Value NULL MISSING IS NULL FALSE TRUE MISSING IS NOT NULL TRUE FALSE MISSING IS MISSING FALSE FALSE TRUE IS NOT MISSING TRUE TRUE FALSE IS VALUED TRUE FALSE FALSE IS NOT VALUED FALSE TRUE TRUE"},{"location":"n1ql-query-strings/#logical-operators","title":"Logical Operators","text":""},{"location":"n1ql-query-strings/#purpose_22","title":"Purpose","text":"<p>Logical operators combine expressions using the following Boolean Logic Rules:</p> <ul> <li>TRUE is TRUE, and FALSE is FALSE</li> <li>Numbers 0 or 0.0 are FALSE</li> <li>Arrays and dictionaries are FALSE</li> <li>String and Blob are TRUE if the values are casted as a non-zero or FALSE if the values are casted as 0 or 0.0</li> <li>NULL is FALSE</li> <li>MISSING is MISSING</li> </ul> <p>Note</p> <p>This is different from Server SQL++, where:</p> <ul> <li>MISSING, NULL and FALSE are FALSE</li> <li>Numbers 0 is FALSE</li> <li>Empty strings, arrays, and objects are FALSE</li> <li>All other values are TRUE</li> </ul> <p>Tip</p> <p>Use TOBOOLEAN(expr) function to convert a value based on Server SQL++ boolean value rules.</p> <p>Table 5. Logical Operators</p> Op Description Example <code>AND</code> Returns <code>TRUE</code> if the operand expressions evaluate to <code>TRUE</code>; otherwise <code>FALSE</code>.If an operand is <code>MISSING</code> and the other is <code>TRUE</code> returns <code>MISSING</code>, if the other operand is <code>FALSE</code> it returns <code>FALSE</code>.If an operand is <code>NULL</code> and the other is <code>TRUE</code> returns <code>NULL</code>, if the other operand is <code>FALSE</code> it returns <code>FALSE</code>. <code>WHERE city = \"San Francisco\" AND status = true</code> <code>OR</code> Returns <code>TRUE</code> if one of the operand expressions is evaluated to <code>TRUE</code>; otherwise returns <code>FALSE</code>.If an operand is <code>MISSING</code>, the operation will result in <code>MISSING</code> if the other operand is <code>FALSE</code> or <code>TRUE</code> if the other operand is <code>TRUE</code>.If an operand is <code>NULL</code>, the operation will result in <code>NULL</code> if the other operand is <code>FALSE</code> or <code>TRUE</code> if the other operand is <code>TRUE</code>. <code>WHERE city = \u201cSan Francisco\u201d OR city = \"Santa Clara\"</code> <p>Table 6. Logical Operation Table</p> a b a AND b a OR b TRUE TRUE TRUE TRUE FALSE FALSE TRUE NULL FALSE \u2075\u207b\u00b9 TRUE MISSING MISSING TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE NULL FALSE FALSE \u2075\u207b\u00b9 MISSING FALSE MISSING NULL TRUE FALSE \u2075\u207b\u00b9 TRUE FALSE FALSE FALSE \u2075\u207b\u00b9 NULL FALSE \u2075\u207b\u00b9 FALSE \u2075\u207b\u00b9 MISSING FALSE \u2075\u207b\u00b2 MISSING \u2075\u207b\u00b3 MISSING TRUE MISSING TRUE FALSE FALSE MISSING NULL FALSE \u2075\u207b\u00b2 MISSING \u2075\u207b\u00b3 MISSING MISSING MISSING <p>Note</p> <p>This differs from Server SQL++ in the following instances: \u2075\u207b\u00b9 Server will return: NULL instead of FALSE \u2075\u207b\u00b2 Server will return: MISSING instead of FALSE \u2075\u207b\u00b3 Server will return: NULL instead of MISSING</p>"},{"location":"n1ql-query-strings/#string-operator","title":"String Operator","text":""},{"location":"n1ql-query-strings/#purpose_23","title":"Purpose","text":"<p>A single string operator is provided. It enables string concatenation.</p> <p>Table 7. String Operators</p> Op Description Example <code>||</code> Concatenating <code>SELECT firstnm || lastnm AS fullname FROM db</code>"},{"location":"n1ql-query-strings/#unary-operators","title":"Unary Operators","text":""},{"location":"n1ql-query-strings/#purpose_24","title":"Purpose","text":"<p>Three unary operators are provided. They operate by modifying an expression, making it numerically positive or negative, or by logically negating its value (<code>TRUE</code> becomes <code>FALSE</code>).</p>"},{"location":"n1ql-query-strings/#syntax_20","title":"Syntax","text":"<pre><code>// UNARY_OP _ expr\n</code></pre> <p>Table 8. Unary Operators</p> Op Description Example <code>+</code> Positive value <code>WHERE v1 = +10</code> <code>-</code> Negative value <code>WHERE v1 = -10</code> <code>NOT</code> Logical Negate operator <sup>*</sup> <code>WHERE \"James\" NOT IN contactsList</code> <p><sup>*</sup> The <code>NOT</code> operator is often used in conjunction with operators such as <code>IN</code>, <code>LIKE</code>, <code>MATCH</code>, and <code>BETWEEN</code> operators. <code>NOT</code> operation on <code>NULL</code> value returns <code>NULL</code>. <code>NOT</code> operation on <code>MISSING</code> value returns <code>MISSING</code>.</p> <p>Table 9. NOT Operation TABLE</p> a NOT a TRUE FALSE FALSE TRUE NULL FALSE MISSING MISSING"},{"location":"n1ql-query-strings/#collate-operators","title":"COLLATE Operators","text":""},{"location":"n1ql-query-strings/#purpose_25","title":"Purpose","text":"<p>Collate operators specify how the string comparison is conducted.</p>"},{"location":"n1ql-query-strings/#usage","title":"Usage","text":"<p>The collate operator is used in conjunction with string comparison expressions and <code>ORDER BY</code> clauses. It allows for one or more collations.</p> <p>If multiple collations are used, the collations need to be specified in a parenthesis. When only one collation is used, the parenthesis is optional.</p> <p>Note</p> <p>Collate is not supported by Server SQL++</p>"},{"location":"n1ql-query-strings/#syntax_21","title":"Syntax","text":"<pre><code>collate = COLLATE collation | '(' collation (_ collation )* ')'\n\ncollation = NO? (UNICODE | CASE | DIAC) WB\n</code></pre>"},{"location":"n1ql-query-strings/#arguments_8","title":"Arguments","text":"<p>The available collation options are:</p> <ul> <li><code>UNICODE</code>: Conduct a Unicode comparison; the default is to do ASCII comparison.</li> <li><code>CASE</code>: Conduct case-sensitive comparison.</li> <li><code>DIAC</code>: Take account of accents and diacritics in the comparison; on by default.</li> <li><code>NO</code>: This can be used as a prefix to the other collations, to disable them (for example: <code>NOCASE</code> to enable   case-insensitive comparison)</li> </ul>"},{"location":"n1ql-query-strings/#example_14","title":"Example","text":"<pre><code>SELECT department FROM db WHERE (name = \"fred\") COLLATE UNICODE\n</code></pre> <pre><code>SELECT department FROM db WHERE (name = \"fred\")\nCOLLATE (UNICODE)\n</code></pre> <pre><code>SELECT department FROM db WHERE (name = \"fred\") COLLATE (UNICODE CASE)\n</code></pre> <pre><code>SELECT name FROM db ORDER BY name COLLATE (UNICODE DIAC)\n</code></pre>"},{"location":"n1ql-query-strings/#conditional-operator","title":"CONDITIONAL Operator","text":""},{"location":"n1ql-query-strings/#purpose_26","title":"Purpose","text":"<p>The Conditional (or <code>CASE</code>) operator evaluates conditional logic in a similar way to the <code>IF</code>/<code>ELSE</code> operator.</p>"},{"location":"n1ql-query-strings/#syntax_22","title":"Syntax","text":"<pre><code>CASE (expression) (WHEN expression THEN expression)+ (ELSE expression)? END\n\nCASE (expression)? (!WHEN expression)?\n  (WHEN expression THEN expression)+ (ELSE expression)? END\n</code></pre> <p>Both Simple Case and Searched Case expressions are supported. The syntactic difference being that the Simple Case expression has an expression after the <code>CASE</code> keyword.</p> <ol> <li>Simple Case Expression<ul> <li>If the <code>CASE</code> expression is equal to the first <code>WHEN</code> expression, the result is the <code>THEN</code> expression.</li> <li>Otherwise, any subsequent <code>WHEN</code> clauses are evaluated in the same way.</li> <li>If no match is found, the result of the <code>CASE</code> expression is the <code>ELSE</code> expression, <code>NULL</code> if no <code>ELSE</code> expression   was provided.</li> </ul> </li> <li>Searched Case Expression<ul> <li>If the first <code>WHEN</code> expression is <code>TRUE</code>, the result of this expression is its <code>THEN</code> expression.</li> <li>Otherwise, subsequent <code>WHEN</code> clauses are evaluated in the same way. If no <code>WHEN</code> clause evaluate to <code>TRUE</code>, then   the result of the expression is the <code>ELSE</code> expression, or <code>NULL</code> if no <code>ELSE</code> expression was provided.</li> </ul> </li> </ol>"},{"location":"n1ql-query-strings/#example_15","title":"Example","text":"<p>Example 16. Simple Case</p> <pre><code>SELECT CASE state WHEN \u2018CA\u2019 THEN \u2018Local\u2019 ELSE \u2018Non-Local\u2019 END FROM DB\n</code></pre> <p>Example 17. Searched Case</p> <pre><code>SELECT CASE WHEN shippedOn IS NOT NULL THEN \u2018SHIPPED\u2019 ELSE \"NOT-SHIPPED\" END FROM db\n</code></pre>"},{"location":"n1ql-query-strings/#functions","title":"Functions","text":"<p>In this section Aggregation Functions | Array Functions | Conditional Functions | Date and Time Functions | Full Text Search Functions | Maths Functions | Metadata Functions | Pattern Searching Functions | String Functions | Type Checking Functions | Type Conversion Functions</p>"},{"location":"n1ql-query-strings/#purpose_27","title":"Purpose","text":"<p>Functions are also expressions.</p>"},{"location":"n1ql-query-strings/#syntax_23","title":"Syntax","text":"<p>The function syntax is the same as Java\u2019s method syntax. It starts with the function name, followed by optional arguments inside parentheses.</p> <pre><code>function = functionName parenExprs\n\nfunctionName  = IDENTIFIER\n\nparenExprs = '(' ( expression (_ ',' _ expression )* )? ')'\n</code></pre>"},{"location":"n1ql-query-strings/#aggregation-functions","title":"Aggregation Functions","text":"<p>Table 10. Aggregation Functions</p> Function Description <code>AVG(expr)</code> Returns average value of the number values in the group <code>COUNT(expr)</code> Returns a count of all values in the group <code>MIN(expr)</code> Returns the minimum value in the group <code>MAX(expr)</code> Returns the maximum value in the group <code>SUM(expr)</code> Returns the sum of all number values in the group"},{"location":"n1ql-query-strings/#array-functions","title":"Array Functions","text":"<p>Table 11. Array Functions</p> Function Description <code>ARRAY_AGG(expr)</code> Returns an array of the non-MISSING group values in the input expression, including NULL values. <code>ARRAY_AVG(expr)</code> Returns the average of all non-NULL number values in the array; or NULL if there are none <code>ARRAY_CONTAINS(expr)</code> Returns TRUE if the value exists in the array; otherwise FALSE <code>ARRAY_COUNT(expr)</code> Returns the number of non-null values in the array <code>ARRAY_IFNULL(expr)</code> Returns the first non-null value in the array <code>ARRAY_MAX(expr)</code> Returns the largest non-NULL, non_MISSING value in the array <code>ARRAY_MIN(expr)</code> Returns the smallest non-NULL, non_MISSING value in the array <code>ARRAY_LENGTH(expr)</code> Returns the length of the array <code>ARRAY_SUM(expr)</code> Returns the sum of all non-NULL numeric value in the array"},{"location":"n1ql-query-strings/#conditional-functions","title":"Conditional Functions","text":"<p>Table 12. Conditional Functions</p> Function Description <code>IFMISSING(expr1, expr2, \u2026)</code> Returns the first non-MISSING value, or NULL if all values are MISSING <code>IFMISSINGRONULL(expr1, expr2, \u2026)</code> Returns the first non-NULL and non-MISSING value, or NULL if all values are NULL or MISSING <code>IFNULL(expr1, expr2, \u2026)</code> Returns the first non-NULL, or NULL if all values are NULL <code>MISSINGIF(expr1, expr2)</code> Returns MISSING when expr1 = expr2; otherwise returns expr1.Returns MISSING if either or both expressions are MISSING.Returns NULL if either or both expressions are NULL.+ <code>NULLF(expr1, expr2)</code> Returns NULL when expr1 = expr2; otherwise returns expr1.Returns MISSING if either or both expressions are MISSING.Returns NULL if either or both expressions are NULL.+"},{"location":"n1ql-query-strings/#date-and-time-functions","title":"Date and Time Functions","text":"<p>Table 13. Date and Time Functions</p> Function Arguments Return Value <code>STR_TO_MILLIS(date1)</code>Coverts a date string to Epoch/UNIX milliseconds. <ul><li><code>date1</code> - A valid date string.</li></ul> Returns an integer containing the converted date string into Epoch/UNIX milliseconds. <code>STR_TO_UTC(date1)</code>Converts a date string into the equivalent date in UTC. <ul><li><code>date1</code> - A valid date string.</li></ul> Returns a date string representing the date string converted to UTC.The output date format follows the date format of the input date. Returns <code>null</code> if an invalid date format is provided. <code>STR_TO_TZ(date1, tz)</code>Converts a date string to it\u2019s equivalent in the specified timezone. <ul><li><code>date1</code> - A valid date string. This is converted to UTC.</li><li><code>tz</code> - An integer that represents minutes offset from UTC. For example, <code>UTC-5</code> would be represented as <code>-300</code>.</li></ul> Returns a date string representing the date string converted to the specified timezone.Returns <code>null</code> if an invalid date format is provided. <code>MILLIS_TO_STR(date1)</code>Converts an Epoch/UNIX timestamp into the specified date string format. <ul><li><code>date1</code> - An integer representing an Epoch/UNIX timestamp in millseconds. Returns a date string representing the local date.Returns <code>null</code> if an invalid timestamp is provided. <code>MILLIS_TO_UTC(date1)</code>Converts an Epoch/UNIX timestamp into a local time date string. <ul><li><code>date1</code> - An integer representing an Epoch/UNIX timestamp in millseconds.</li></ul> Returns a date string representing the date in UTC.Returns <code>null</code> if an invalid timestamp is provided. <code>MILLIS_TO_TZ(date1,tz, [fmt])</code>Converts an Epoch/UNIX timestamp into the specified time zone in the specified date string format. <ul><li><code>date1</code> - An integer representing an Epoch/UNIX timestamp in milliseconds.</li><li><code>tz</code> - An integer that represents minutes offset from UTC. For example, <code>UTC-5</code> would be represented as <code>-300</code>.</li><li><code>fmt</code> - An optional string parameter representing a date format to output the result as.</li></ul> Returns a date string representing the date in the specified timezone in the specified format.If <code>fmt</code> is not specified, the output default to the combined full date and time. <code>DATE_DIFF_STR(date1, date2, part)</code>Finds the elapsed time between two date strings. This is measured from <code>date2</code> to <code>date1</code>. <ul><li><code>date1</code> - A valid date string. This is converted to UTC.</li><li><code>date2</code> - A valid date string. This is converted to UTC.</li><li><code>part</code> - A string representing the date component units to return.</li></ul> Returns an integer representing the elapsed time measured from <code>date2</code> to <code>date1</code> (in units based on the specified <code>part</code>) between both dates.The value is positive if <code>date1</code> is greater than <code>date2</code>, negative otherwise.Returns <code>null</code> if any of the parameters are invalid. <code>DATE_DIFF_MILLIS(date1, date2, part)</code>Finds the elapsed time between two Epoch/UNIX timestamps. <ul><li><code>date1</code> - An integer representing an Epoch/UNIX timestamp in milliseconds.</li><li><code>date2</code> - An integer representing an Epoch/UNIX timestamp in milliseconds.</li><li><code>part</code> - A string representing the date component units to return.</li></ul> Returns an integer representing the elapsed time measured from <code>date2</code> to <code>date1</code> (in units based on the specified <code>part</code>) between both dates.The value is positive if <code>date1</code> is greater than <code>date2</code>, negative otherwise.Returns <code>null</code> if any of the parameters are invalid. <code>DATE_ADD_STR(date1, n, part)</code>Performs date arithmetic on a date string. For example <code>DATE_ADD_STR(\"2024-03-20T15:43:01+0000\", 3, \"day\")</code> adds 3 days to the provided date. <ul><li><code>date1</code> - A valid date string. This is converted to UTC.</li><li><code>n</code> - An integer or expression that evaluates to an integer. A positive value will increment the date component whereas a negative value will decrement the date component.</li><li><code>part</code> - A string representing the component of the date to increment.</li></ul> Returns an integer representing the calculation result as an Epoch/UNIX timestamp in milliseconds.Returns <code>null</code> if any of the parameters are invalid. <code>DATE_ADD_MILLIS(date1, n, part)</code>Performs date arithmetic on a particular component of an Epoch/UNIX timestamp value. For example <code>DATE_ADD_STR(1710946158819, 3, 'day')</code> adds 3 days to the provided date. <ul><li><code>date1</code> - An integer representing an Epoch/UNIX timestamp in milliseconds.</li><li><code>n</code> - An integer or expression that evaluates to an integer. A positive value will increment the date component whereas a negative value will decrement the date component.</li><li><code>part</code> - A string representing the component of the date to increment.</li></ul> Returns an integer representing the calculation result as an Epoch/UNIX timestamp in milliseconds.Returns <code>null</code> if any of the parameters are invalid."},{"location":"n1ql-query-strings/#full-text-search-functions","title":"Full Text Search Functions","text":"<p>Table 14. FTS Functions</p> Function Description Example <code>MATCH(indexName, term)</code> Returns <code>TRUE</code> if <code>term</code> expression matches the FTS indexed term. <code>indexName</code> identifies the FTS index, <code>term</code> expression to search for matching. <code>WHERE MATCH (description, \u201ccouchbase\u201d)</code> <code>RANK(indexName)</code> Returns a numeric value indicating how well the current query result matches the full-text query when performing the <code>MATCH</code>. <code>indexName</code> is an IDENTIFIER for the FTS index. <code>WHERE MATCH (description, \u201ccouchbase\u201d) ORDER BY RANK(description)</code>"},{"location":"n1ql-query-strings/#maths-functions","title":"Maths Functions","text":"<p>Table 15. Maths Functions</p> Function Description <code>ABS(expr)</code> Returns the absolute value of a number. <code>ACOS(expr)</code> Returns the arc cosine in radians. <code>ASIN(expr)</code> Returns the arcsine in radians. <code>ATAN(expr)</code> Returns the arctangent in radians. <code>ATAN2(expr1,expr2)</code> Returns the arctangent of expr1/expr2. <code>CEIL(expr)</code> Returns the smallest integer not less than the number. <code>COS(expr)</code> Returns the cosine value of the expression. <code>DIV(expr1, expr2)</code> Returns float division of expr1 and expr2.Both expr1 and expr2 are cast to a double number before division.The returned result is always a double. <code>DEGREES(expr)</code> Converts radians to degrees. <code>E()</code> Returns base of natural logarithms. <code>EXP(expr)</code> Returns expr value <code>FLOOR(expr)</code> Returns largest integer not greater than the number. <code>IDIV(expr1, expr2)</code> Returns integer division of expr1 and expr2. <code>LN(expr)</code> Returns log base e value. <code>LOG(expr)</code> Returns log base 10 value. <code>PI()</code> Return PI value. <code>POWER(expr1, expr2)</code> Returns expr1expr2 value. <code>RADIANS(expr)</code> Returns degrees to radians. <code>ROUND(expr (, digits_expr)?)</code> Returns the rounded value to the given number of integer digits to the right of the decimal point (left if digits is negative). Digits are 0 if not given.The function uses Rounding Away From Zero convention to round midpoint values to the next number away from zero (so, for example, <code>ROUND(1.75)</code> returns 1.8 but <code>ROUND(1.85)</code> returns 1.9. <sup>*</sup> <code>ROUND_EVEN(expr (, digits_expr)?)</code> Returns rounded value to the given number of integer digits to the right of the decimal point (left if digits is negative). Digits are 0 if not given.The function uses Rounding to Nearest Even (Banker\u2019s Rounding) convention which rounds midpoint values to the nearest even number (for example, both <code>ROUND_EVEN(1.75)</code> and <code>ROUND_EVEN(1.85)</code> return 1.8). <code>SIGN(expr)</code> Returns -1 for negative, 0 for zero, and 1 for positive numbers. <code>SIN(expr)</code> Returns sine value. <code>SQRT(expr)</code> Returns square root value. <code>TAN(expr)</code> Returns tangent value. <code>TRUNC (expr (, digits, expr)?)</code> Returns a truncated number to the given number of integer digits to the right of the decimal point (left if digits is negative). Digits are 0 if not given. <p><sup>*</sup> The behavior of the <code>ROUND()</code> function is different from Server SQL++ <code>ROUND()</code>, which rounds the midpoint values using Rounding to Nearest Even convention.</p>"},{"location":"n1ql-query-strings/#metadata-functions","title":"Metadata Functions","text":"<p>Table 16. Metadata Functions</p> Function Description Example <code>META(dataSourceName?)</code> Returns a dictionary containing metadata properties including:<ul><li>id : document identifier</li><li>sequence : document mutating sequence number</li><li>deleted : flag indicating whether document is deleted or not</li><li>expiration : document expiration date in timestamp formatThe optional dataSourceName identifies the database or the database alias name.</li></ul>To access a specific metadata property, use the dot expression. <code>SELECT META() FROM db</code><code>SELECT META().id, META().sequence, META().deleted, META().expiration FROM db</code><code>SELECT p.name, r.rating FROM product as p INNER JOIN reviews AS r ON META(r).id IN p.reviewList WHERE META(p).id = \"product320\"</code>"},{"location":"n1ql-query-strings/#pattern-searching-functions","title":"Pattern Searching Functions","text":"<p>Table 17. Pattern Searching Functions</p> Function Description <code>REGEXP_CONTAINS(expr, pattern)</code> Returns TRUE if the string value contains any sequence that matches the regular expression pattern. <code>REGEXP_LIKE(expr, pattern)</code> Return TRUE if the string value exactly matches the regular expression pattern. <code>REGEXP_POSITION(expr, pattern)</code> Returns the first position of the occurrence of the regular expression pattern within the input string expression. Return -1 if no match is found. Position counting starts from zero. <code>REGEXP_REPLACE(expr, pattern, repl [, n])</code> Returns new string with occurrences of pattern replaced with repl. If n is given, at the most n replacements are performed. If n is not given, all matching occurrences are replaced."},{"location":"n1ql-query-strings/#string-functions","title":"String Functions","text":"<p>Table 18. String Functions</p> Function Description <code>CONTAINS(expr, substring_expr)</code> Returns true if the substring exists within the input string, otherwise returns false. <code>LENGTH(expr)</code> Returns the length of a string. The length is defined as the number of characters within the string. <code>LOWER(expr)</code> Returns the lowercase string of the input string. <code>LTRIM(expr)</code> Returns the string with all leading whitespace characters removed. <code>RTRIM(expr)</code> Returns the string with all trailing whitespace characters removed. <code>TRIM(expr)</code> Returns the string with all leading and trailing whitespace characters removed. <code>UPPER(expr)</code> Returns the uppercase string of the input string."},{"location":"n1ql-query-strings/#type-checking-functions","title":"Type Checking Functions","text":"<p>Table 19. Type Checking Functions</p> Function Description <code>ISARRAY(expr)</code> Returns TRUE if expression is an array, otherwise returns MISSING, NULL or FALSE. <code>ISATOM(expr)</code> Returns TRUE if expression is a Boolean, number, or string, otherwise returns MISSING, NULL or FALSE. <code>ISBOOLEAN(expr)</code> Returns TRUE if expression is a Boolean, otherwise returns MISSING, NULL or FALSE. <code>ISNUMBER(expr)</code> Returns TRUE if expression is a number, otherwise returns MISSING, NULL or FALSE. <code>ISOBJECT(expr)</code> Returns TRUE if expression is an object (dictionary), otherwise returns MISSING, NULL or FALSE. <code>ISSTRING(expr)</code> Returns TRUE if expression is a string, otherwise returns MISSING, NULL or FALSE. <code>TYPE(expr)</code> Returns one of the following strings, based on the value of expression:<ul><li>\u201cmissing\u201d</li><li>\u201cnull\u201d</li><li>\u201cboolean\u201d</li><li>\u201cnumber\u201d</li><li>\u201cstring\u201d</li><li>\u201carray\u201d</li><li>\u201cobject\u201d</li><li>\u201cbinary\u201d</li></ul>"},{"location":"n1ql-query-strings/#type-conversion-functions","title":"Type Conversion Functions","text":"<p>Table 20. Type Conversion Functions</p> Function Description <code>TOARRAY(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns the array itself.Returns all other values wrapped in an array. <code>TOATOM(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns an array of a single item if the value is an array.Returns an object of a single key/value pair if the value is an object.Returns boolean, numbers, or stringsReturns NULL for all other values. <code>TOBOOLEAN(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns FALSE if the value is FALSE.Returns FALSE if the value is 0 or NaN.Returns FALSE if the value is an empty string, array, and object.Return TRUE for all other values. <code>TONUMBER(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns 0 if the value is FALSE.Returns 1 if the value is TRUE.Returns NUMBER if the value is NUMBER.Returns NUMBER parsed from the string value.Returns NULL for all other values. <code>TOOBJECT(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns the object if the value is an object.Returns an empty object for all other values. <code>TOSTRING(expr)</code> Returns MISSING if the value is MISSING.Returns NULL if the value is NULL.Returns \u201cfalse\u201d if the value is FALSE.Returns \u201ctrue\u201d if the value is TRUE.Returns NUMBER in String if the value is NUMBER.Returns the string value if the value is a string.Returns NULL for all other values."},{"location":"n1ql-query-strings/#querybuilder-differences","title":"QueryBuilder Differences","text":"<p>Couchbase Lite SQL++ Query supports all <code>QueryBuilder</code> features, except Predictive Query and Index. See Table 21 for the features supported by SQL++ but not by <code>QueryBuilder</code>.</p> <p>Table 21. QueryBuilder Differences</p> Category Components Conditional Operator <code>CASE(WHEN \u2026 THEN \u2026 ELSE ..)</code> Array Functions <code>ARRAY_AGG</code><code>ARRAY_AVG</code><code>ARRAY_COUNT</code><code>ARRAY_IFNULL</code><code>ARRAY_MAX</code><code>ARRAY_MIN</code><code>ARRAY_SUM</code> Conditional Functions <code>IFMISSING</code><code>IFMISSINGORNULL</code><code>IFNULL</code><code>MISSINGIF</code><code>NULLIF</code> Math Functions <code>DIV</code><code>IDIV</code><code>ROUND_EVEN</code> Pattern Matching Functions <code>REGEXP_CONTAINS</code><code>REGEXP_LIKE</code><code>REGEXP_POSITION</code><code>REGEXP_REPLACE</code> Type Checking Functions <code>ISARRAY</code><code>ISATOM</code><code>ISBOOLEAN</code><code>ISNUMBER</code><code>ISOBJECT</code><code>ISSTRING TYPE</code> Type Conversion Functions <code>TOARRAY</code><code>TOATOM</code><code>TOBOOLEAN</code><code>TONUMBER</code><code>TOOBJECT</code><code>TOSTRING</code>"},{"location":"n1ql-query-strings/#query-parameters","title":"Query Parameters","text":"<p>You can provide runtime parameters to your SQL++ query to make it more flexible.</p> <p>To specify substitutable parameters within your query string prefix the name with <code>$</code>, <code>$type</code> \u2014 see Example 18.</p> <p>Example 18. Running a SQL++ Query</p> <pre><code>val query = database.createQuery(\n    $$\"SELECT META().id AS id FROM _ WHERE type = $type\"\n) \n\nquery.parameters = Parameters().setString(\"type\", \"hotel\") \n\nreturn query.execute().allResults()\n</code></pre> <ol> <li>Define a parameter placeholder <code>$type</code></li> <li>Set the value of the <code>$type</code> parameter</li> </ol>"},{"location":"n1ql-server-differences/","title":"SQL++ Server Differences","text":"<p>Differences between Couchbase Server SQL++ and Couchbase Lite SQL++</p> <p>Important</p> <p>N1QL is Couchbase\u2019s implementation of the developing SQL++ standard. As such the terms N1QL and SQL++ are used interchangeably in Couchbase documentation unless explicitly stated otherwise.</p> <p>There are several minor but notable behavior differences between SQL++ for Mobile queries and SQL++ for Server, as shown in Table 1.</p> <p>In some instances, if required, you can force SQL++ for Mobile to work in the same way as SQL++ for Server. This table compares Couchbase Server and Mobile instances:</p> <p>Table 1. SQL++ Query Comparison</p> Feature SQL++ for Couchbase Server SQL++ for Mobile Scopes and Collections <code>SELECT *FROM <code>travel-sample</code>.inventory.airport</code> <code>SELECT *FROM inventory.airport</code> Scopes and Collections <code>SELECT *FROM <code>travel-sample</code>.inventory.airport</code> <code>SELECT *FROM inventory.airport</code> <code>USE KEYS</code> <code>SELECT fname, email FROM tutorial USE KEYS [\"dave\", \"ian\"];</code> <code>SELECT fname, email FROM tutorial WHERE meta().id IN (\"dave\", \"ian\");</code> <code>ON KEYS</code> <code>SELECT * FROM `user` u</code><code>JOIN orders o ON KEYS ARRAY s.order_id</code><code>FOR s IN u.order_history END;</code> <code>SELECT * FROM user u, u.order_history s</code><code>JOIN orders o ON s.order_id = meta(o).id;</code> <code>ON KEY</code> <code>SELECT * FROM `user` u</code><code>JOIN orders o ON KEY o.user_id FOR u;</code> <code>SELECT * FROM user u</code><code>JOIN orders o ON meta(u).id = o.user_id;</code> <code>NEST</code> <code>SELECT * FROM `user` u</code><code>NEST orders orders</code><code>ON KEYS ARRAY s.order_id</code><code>FOR s IN u.order_history END;</code> <code>NEST</code>/<code>UNNEST</code> not supported <code>LEFT OUTER NEST</code> <code>SELECT * FROM user u</code><code>LEFT OUTER NEST orders orders</code><code>ON KEYS ARRAY s.order_id</code><code>FOR s IN u.order_history END;</code> <code>NEST</code>/<code>UNNEST</code> not supported <code>ARRAY</code> <code>ARRAY i FOR i IN [1, 2] END</code> <code>(SELECT VALUE i FROM [1, 2] AS i)</code> <code>ARRAY FIRST</code> <code>FIRST v FOR v IN arr</code> <code>arr[0]</code> <code>LIMIT l OFFSET o</code> Does not allow <code>OFFSET</code> without <code>LIMIT</code> Allows <code>OFFSET</code> without <code>LIMIT</code> <code>UNION</code>, <code>INTERSECT</code>, and <code>EXCEPT</code> All three are supported (with <code>ALL</code> and <code>DISTINCT</code> variants) Not supported <code>OUTER JOIN</code> Both <code>LEFT</code> and <code>RIGHT OUTER JOIN</code> supported Only <code>LEFT OUTER JOIN</code> supported (and necessary for query expressability) <code>&lt;</code>, <code>&lt;=</code>, <code>=</code>, etc. operators Can compare either complex values or scalar values Only scalar values may be compared <code>ORDER BY</code> Result sequencing is based on specific rules described in SQL++ (server) OrderBy clause Result sequencing is based on the SQLite ordering described in SQLite select overviewThe ordering of Dictionary and Array objects is based on binary ordering. <code>SELECT DISTINCT</code> Supported SELECT DISTINCT VALUE is supported when the returned values are scalars <code>CREATE INDEX</code> Supported Not Supported <code>INSERT</code>/\u200b<code>UPSERT</code>/\u200b<code>DELETE</code> Supported Not Supported"},{"location":"n1ql-server-differences/#boolean-logic-rules","title":"Boolean Logic Rules","text":"SQL++ for Couchbase Server SQL++ for Mobile Couchbase Server operates in the same way as Couchbase Lite, except:<ul><li>MISSING, NULL and FALSE are FALSE</li><li>Numbers 0 is FALSE</li><li>Empty strings, arrays, and objects are FALSE</li><li>All other values are TRUE</li></ul>You can choose to use Couchbase Server\u2019s SQL++ rules by using the <code>TOBOOLEAN(expr)</code> function to convert a value to its boolean value. SQL++ for Mobile\u2019s boolean logic rules are based on SQLite\u2019s, so:<ul><li>TRUE is TRUE, and FALSE is FALSE</li><li>Numbers 0 or 0.0 are FALSE</li><li>Arrays and dictionaries are FALSE</li><li>String and Blob are TRUE if the values are casted as a non-zero or FALSE if the values are casted as 0 or 0.0 \u2014 see SQLITE\u2019s CAST and Boolean expressions for more details)</li><li>NULL is FALSE</li><li>MISSING is MISSING</li></ul>"},{"location":"n1ql-server-differences/#logical-operations","title":"Logical Operations","text":"<p>In SQL++ for Mobile logical operations will return one of three possible values: <code>TRUE</code>, <code>FALSE</code>, or <code>MISSING</code>.</p> <p>Logical operations with the MISSING value could result in <code>TRUE</code> or <code>FALSE</code> if the result can be determined regardless of the missing value, otherwise the result will be <code>MISSING</code>.</p> <p>In SQL++ for Mobile \u2014 unlike SQL++ for Server \u2014 <code>NULL</code> is implicitly converted to <code>FALSE</code> before evaluating logical operations. Table 2 summarizes the result of logical operations with different operand values and also shows where the Couchbase Server behavior differs.</p> <p>Table 2. Logical Operations Comparison</p> Operanda SQL++ for Mobile SQL++ for Server b a AND b a OR b b a AND b a OR b <code>TRUE</code> <code>TRUE</code> <code>TRUE</code> <code>TRUE</code> - - - <code>FALSE</code> <code>FALSE</code> <code>TRUE</code> - - - <code>NULL</code> <code>FALSE</code> <code>TRUE</code> - <code>NULL</code> - <code>MISSING</code> <code>MISSING</code> <code>TRUE</code> - - - <code>FALSE</code> <code>TRUE</code> <code>FALSE</code> <code>TRUE</code> - - - <code>FALSE</code> <code>FALSE</code> <code>FALSE</code> - - - <code>NULL</code> <code>FALSE</code> <code>FALSE</code> - - <code>NULL</code> <code>MISSING</code> <code>FALSE</code> <code>MISSING</code> - - - <code>NULL</code> <code>TRUE</code> <code>FALSE</code> <code>TRUE</code> - <code>NULL</code> - <code>FALSE</code> <code>FALSE</code> <code>FALSE</code> - - <code>NULL</code> <code>NULL</code> <code>FALSE</code> <code>FALSE</code> - <code>NULL</code> <code>NULL</code> <code>MISSING</code> <code>FALSE</code> <code>MISSING</code> - <code>MISSING</code> <code>NULL</code> <code>MISSING</code> <code>TRUE</code> <code>MISSING</code> <code>TRUE</code> - - - <code>FALSE</code> <code>FALSE</code> <code>MISSING</code> - - - <code>NULL</code> <code>FALSE</code> <code>MISSING</code> - <code>MISSING</code> <code>NULL</code> <code>MISSING</code> <code>MISSING</code> <code>MISSING</code> - - -"},{"location":"n1ql-server-differences/#crud-operations","title":"CRUD Operations","text":"<p>SQL++ for Mobile only supports Read or Query operations.</p> <p>SQL++ for Server fully supports CRUD operation.</p>"},{"location":"n1ql-server-differences/#functions","title":"Functions","text":""},{"location":"n1ql-server-differences/#division-operator","title":"Division Operator","text":"SQL++ for Server SQL++ for Mobile SQL++ for Server always performs float division regardless of the types of the operands.You can force this behavior in SQL++ for Mobile by using the <code>DIV(x, y)</code> function. The operand types determine the division operation performed.If both are integers, integer division is used.If one is a floating number, then float division is used."},{"location":"n1ql-server-differences/#round-function","title":"Round Function","text":"SQL++ for Server SQL++ for Mobile SQL++ for Server <code>ROUND()</code> uses the Rounding to Nearest Even convention (for example, <code>ROUND(1.85)</code> returns 1.8).You can force this behavior in Couchbase Lite by using the <code>ROUND_EVEN()</code> function. The <code>ROUND()</code> function returns a value to the given number of integer digits to the right of the decimal point (left if digits is negative).<ul><li>Digits are 0 if not given.</li><li>Midpoint values are handled using the Rounding Away From Zero convention, which rounds them to the next number away from zero (for example, <code>ROUND(1.85)</code> returns 1.9).</li></ul>"},{"location":"new-logging-api/","title":"New Logging API","text":"<p>Couchbase Lite 3.2.2 introduces a new Logging API.</p>"},{"location":"new-logging-api/#upgrading-to-the-new-cbl-logging-api","title":"Upgrading to the New CBL Logging API","text":"<p>Warning</p> <p>Use of the deprecated and new Logging API at the same time is not supported.</p> <p>You can find information about the new Couchbase Lite Logging API introduced in Couchbase Lite 3.2.2.</p> <p>For information about the now deprecated earlier version of the Logging API, see Legacy Logging API.</p>"},{"location":"new-logging-api/#logsinks","title":"LogSinks","text":"<p>Couchbase Lite 3.2.2 introduces a new Logging API. The new Logging API has the following benefits:</p> <ul> <li>Log sinks are now thread safe, removing risk of inconsistent states during initialization.</li> <li>Simplified API and reduced implementation complexity.</li> </ul> <p>The new logging API retains many of the core concepts of the previous API.</p> <p>The first thing to note is that the three destinations for logs have been renamed as <code>LogSinks</code>, in keeping with common source/sink terminology.</p> <p>The <code>FileLogSink</code>, the <code>ConsoleLogSink</code> and the <code>CustomLogSink</code> are all to be installed in the <code>LogSinks</code> object.</p> <p>Only <code>ConsoleLogSink</code> is enabled for all logging domains at the warning level by default. To enable a specific type of log sink, create a log sink object of that type, set its minimum log level and domains, and assign it to <code>LogSinks</code>. To disable a log sink, set it to null or use a log sink with <code>LogLevel.NONE</code>.</p> <p>Couchbase still logs its messages in a handful of named domains and at common log levels: <code>LogLevel.DEBUG</code> the most verbose, and <code>LogLevel.ERROR</code> only for serious failures.</p> <p>The biggest difference between the new and the old API is that <code>LogSinks</code> are immutable: you set the level and domain at which they log in their constructors. For example, you can only change the level at which the <code>ConsoleLogSink</code> forwards messages to the console by installing a new one created for the new log level.</p> <p>Log output is split into the following streams:</p> <ul> <li>Logging to the Couchbase File Log   Each log level writes to a separate file and there is a single retention policy for all files.</li> <li>Logging to the Console   You can independently configure and control console logs, which provides a convenient method of accessing diagnostic   information during debugging scenarios.</li> </ul> <p>With console logging, you can fine-tune diagnostic output to suit specific debug scenarios, without interfering with   any logging required by Couchbase Support for the investigation of issues. * Using a Custom Logger   For greater flexibility you can implement a custom logging class.</p>"},{"location":"new-logging-api/#logging-to-the-console","title":"Logging to the Console","text":"<p>The changes necessary convert the installation of a console logger from the old to the new API are minimal. Create an instance of <code>ConsoleLogSink</code> initialized with the desired log level and domains and install it.</p> <p>Old API</p> <pre><code>Database.log.console.domains = LogDomain.ALL_DOMAINS\nDatabase.log.console.level = LogLevel.WARNING\n</code></pre> <p>New API</p> <pre><code>LogSinks.console = ConsoleLogSink(LogLevel.WARNING)\n</code></pre>"},{"location":"new-logging-api/#logging-to-the-couchbase-file-log","title":"Logging to the Couchbase File Log","text":"<p>The changes necessary to convert the installation of a file logger are also similar. Instead of configuring a <code>FileLogger</code> using a <code>LogFileConfiguration</code>, create a new <code>FileLogSink</code> with the desired properties and install it.</p> <p>Note</p> <p><code>setRotateCount</code> from the old API is slightly different from <code>setMaxKeptFiles</code>. <code>setMaxKeptFiles</code> is the maximum number of log files that will exist at any time and is the count of rotated files (<code>setRotateCount</code>) plus one.</p> <p>Old API</p> <pre><code>Database.log.file.apply {\n    config = LogFileConfiguration(directory = \"path/to/temp/logs\").apply {\n        maxSize = 10240\n        maxRotateCount = 5\n        usesPlaintext = false\n    }\n    level = LogLevel.INFO\n}\n</code></pre> <p>New API</p> <pre><code>LogSinks.file = FileLogSink(\n    directory = \"path/to/temp/logs\",\n    maxKeptFiles = 12,\n    isPlainText = true\n)\n</code></pre>"},{"location":"new-logging-api/#using-a-custom-logger","title":"Using a Custom Logger","text":"<p>Installing a custom log sink with the new API is also streamlined: create an instance of your custom sink, and to install it use <code>LogSinks.custom</code>.</p> <p>As with the other log sinks, you will have to specify the level and domain at which Couchbase logs are forwarded to your custom sink at its creation.</p> <p>Your custom log sink code will have to change as well. A custom log sink implements the <code>LogSink</code> functional interface and is assigned to a <code>CustomLogSink</code> instance during creation.</p> <p>A second important change is that your logger will receive only logs at the level and domain for which it is initialized. There is no need to record or filter the logs forwarded to the <code>writeLog</code> method which replaces the <code>log</code> method from the old API.</p> <p>Related to this last point, the Couchbase <code>Logger</code>s, now <code>LogSink</code>s are meant to support logging by the Couchbase Lite platform. They were never meant as a general framework for logging.</p> <p>Important</p> <p>With the new API, customer code can no longer log, directly, to any of the Couchbase log sinks. The Console and File log sinks cannot be subclassed and do not publish methods that allow writing logs. If you need to log to the console for example, you\u2019ll have to create your own way of doing so.</p> <p>Old API Implementing The Custom Logger Interface</p> <pre><code>class LogTestLogger(override val level: LogLevel) : Logger {\n    override fun log(level: LogLevel, domain: LogDomain, message: String) {\n        // this method will never be called if param level &lt; this.level\n        // handle the message, for example piping it to a third party framework\n    }\n}\n</code></pre> <p>Old API Enable Custom Logger</p> <pre><code>// this custom logger will not log an event with a log level &lt; WARNING\nDatabase.log.custom = LogTestLogger(LogLevel.WARNING)\n</code></pre> <p>New API</p> <pre><code>LogSinks.custom = CustomLogSink(\n    LogLevel.WARNING,\n    LogDomain.NETWORK, LogDomain.REPLICATOR\n) { level, domain, message -&gt;\n    // will be called only with messages from the NETWORK and REPLICATOR\n    // domains with a log level of WARNING or higher.\n}\n</code></pre>"},{"location":"paging/","title":"Paging","text":"<p>The paging extensions are built on Google's AndroidX Paging. Kotbase Paging provides a <code>PagingSource</code> which performs limit/offset paging queries based on a user-supplied database query.</p>"},{"location":"paging/#installation","title":"Installation","text":"Enterprise EditionCommunity Edition build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-ee-paging:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre> build.gradle.kts<pre><code>kotlin {\n    sourceSets {\n        commonMain.dependencies {\n            implementation(\"dev.kotbase:couchbase-lite-paging:3.2.4-1.2.0\")\n        }\n    }\n}\n</code></pre>"},{"location":"paging/#usage","title":"Usage","text":"<pre><code>// Uses kotlinx-serialization JSON processor\n@Serializable\ndata class Hotel(val id: String, val type: String, val name: String)\n\nval select = select(Meta.id, \"type\", \"name\")\nval mapper = { json: String -&gt;\n    Json.decodeFromString&lt;Hotel&gt;(json)\n}\nval queryProvider: QueryProvider = {\n    where {\n        (\"type\" equalTo \"hotel\") and\n        (\"state\" equalTo \"California\")\n    }\n    .orderBy { \"name\".ascending() }\n}\n\nval pagingSource = QueryPagingSource(\n    EmptyCoroutineContext,\n    select,\n    collection,\n    mapper,\n    queryProvider\n)\n</code></pre>"},{"location":"passive-peer/","title":"Passive Peer","text":"<p>How to set up a listener to accept a replicator connection and sync using peer-to-peer</p> <p>Android enablers</p> <p>Allow Unencrypted Network Traffic</p> <p>To use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>iOS Restrictions</p> <p>iOS 14 Applications</p> <p>When your application attempts to access the user\u2019s local network, iOS will prompt them to allow (or deny) access. You can customize the message presented to the user by editing the description for the <code>NSLocalNetworkUsageDescription</code> key in the <code>Info.plist</code>.</p> <p>Use Background Threads</p> <p>As with any network or file I/O activity, Couchbase Lite activities should not be performed on the UI thread. Always use a background thread.</p> <p>Code Snippets</p> <p>All code examples are indicative only. They demonstrate the basic concepts and approaches to using a feature. Use them as inspiration and adapt these examples to best practice when developing applications for your platform.</p>"},{"location":"passive-peer/#introduction","title":"Introduction","text":"<p>This is an Enterprise Edition feature.</p> <p>This content provides code and configuration examples covering the implementation of Peer-to-Peer Sync over WebSockets. Specifically, it covers the implementation of a Passive Peer.</p> <p>Couchbase\u2019s Passive Peer (also referred to as the server, or listener) will accept a connection from an Active Peer (also referred to as the client or replicator) and replicate database changes to synchronize both databases.</p> <p>Subsequent sections provide additional details and examples for the main configuration options.</p> <p>Secure Storage</p> <p>The use of TLS, its associated keys and certificates requires using secure storage to minimize the chances of a security breach. The implementation of this storage differs from platform to platform \u2014 see Using Secure Storage.</p>"},{"location":"passive-peer/#configuration-summary","title":"Configuration Summary","text":"<p>You should configure and initialize the Listener with a list of collections to sync. There is no limit on the number of Listeners you may configure \u2014 Example 1 shows a simple initialization and configuration process.</p> <p>Example 1. Listener configuration and initialization</p> <pre><code>val listener = URLEndpointListener(\n    URLEndpointListenerConfiguration(\n        collections = collections,\n        port = 55990,\n        networkInterface = \"wlan0\",\n\n        enableDeltaSync = false,\n\n        // Configure server security\n        disableTls = false,\n\n        // Use an Anonymous Self-Signed Cert\n        identity = null,\n\n        // Configure Client Security using an Authenticator\n        // For example, Basic Authentication\n        authenticator = ListenerPasswordAuthenticator { usr, pwd -&gt;\n            (usr === validUser) &amp;&amp; (pwd.concatToString() == validPass)\n        }\n    )\n)\n\n// Start the listener\nlistener.start()\n</code></pre> <ol> <li>Identify the local database and the collections to be used \u2014 see Initialize the Listener    Configuration</li> <li>Optionally, choose a port to use. By default, the system will automatically assign a port \u2014 to override this, see    Set Port and Network Interface</li> <li>Optionally, choose a network interface to use. By default, the system will listen on all network interfaces \u2014 to    override this see Set Port and Network Interface</li> <li>Optionally, choose to sync only changes. The default is not to enable delta-sync \u2014 see Delta Sync</li> <li>Set server security. TLS is always enabled instantly, so you can usually omit this line. But you can, optionally,    disable TLS (not advisable in production) \u2014 see TLS Security</li> <li>Set the credentials this server will present to the client for authentication. Here we show the default TLS    authentication, which is an anonymous self-signed certificate. The server must always authenticate itself to the    client.</li> <li>Set client security \u2014 define the credentials the server expects the client to present for authentication. Here we    show how basic authentication is configured to authenticate the client-supplied credentials from the http    authentication header against valid credentials \u2014 see Authenticating the Client for    more options.    Note that client authentication is optional.</li> <li>Initialize the listener using the configuration settings.</li> <li>Start Listener</li> </ol>"},{"location":"passive-peer/#device-discovery","title":"Device Discovery","text":"<p>This phase is optional: If the listener is initialized on a well-known URL endpoint (for example, a static IP address or well-known DNS address) then you can configure Active Peers to connect to those.</p> <p>Before initiating the listener, you may execute a peer discovery phase. For the Passive Peer, this involves advertising the service using, for example, Network Service Discovery on Android or Bonjour on iOS and waiting for an invite from the Active Peer. The connection is established once the Passive Peer has authenticated and accepted an Active Peer\u2019s invitation.</p>"},{"location":"passive-peer/#initialize-the-listener-configuration","title":"Initialize the Listener Configuration","text":"<p>Initialize the Listener configuration with a list of collections from the local database \u2014 see Example 2. All other configuration values take their default setting.</p> <p>Example 2. Specify Local Collections</p> <pre><code>collections = collections,\n</code></pre> <p>Set the list of local collections using the <code>URLEndpointListenerConfiguration</code>.</p>"},{"location":"passive-peer/#set-port-and-network-interface","title":"Set Port and Network Interface","text":""},{"location":"passive-peer/#port-number","title":"Port number","text":"<p>The Listener will automatically select an available port if you do not specify one \u2014 see Example 3 for how to specify a port.</p> <p>Example 3. Specify a port</p> <pre><code>port = 55990,\n</code></pre> <p>To use a canonical port \u2014 one known to other applications \u2014 specify it explicitly using the <code>port</code> property shown here. Ensure that firewall rules do not block any port you do specify.</p>"},{"location":"passive-peer/#network-interface","title":"Network Interface","text":"<p>The listener will listen on all network interfaces by default.</p> <p>Example 4. Specify a Network Interface to Use</p> <pre><code>networkInterface = \"wlan0\",\n</code></pre> <p>To specify an interface \u2014 one known to other applications \u2014 identify it explicitly, using the <code>networkInterface</code> property shown here. This must be either an IP address or network interface name such as <code>en0</code>.</p>"},{"location":"passive-peer/#delta-sync","title":"Delta Sync","text":"<p>Delta Sync allows clients to sync only those parts of a document that have changed. This can result in significant bandwidth consumption savings and throughput improvements. Both are valuable benefits, especially when network bandwidth is constrained.</p> <p>Example 5. Enable delta sync</p> <pre><code>enableDeltaSync = false,\n</code></pre> <p>Delta sync replication is not enabled by default. Use <code>URLEndpointListenerConfiguration</code>'s <code>isDeltaSyncEnabled</code> property to activate or deactivate it.</p>"},{"location":"passive-peer/#tls-security","title":"TLS Security","text":""},{"location":"passive-peer/#enable-or-disable-tls","title":"Enable or Disable TLS","text":"<p>Define whether the connection is to use TLS or clear text.</p> <p>TLS-based encryption is enabled by default, and this setting ought to be used in any production environment. However, it can be disabled. For example, for development or test environments.</p> <p>When TLS is enabled, Couchbase Lite provides several options on how the listener may be configured with an appropriate TLS Identity \u2014 see Configure TLS Identity for Listener.</p> <p>Note</p> <p>On the Android platform, to use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>You can use <code>URLEndpointListenerConfiguration</code>'s <code>isTlsDisabled</code> method to disable TLS communication if necessary.</p> <p>The <code>isTlsDisabled</code> setting must be <code>false</code> when Client Cert Authentication is required.</p> <p>Basic Authentication can be used with, or without, TLS.</p> <p><code>isTlsDisabled</code> works in conjunction with <code>TLSIdentity</code>, to enable developers to define the key and certificate to be used.</p> <ul> <li>If <code>isTlsDisabled</code> is <code>true</code> \u2014 TLS communication is disabled and TLS identity is ignored.   Active peers will use the <code>ws://</code> URL scheme used to connect to the listener.</li> <li>If <code>isTlsDisabled</code> is <code>false</code> or not specified \u2014 TLS communication is enabled.   Active peers will use the wss:// URL scheme to connect to the listener.</li> </ul>"},{"location":"passive-peer/#configure-tls-identity-for-listener","title":"Configure TLS Identity for Listener","text":"<p>Define the credentials the server will present to the client for authentication. Note that the server must always authenticate itself with the client \u2014 see Authenticating the Listener on Active Peer for how the client deals with this.</p> <p>Use <code>URLEndpointListenerConfiguration</code>'s <code>tlsIdentity</code> property to configure the TLS Identity used in TLS communication.</p> <p>If <code>TLSIdentity</code> is not set, then the listener uses an auto-generated anonymous self-signed identity (unless <code>isTlsDisabled = true</code>). Whilst the client cannot use this to authenticate the server, it will use it to encrypt communication, giving a more secure option than non-TLS communication.</p> <p>The auto-generated anonymous self-signed identity is saved in secure storage for future use to obviate the need to re-generate it.</p> <p>Note</p> <p>Typically, you will configure the listener\u2019s TLS Identity once during the initial launch and re-use it (from secure storage) on any subsequent starts.</p> <p>Here are some example code snippets showing:</p> <ul> <li>Importing a TLS identity \u2014 see Example 6</li> <li>Setting TLS identity to expect self-signed certificate \u2014 see Example 7</li> <li>Setting TLS identity to expect anonymous certificate \u2014 see Example 8</li> </ul> <p>Example 6. Import Listener\u2019s TLS identity</p> <p>TLS identity certificate import APIs are platform-specific.</p> AndroidiOS/macOSJVM in androidMain<pre><code>config.isTlsDisabled = false\n\nKeyStoreUtils.importEntry(\n    \"PKCS12\",\n    context.assets.open(\"cert.p12\"),\n    \"store-password\".toCharArray(),\n    \"store-alias\",\n    \"key-password\".toCharArray(),\n    \"new-alias\"\n)\n\nconfig.tlsIdentity = TLSIdentity.getIdentity(\"new-alias\")\n</code></pre> in appleMain<pre><code>config.isTlsDisabled = false\n\nval path = NSBundle.mainBundle.pathForResource(\"cert\", ofType = \"p12\") ?: return\n\nval certData = NSData.dataWithContentsOfFile(path) ?: return\n\nval tlsIdentity = TLSIdentity.importIdentity(\n    data = certData.toByteArray(),\n    password = \"123\".toCharArray(),\n    alias = \"alias\"\n)\n\nconfig.tlsIdentity = tlsIdentity\n</code></pre> in jvmMain<pre><code>config.isTlsDisabled = false\n\nval keyStore = KeyStore.getInstance(\"PKCS12\")\nFiles.newInputStream(Path(\"cert.p12\")).use { keyStream -&gt;\n    keyStore.load(\n        keyStream,\n        \"keystore-password\".toCharArray()\n    )\n}\n\nconfig.tlsIdentity = TLSIdentity.getIdentity(keyStore, \"alias\", \"keyPass\".toCharArray())\n</code></pre> <ol> <li>Ensure TLS is used</li> <li>Get key and certificate data</li> <li>Use the retrieved data to create and store the TLS identity</li> <li>Set this identity as the one presented in response to the client\u2019s prompt</li> </ol> <p>Example 7. Create Self-Signed Cert</p> CommonJVM in commonMain<pre><code>config.isTlsDisabled = false\n\nval attrs = mapOf(\n    TLSIdentity.CERT_ATTRIBUTE_COMMON_NAME to \"Couchbase Demo\",\n    TLSIdentity.CERT_ATTRIBUTE_ORGANIZATION to \"Couchbase\",\n    TLSIdentity.CERT_ATTRIBUTE_ORGANIZATION_UNIT to \"Mobile\",\n    TLSIdentity.CERT_ATTRIBUTE_EMAIL_ADDRESS to \"noreply@couchbase.com\"\n)\n\nval tlsIdentity = TLSIdentity.createIdentity(\n    true,\n    attrs,\n    Clock.System.now() + 1.days,\n    \"cert-alias\"\n)\n\nconfig.tlsIdentity = tlsIdentity\n</code></pre> in jvmMain<pre><code>// On the JVM platform, before calling\n// common TLSIdentity.createIdentity() or getIdentity()\n// load a KeyStore to use\nval keyStore = KeyStore.getInstance(\"PKCS12\")\nkeyStore.load(null, null)\nTLSIdentity.useKeyStore(keyStore)\n</code></pre> <ol> <li>Ensure TLS is used.</li> <li>Map the required certificate attributes.</li> <li>Create the required TLS identity using the attributes. Add to secure storage as 'cert-alias'.</li> <li>Configure the server to present the defined identity credentials when prompted.</li> </ol> <p>Example 8. Use Anonymous Self-Signed Certificate</p> <p>This example uses an anonymous self-signed certificate. Generated certificates are held in secure storage.</p> <pre><code>config.isTlsDisabled = false\n\n// Use an Anonymous Self-Signed Cert\nconfig.tlsIdentity = null\n</code></pre> <ol> <li>Ensure TLS is used.    This is the default setting.</li> <li>Authenticate using an anonymous self-signed certificate.    This is the default setting.</li> </ol>"},{"location":"passive-peer/#authenticating-the-client","title":"Authenticating the Client","text":"<p>In this section Use Basic Authentication | Using Client Certificate Authentication  | Delete Entry | The Impact of TLS Settings </p> <p>Define how the server (listener) will authenticate the client as one it is prepared to interact with.</p> <p>Whilst client authentication is optional, Couchbase Lite provides the necessary tools to implement it. Use the <code>URLEndpointListenerConfiguration</code> class\u2019s <code>authenticator</code> property to specify how the client-supplied credentials are to be authenticated.</p> <p>Valid options are:</p> <ul> <li>No authentication \u2014 If you do not define a <code>ListenerAuthenticator</code> then all clients are accepted.</li> <li>Basic Authentication \u2014 uses the <code>ListenerPasswordAuthenticator</code> to authenticate the client using the client-supplied   username and password (from the http authentication header).</li> <li><code>ListenerCertificateAuthenticator</code> \u2014 which   authenticates the client using a client supplied chain of one or more certificates. You should initialize the   authenticator using one of the following constructors:<ul> <li>A root certificate, or a list of intermediate certificates and a root certificate \u2014 the client supplied   certificate must end at a certificate in this list if it is to be authenticated.</li> <li>A block of code that assumes total responsibility for authentication \u2014 it must return a boolean response (<code>true</code>   for an authenticated client, or <code>false</code> for a failed authentication).</li> </ul> </li> </ul>"},{"location":"passive-peer/#use-basic-authentication","title":"Use Basic Authentication","text":"<p>Define how to authenticate client-supplied username and password credentials. To use client-supplied certificates instead \u2014 see Using Client Certificate Authentication</p> <p>Example 9. Password authentication</p> <pre><code>config.authenticator = ListenerPasswordAuthenticator { username, password -&gt;\n    username == validUser &amp;&amp; password.concatToString() == validPassword\n}\n</code></pre> <p>Where <code>username</code>/<code>password</code> are the client-supplied values (from the http-authentication header) and <code>validUser</code>/<code>validPassword</code> are the values acceptable to the server.</p>"},{"location":"passive-peer/#using-client-certificate-authentication","title":"Using Client Certificate Authentication","text":"<p>Define how the server will authenticate client-supplied certificates.</p> <p>There are two ways to authenticate a client:</p> <ul> <li>A chain of one or more certificates that ends at a certificate in the list of certificates supplied to the constructor   for <code>ListenerCertificateAuthenticator</code> \u2014 see   Example 10</li> <li>Application logic: This method assumes complete responsibility for verifying and authenticating the client \u2014 see   Example 11   If the parameter supplied to the constructor for <code>ListenerCertificateAuthenticator</code> is of type   <code>ListenerCertificateAuthenticatorDelegate</code>, all other forms of authentication are bypassed.   The client response to the certificate request is passed to the method supplied as the constructor parameter. The   logic should take the form of a function or lambda.</li> </ul> <p>Example 10. Set Certificate Authorization</p> <p>Configure the server (listener) to authenticate the client against a list of one or more certificates provided by the server to the <code>ListenerCertificateAuthenticator</code>.</p> <pre><code>// Configure the client authenticator\n// to validate using ROOT CA\n// validId.certs is a list containing a client cert to accept\n// and any other certs needed to complete a chain between\n// the client cert and a CA\nval validId = TLSIdentity.getIdentity(\"Our Corporate Id\")\n    ?: throw IllegalStateException(\"Cannot find corporate id\")\n\n// accept only clients signed by the corp cert\nval listener = URLEndpointListener(\n    URLEndpointListenerConfiguration(\n        // get the identity \n        collections = collections,\n        identity = validId,\n        authenticator = ListenerCertificateAuthenticator(validId.certs)\n    )\n)\n</code></pre> <ol> <li>Get the identity data to authenticate against. This can be, for example, from a resource file provided with the app,    or an identity previously saved in secure storage.</li> <li>Configure the authenticator to authenticate the client supplied certificate(s) using these root certs. A valid client    will provide one or more certificates that match a certificate in this list.</li> <li>Add the authenticator to the listener configuration.</li> </ol> <p>Example 11. Application Logic</p> <p>Configure the server (listener) to authenticate the client using user-supplied logic.</p> <pre><code>// Configure authentication using application logic\nval corpId = TLSIdentity.getIdentity(\"OurCorp\")\n    ?: throw IllegalStateException(\"Cannot find corporate id\")\n\nconfig.tlsIdentity = corpId\n\nconfig.authenticator = ListenerCertificateAuthenticator { certs -&gt;\n    // supply logic that returns boolean\n    // true for authenticate, false if not\n    // For instance:\n    certs[0].contentEquals(corpId.certs[0])\n}\n</code></pre> <ol> <li>Get the identity data to authenticate against. This can be, for example, from a resource file provided with the app,    or an identity previously saved in secure storage.</li> <li>Configure the authenticator to pass the root certificates to a user supplied code block. This code assumes complete    responsibility for authenticating the client supplied certificate(s). It must return a boolean value; with <code>true</code>    denoting the client supplied certificate authentic.</li> <li>Add the authenticator to the listener configuration.</li> </ol>"},{"location":"passive-peer/#delete-entry","title":"Delete Entry","text":"<p>You can remove unwanted TLS identities from secure storage using the convenience API.</p> <p>Example 12. Deleting TLS Identities</p> <pre><code>TLSIdentity.deleteIdentity(\"cert-alias\")\n</code></pre>"},{"location":"passive-peer/#the-impact-of-tls-settings","title":"The Impact of TLS Settings","text":"<p>The table in this section shows the expected system behavior (in regards to security) depending on the TLS configuration settings deployed.</p> <p>Table 1. Expected system behavior</p> isTlsDisabled tlsIdentity (corresponding to server) Expected system behavior <code>true</code> Ignored TLS is disabled; all communication is plain text. <code>false</code> Set to <code>null</code> <ul><li>The system will auto generate an anonymous self-signed cert.</li><li>Active Peers (clients) should be configured to accept self-signed certificates.</li><li>Communication is encrypted.</li></ul> <code>false</code> Set to server identity generated from a self- or CA-signed certificate<ul><li>On first use \u2014 Bring your own certificate and private key; for example, using the <code>TLSIdentity</code> class\u2019s <code>createIdentity()</code> method to add it to the secure storage.</li><li>Each time \u2014 Use the server identity from the certificate stored in the secure storage; for example, using the <code>TLSIdentity</code> class\u2019s <code>getIdentity()</code> method with the alias you want to retrieve.</li></ul> <ul><li>System will use the configured identity.</li><li>Active Peers will validate the server certificate corresponding to the <code>TLSIdentity</code> (as long as they are configured to not skip validation \u2014 see TLS Security).</li></ul>"},{"location":"passive-peer/#start-listener","title":"Start Listener","text":"<p>Once you have completed the listener\u2019s configuration settings you can initialize the listener instance and start it running \u2014 see Example 13.</p> <p>Example 13. Initialize and start listener</p> <pre><code>// Initialize the listener\nval listener = URLEndpointListener(\n    URLEndpointListenerConfiguration(\n        collections = collections,\n        port = 55990,\n        networkInterface = \"wlan0\",\n\n        enableDeltaSync = false,\n\n        // Configure server security\n        disableTls = false,\n\n        // Use an Anonymous Self-Signed Cert\n        identity = null,\n\n        // Configure Client Security using an Authenticator\n        // For example, Basic Authentication\n        authenticator = ListenerPasswordAuthenticator { usr, pwd -&gt;\n            (usr === validUser) &amp;&amp; (pwd.concatToString() == validPass)\n        }\n    )\n)\n\n// Start the listener\nlistener.start()\n</code></pre>"},{"location":"passive-peer/#monitor-listener","title":"Monitor Listener","text":"<p>Use the listener\u2019s <code>status</code> property to get counts of total and active connections \u2014 see Example 14.</p> <p>You should note that these counts can be extremely volatile. So, the actual number of active connections may have changed, by the time the <code>ConnectionStatus</code> class returns a result.</p> <p>Example 14. Get connection counts</p> <pre><code>val connectionCount = listener.status?.connectionCount\nval activeConnectionCount = listener.status?.activeConnectionCount\n</code></pre>"},{"location":"passive-peer/#stop-listener","title":"Stop Listener","text":"<p>It is best practice to check the status of the listener\u2019s connections and stop only when you have confirmed that there are no active connections \u2014 see Example 15.</p> <p>Example 15. Stop listener using stop method</p> <pre><code>listener.stop()\n</code></pre> <p>Note</p> <p>Closing the database will also close the listener.</p>"},{"location":"peer-to-peer-sync/","title":"Peer-to-Peer Sync","text":"<p>Couchbase Lite\u2019s Peer-to-Peer Synchronization enables edge devices to synchronize securely without consuming centralized cloud-server resources</p>"},{"location":"peer-to-peer-sync/#introduction","title":"Introduction","text":"<p>This is an Enterprise Edition feature.</p> <p>Couchbase Lite\u2019s Peer-to-Peer synchronization solution offers secure storage and bidirectional data synchronization between edge devices without needing a centralized cloud-based control point.</p> <p>Couchbase Lite\u2019s Peer-to-Peer data synchronization provides:</p> <ul> <li>Instant WebSocket-based listener for use in Peer-to-Peer applications communicating over IP-based networks</li> <li>Simple application development, enabling sync with a short amount of code</li> <li>Optimized network bandwidth usage and reduced data transfer costs with Delta Sync support</li> <li>Securely sync data with built-in support for Transport Layer Security (TLS) encryption and authentication support</li> <li>Document management. Reducing conflicts in concurrent writes with built-in conflict management support</li> <li>Built-in network resiliency</li> </ul>"},{"location":"peer-to-peer-sync/#overview","title":"Overview","text":"<p>Peer-to-Peer synchronization requires one Peer to act as the Listener to the other Peer\u2019s replicator.</p> <p></p> <p>Peer-to-Peer synchronization requires one Peer to act as the Listener to the other Peer\u2019s replicator. Therefore, to use Peer-to-Peer synchronization in your application, you must configure one Peer to act as a Listener using the Couchbase Listener API, the most important of which include <code>URLEndpointListener</code> and <code>URLEndpointListenerConfiguration</code>.</p> <p>Example 1. Simple workflow</p> <ol> <li>Configure the listener (passive peer, or server)</li> <li>Initialize the listener, which listens for incoming WebSocket connections (on a user-defined, or auto-selected,    port)</li> <li>Configure a replicator (active peer, or client)</li> <li>Use some form of discovery phase, perhaps with a zero-config protocol such as Network Service Discovery for    Android or Bonjour for iOS, or use known URL endpoints, to identify a listener</li> <li>Point the replicator at the listener</li> <li>Initialize the replicator</li> <li>Replicator and listener engage in the configured security protocol exchanges to confirm connection</li> <li>If connection is confirmed then replication will commence, synchronizing the two data stores</li> </ol> <p>Here you can see configuration involves a Passive Peer and an Active Peer and a user-friendly listener configuration in Basic Setup.</p> <p>You can also learn how to implement Peer-to-Peer synchronization by referring to our tutorial \u2014 see Getting Started with Peer-to-Peer Synchronization.</p>"},{"location":"peer-to-peer-sync/#features","title":"Features","text":"<p>Couchbase Lite\u2019s Peer-to-Peer synchronization solution provides support for cross-platform synchronization, for example, between Android and iOS devices.</p> <p>Each listener instance serves a single Couchbase Lite database, enabling synchronization for documents within specified collections of that database.</p> <p>Having a Listener on a database still allows you to open replications to the other clients. For example, a Listener can actively begin replicating to other Listeners while listening for connections. These replications can be for the same or a different database.</p> <p>The Listener will automatically select a port to use or a user-specified port. It will also listen on all available networks, unless you specify a specific network.</p>"},{"location":"peer-to-peer-sync/#security","title":"Security","text":"<p>Couchbase Lite\u2019s Peer-to-Peer synchronization supports encryption and authentication over TLS with multiple modes, including:</p> <ul> <li>No encryption, for example, clear text.</li> <li>CA cert</li> <li>Self-signed cert</li> <li>Anonymous self-signed \u2014 an auto-generated anonymous TLS identity is generated if no identity is specified. This TLS   identity provides encryption but not authentication.   Any self-signed certificates generated by the convenience API are stored in secure storage.</li> </ul> <p>The replicator (client) can handle certificates pinned by the listener for authentication purposes.</p> <p>Support is also provided for basic authentication using username and password credentials. Whilst this can be used in clear text mode, developers are strongly advised to use TLS encryption.</p> <p>For testing and development purposes, support is provided for the client (active, replicator) to skip verification of self-signed certificates; this mode should not be used in production.</p>"},{"location":"peer-to-peer-sync/#error-handling","title":"Error Handling","text":"<p>When a listener is stopped, then all connected replicators are notified by a WebSocket error. Your application should distinguish between transient and permanent connectivity errors.</p>"},{"location":"peer-to-peer-sync/#passive-peers","title":"Passive peers","text":"<p>A Passive Peer losing connectivity with an Active Peer will clean up any associated endpoint connections to that peer. The Active Peer may attempt to reconnect to the Passive Peer.</p>"},{"location":"peer-to-peer-sync/#active-peers","title":"Active peers","text":"<p>An Active Peer permanently losing connectivity with a Passive Peer will cease replicating.</p> <p>An Active Peer temporarily losing connectivity with a passive Peer will use exponential backoff functionality to attempt reconnection.</p>"},{"location":"peer-to-peer-sync/#delta-sync","title":"Delta Sync","text":"<p>Optional delta-sync support is provided but is inactive by default.</p> <p>Delta-sync can be enabled on a per-replication basis provided that the databases involved are also configured to permit it.</p>"},{"location":"peer-to-peer-sync/#conflict-resolution","title":"Conflict Resolution","text":"<p>Conflict resolution for Peer-to-Peer synchronization works in the same way as it does for Sync Gateway replication, with both custom and automatic resolution available.</p>"},{"location":"peer-to-peer-sync/#basic-setup","title":"Basic Setup","text":"<p>You can configure a Peer-to-Peer synchronization with just a short amount of code as shown here in Example 2  and Example 3.</p> <p>Example 2. Simple Listener</p> <p>This simple listener configuration will give you a listener ready to participate in an encrypted synchronization with a replicator providing a valid username and password.</p> <pre><code>val listener = URLEndpointListener(\n    URLEndpointListenerConfiguration(\n        collections = db.collections,\n        authenticator = ListenerPasswordAuthenticator { user, pwd -&gt;\n            (user == \"daniel\") &amp;&amp; (pwd.concatToString() == \"123\")\n        }\n    )\n)\nlistener.start()\nthis.listener = listener\n</code></pre> <ol> <li>Initialize the listener configuration</li> <li>Configure the client authenticator to require basic authentication</li> <li>Initialize the listener</li> <li>Start the listener</li> </ol> <p>Example 3. Simple Replicator</p> <p>This simple replicator configuration will give you an encrypted, bi-directional Peer-to-Peer synchronization with automatic conflict resolution.</p> <pre><code>val listenerEndpoint = URLEndpoint(\"wss://10.0.2.2:4984/db\") \nval repl = Replicator(\n    ReplicatorConfiguration(listenerEndpoint)\n        .addCollections(collections)\n        .apply {\n            authenticator = BasicAuthenticator(\"valid.user\", \"valid.password.string\".toCharArray())\n            isAcceptOnlySelfSignedServerCertificate = true\n        }\n)\nrepl.start() \nthis.replicator = repl\n</code></pre> <ol> <li>Get the listener\u2019s endpoint. Here we use a known URL, but it could be a URL established dynamically in a discovery    phase.</li> <li>Initialize the replicator configuration with the collections of the database to be synchronized and the listener it    is to synchronize with.</li> <li>Configure the replicator to expect a self-signed certificate from the listener.</li> <li>Configure the replicator to present basic authentication credentials if the listener prompts for them (client    authentication is optional).</li> <li>Initialize the replicator.</li> <li>Start the replicator.</li> </ol>"},{"location":"peer-to-peer-sync/#api-highlights","title":"API Highlights","text":""},{"location":"peer-to-peer-sync/#urlendpointlistener","title":"URLEndpointListener","text":"<p>The <code>URLEndpointListener</code> is the listener for peer-to-peer synchronization. It acts like a passive replicator, in the same way that Sync Gateway does in a 'standard' replication. On the client side, the listener\u2019s endpoint is used to point the replicator to the listener.</p> <p>Core functionalities of the listener are:</p> <ul> <li>Users can initialize the class using a <code>URLEndpointListenerConfiguration</code> object.</li> <li>The listener can be started, or can be stopped.</li> <li>Once the listener is started, a total number of connections or active connections can be checked.</li> </ul>"},{"location":"peer-to-peer-sync/#urlendpointlistenerconfiguration","title":"URLEndpointListenerConfiguration","text":"<p>Use <code>URLEndpointListenerConfiguration</code> to create a configuration object you can then use to initialize the listener.</p> <p><code>port</code></p> <p>This is the port that the listener will listen to.</p> <p>If the port is zero, the listener will auto-assign an available port to listen on.</p> <p>Default value is zero. When the listener is not started, the port zero.</p> <p><code>networkInterface</code></p> <p>Use this to select a specific Network Interface to use, in the form of the IP Address or network interface name.</p> <p>If the network interface is specified, only that interface wil be used.</p> <p>If the network interface is not specified, all available network interfaces will be used.</p> <p>The value is null if the listener is not started.</p> <p><code>isTlsDisabled</code></p> <p>You can use <code>URLEndpointListenerConfiguration</code>'s <code>isTlsDisabled</code> property to disable TLS communication if necessary.</p> <p>The <code>isTlsDisabled</code> setting must be <code>false</code> when Client Cert Authentication is required.</p> <p>Basic Authentication can be used with, or without, TLS.</p> <p><code>isTlsDisabled</code> works in conjunction with <code>TLSIdentity</code>, to enable developers to define the key and certificate to be used.</p> <ul> <li>If <code>isTlsDisabled</code> is <code>true</code> \u2014 TLS communication is disabled and <code>tlsIdentity</code> is ignored.   Active peers will use the <code>ws://</code> URL scheme used to connect to the listener.</li> <li>If <code>isTlsDisabled</code> is <code>false</code> or not specified \u2014 TLS communication is enabled.   Active peers will use the <code>wss://</code> URL scheme to connect to the listener.</li> </ul> <p><code>tlsIdentity</code></p> <p>Use <code>URLEndpointListenerConfiguration</code>'s <code>tlsIdentity</code> property to configure the TLS Identity used in TLS communication.</p> <p>If <code>TLSIdentity</code> is not set, then the listener uses an auto-generated anonymous self-signed identity (unless <code>isTlsDisabled = true</code>). Whilst the client cannot use this to authenticate the server, it will use it to encrypt communication, giving a more secure option than non-TLS communication.</p> <p>The auto-generated anonymous self-signed identity is saved in secure storage for future use to obviate the need to re-generate it.</p> <p>When the listener is not started, the identity is null. When TLS is disabled, the identity is always null.</p> <p><code>authenticator</code></p> <p>Use this to specify the authenticator the listener uses to authenticate the client\u2019s connection request. This should be set to one of the following:</p> <ul> <li><code>ListenerPasswordAuthenticator</code></li> <li><code>ListenerCertificateAuthenticator</code></li> <li><code>null</code> \u2014 there is no authentication</li> </ul> <p><code>isReadOnly</code></p> <p>Use this to allow only pull replication. The default value is <code>false</code>.</p> <p><code>isDeltaSyncEnabled</code></p> <p>The option to enable Delta Sync and replicate only changed data also depends on the delta sync settings at database level. The default value is <code>false</code>.</p>"},{"location":"peer-to-peer-sync/#security_1","title":"Security","text":"<p>Couchbase Lite\u2019s Peer-to-Peer synchronization ensures secure communication through TLS and supports multiple authentication mechanisms.</p>"},{"location":"peer-to-peer-sync/#tls-identity","title":"TLS Identity","text":"<p>The URLEndpointListener uses a TLS identity to establish secure connections. (A TLS identity is an RSA public/private key pair and certificate.) The identity can include either a certificate signed by a trusted Certificate Authority (CA), or a self-signed certificate. If no identity is specified, the listener automatically generates an anonymous, self-signed certificate, which is primarily used for encryption, but not for authentication.</p> <p>When replicating with a listener that uses a self-signed certificate, the replicator (client) can be configured to skip certificate validation. This option is useful for development or testing, but not recommended for production.</p> <p>Note</p> <p>The minimum supported version of TLS is TLS 1.2.</p>"},{"location":"peer-to-peer-sync/#authentication-mechanisms","title":"Authentication Mechanisms","text":"<p>The URLEndpointListener supports two authentication mechanisms:</p> <ul> <li>Basic Authentication, using a username and password.</li> <li>Certificate Authentication, which authenticates clients using client certificates, and is only available when TLS is   enabled.</li> </ul>"},{"location":"peer-to-peer-sync/#using-secure-storage","title":"Using Secure Storage","text":"<p>TLS and its associated keys and certificates might require using secure storage to minimize the chances of a security breach. The implementation of this storage differs from platform to platform. This table summarizes the secure storage used to store keys and certificates.</p> AndroidmacOS/iOSJavaWindowsLinux <p>Secure storage details</p> <p> Platform Android Key Storage Android System KeyStore Certificate Storage Android System KeyStore Notes <ul> <li>Android KeyStore was introduced from Android API 18.</li> <li>Android KeyStore security has evolved over time to provide more secure support. Please check this document for more info: Hardware-backed Keystore.</li> </ul> Reference Android Keystore system </p> <p>Secure storage details</p> <p> Platform macOS/iOS Key Storage KeyChain Certificate Storage KeyChain Notes Use kSecAttrLabel of the SecCertificate to store the TLSIdentity\u2019s label Reference Keychain services </p> <p>Secure storage details</p> <p> Platform Java Key Storage User Specified KeyStore Certificate Storage User Specified KeyStore Notes <ul> <li>The KeyStore represents a storage facility for cryptographic keys and certificates. It\u2019s users' choice to decide whether to persist the KeyStore or not.</li> <li>The supported KeyStore types are PKCS12 (Default from Java 9) and JKS (Default on Java 8 and below).</li> </ul> Reference Class KeyStore </p> <p>Secure storage details</p> <p> Platform Windows Key Storage CNG Key Storage Provider Certificate Storage CNG Key Storage Provider Reference Key Storage and Retrieval </p> <p>As Linux-based operating systems do not have a standard or common secure key storage, Couchbase Lite C does not support persisting generated identities with the specified label on this platform.</p> <p>As an alternative, Couchbase Lite C enables developers to implement their own cryptographic operations through a set of callbacks, enabling certificate signing and other cryptographic tasks during the TLS handshake using a private key stored in their preferred secure key storage. These callbacks allow operations like signing data, with the private key remaining securely stored and never exposed. The key idea is that all cryptographic operations are performed within secure key storage, ensuring that the private key is protected throughout the TLS handshake process.</p>"},{"location":"platforms/","title":"Supported Platforms","text":"<p>Kotbase provides a common Kotlin Multiplatform API for Couchbase Lite, allowing you to develop a single Kotlin shared library, which compiles to native binaries that can be consumed by native apps on each of the supported platforms: Android, JVM, iOS, macOS, Linux, and Windows.</p>"},{"location":"platforms/#android-jvm","title":"Android  + JVM","text":"<p>Kotbase implements support for JVM desktop and Android apps via the Couchbase Lite Java and Android SDKs. Kotbase's API mirrors the Java SDK as much as feasible, which allows for smooth migration for existing Kotlin code currently utilizing either the Java or Android KTX SDKs. See Differences from Couchbase Lite Java SDK for details about where the APIs differ.</p> <p>Kotbase will pull in the correct Couchbase Lite Java dependencies via Gradle.</p>"},{"location":"platforms/#minification","title":"Minification","text":"<p>An application that enables ProGuard minification must ensure that certain pieces of Couchbase Lite library code are not changed.</p> Near-minimal rule set that retains the needed code proguard-rules.pro<pre><code>-dontwarn edu.umd.cs.findbugs.annotations.SuppressFBWarnings\n\n-keep class com.couchbase.lite.ConnectionStatus { &lt;init&gt;(...); }\n-keep class com.couchbase.lite.LiteCoreException { static &lt;methods&gt;; }\n-keep class com.couchbase.lite.internal.replicator.CBLTrustManager {\n    public java.util.List checkServerTrusted(java.security.cert.X509Certificate[], java.lang.String, java.lang.String);\n}\n-keep interface com.couchbase.lite.internal.ReplicationCollection$C4Filter\n-keep class com.couchbase.lite.internal.ReplicationCollection {\n    static &lt;methods&gt;;\n    &lt;fields&gt;;\n}\n-keep class com.couchbase.lite.internal.fleece.FLSliceResult { static &lt;methods&gt;; }\n-keep class com.couchbase.lite.internal.core.C4* {\n    static &lt;methods&gt;;\n    &lt;fields&gt;;\n    &lt;init&gt;(...);\n}\n</code></pre>"},{"location":"platforms/#android","title":"Android","text":"API x86 x64 ARM32 ARM64 22+"},{"location":"platforms/#jvm","title":"JVM","text":"JDK Linux x64 macOS x64 Windows x64 8+"},{"location":"platforms/#jvm-on-linux","title":"JVM on Linux","text":"<p>Targeting JVM running on Linux requires a specific version of the libicu dependency. (You will see an error such as <code>libLiteCore.so: libicuuc.so.71: cannot open shared object file: No such file or directory</code> indicating the expected version.) If the required version isn't available from your distribution's package manager, you can download it from GitHub.</p>"},{"location":"platforms/#ios-macos","title":"iOS + macOS","text":"<p>Kotbase supports native iOS and macOS apps via the Couchbase Lite Objective-C SDK. Developers with experience using Couchbase Lite in Swift should find Kotbase's API in Kotlin familiar.</p> <p>Binaries need to link with the correct version of the <code>CouchbaseLite</code> XCFramework, which can be downloaded here or added via Carthage or CocoaPods. The version should match the major and minor version of Kotbase, e.g. CouchbaseLite 3.2.x for Kotbase 3.2.4-1.2.0.</p> <p>The Kotlin CocoaPods Gradle plugin can also be used to generate a Podspec for your project that includes the <code>CouchbaseLite</code> dependency. Use <code>linkOnly = true</code> to link the dependency without generating Kotlin Objective-C interop:</p> <p>CocoaPods plugin</p> Enterprise EditionCommunity Edition build.gradle.kts<pre><code>plugins {\n    kotlin(\"multiplatform\")\n    kotlin(\"native.cocoapods\")\n}\n\nkotlin {\n    cocoapods {\n        ...\n        pod(\"CouchbaseLite-Enterprise\", version = \"3.2.4\", linkOnly = true)\n    }\n}\n</code></pre> build.gradle.kts<pre><code>plugins {\n    kotlin(\"multiplatform\")\n    kotlin(\"native.cocoapods\")\n}\n\nkotlin {\n    cocoapods {\n        ...\n        pod(\"CouchbaseLite\", version = \"3.2.4\", linkOnly = true)\n    }\n}\n</code></pre>"},{"location":"platforms/#ios","title":"iOS","text":"Version x64 ARM64 10+"},{"location":"platforms/#macos","title":"macOS","text":"Version x64 ARM64 10.14+"},{"location":"platforms/#linux-windows","title":"Linux  + Windows","text":"<p>Experimental support for Linux and Windows is provided via the Couchbase Lite C SDK. Core functionality should be mostly stable, however these platforms have not been tested in production. There are some tests that have slightly different behavior in a few edge cases and others that are failing that need further debugging. See comments in tests marked <code>@IgnoreLinuxMingw</code> for details.</p> <p>There are a few Enterprise Edition features that are not implemented in the Couchbase Lite C SDK. Kotbase will throw an <code>UnsupportedOperationException</code> if these APIs are called from these platforms.</p> <p>Binaries need to link with the correct version of the native platform <code>libcblite</code> binary, which can be downloaded here or here. The version should match the major and minor version of Kotbase, e.g. libcblite 3.2.x for Kotbase 3.2.4-1.2.0.</p>"},{"location":"platforms/#linux","title":"Linux","text":"<p>Linux also requires libz, libicu, and libpthread, which may or may not be installed on your system.</p> <p>Targeting Linux requires a specific version of the libicu dependency. (You will see an error such as <code>libLiteCore.so: libicuuc.so.71: cannot open shared object file: No such file or directory</code> indicating the expected version.) If the required version isn't available from your distribution's package manager, you can download it from GitHub.</p> Distro Version x64 ARM64 Debian 9+ Raspberry Pi OS 10+ Ubuntu 20.04+"},{"location":"platforms/#using-apt","title":"Using APT","text":"<p>Using the Advanced Package Tool (apt) is the easiest way to install Couchbase Lite on Ubuntu and Debian platforms. Just download the meta package that apt requires to automatically get and install Couchbase Lite, including any dependencies.</p> <ol> <li> <p>Download the meta package</p> curlwget <pre><code>curl -O https://packages.couchbase.com/releases/couchbase-release/couchbase-release-1.0-noarch.deb\n</code></pre> <pre><code>wget https://packages.couchbase.com/releases/couchbase-release/couchbase-release-1.0-noarch.deb\n</code></pre> </li> <li> <p>Install the meta package</p> aptdpkg <pre><code>sudo apt install ./couchbase-release-1.0-noarch.deb\n</code></pre> <pre><code>sudo dpkg -i ./couchbase-release-1.0-noarch.deb\n</code></pre> </li> <li> <p>Update the local package database</p> <pre><code>sudo apt update\n</code></pre> </li> <li> <p>Install the required release package(s)</p> EnterpriseCommunity <p>Runtime Only<pre><code>sudo apt install libcblite\n</code></pre> Development<pre><code>sudo apt install libcblite-dev\n</code></pre></p> <p>Runtime Only<pre><code>sudo apt install libcblite-community\n</code></pre> Development<pre><code>sudo apt install libcblite-dev-community\n</code></pre></p> </li> </ol>"},{"location":"platforms/#windows","title":"Windows","text":"Version x64 10+"},{"location":"prebuilt-database/","title":"Pre-built Database","text":"<p>How to include a snapshot of a pre-built database in your Couchbase Lite app package to shorten initial sync time and reduce bandwidth use</p>"},{"location":"prebuilt-database/#overview","title":"Overview","text":"<p>Couchbase Lite supports pre-built databases. You can pre-load your app with data instead of syncing it from Sync Gateway during startup to minimize consumer wait time (arising from data setup) on initial install and launch of the application.</p> <p>Avoiding an initial bulk sync reduces startup time and network transfer costs.</p> <p>It is typically more efficient to download bulk data using the http/ftp stream employed during the application installation than to install a smaller application bundle and then use a replicator to pull in the bulk data.</p> <p>Pre-loaded data is typically public/shared, non-user-specific data that is static. Even if the data is not static, you can still benefit from preloading it and only syncing the changed documents on startup.</p> <p>The initial sync of any pre-built database pulls in any content changes on the server that occurred after its incorporation into the app, updating the database.</p> <p>To use a prebuilt database:</p> <ol> <li>Create a new Couchbase Lite database with the required dataset \u2014 see Creating Pre-built    Database</li> <li>Incorporate the pre-built database with your app bundle as an asset/resource \u2014 see Bundle a Database with an    Application</li> <li>Adjust the start-up logic of your app to check for the presence of the required database.    If the database doesn\u2019t already exist, create one using the bundled pre-built database. Initiate a sync to update    the data \u2014 see Using Pre-built Database on App Launch</li> </ol>"},{"location":"prebuilt-database/#creating-pre-built-database","title":"Creating Pre-built Database","text":"<p>These steps should form part of your build and release process:</p> <ol> <li> <p>Create a fresh Couchbase Lite database (every time)</p> <p>Important</p> <p>Always start with a fresh database for each app version; this ensures there are no checkpoint issues</p> <p>Otherwise: You will invalidate the cached checkpoint in the packaged database, and instead reuse the same database in your build process (for subsequent app versions).</p> </li> <li> <p>Pull the data from Sync Gateway into the new Couchbase Lite database</p> <p>Important</p> <p>Ensure the replication used to populate Couchbase Lite database uses the exact same remote URL and replication config parameters (channels and filters) as those your app will use when it is running.</p> <p>Otherwise: \u2026 there will be a checkpoint mismatch and the app will attempt to pull the data down again</p> <p>Don\u2019t, for instance, create a pre-built database against a staging Sync Gateway server and use it within a production app that syncs against a production Sync Gateway.</p> <p>You can use the cblite tool (<code>cblite cp</code>) for this \u2014 see cblite cp (export, import, push, pull) | cblite on GitHub</p> <p>Alternatively \u2026</p> <ul> <li>You can write a simple CBL app to just initiate the required pull sync \u2014 see Remote Sync Gateway</li> <li>A third party community Java app is available. It provides a UI to create a local Couchbase Lite database and pull   data from a Sync Gateway database \u2014 see CouchbaseLite Tester.</li> </ul> </li> <li> <p>Create the same indexes the app will use (wait for the replication to finish before doing this).</p> </li> </ol>"},{"location":"prebuilt-database/#bundle-a-database-with-an-application","title":"Bundle a Database with an Application","text":"<p>Copy the database into your app package.</p> <p>Put it in an appropriate place (for example, an assets or resource folder).</p> <p>Where the platform permits you can zip the database.</p> <p>Alternatively \u2026 rather than bundling the database within the app, the app could pull the database down from a CDN server on launch.</p>"},{"location":"prebuilt-database/#database-encryption","title":"Database Encryption","text":"<p>This is an Enterprise Edition feature.</p> <p>If you are using an encrypted database, <code>Database.copy()</code> does not change the encryption key. The encryption key specified in the config when opening the database is the encryption key used for both the original database and copied database.</p> <p>If you copied an un-encrypted database and want to apply encryption to the copy, or if you want to change (or remove) the encryption key applied to the copy:</p> <ol> <li>Provide the original encryption-key (if any) in the database copy\u2019s configuration using    <code>DatabaseConfiguration.setEncryptionKey()</code>.</li> <li>Open the database copy.</li> <li>Use <code>Database.changeEncryptionKey()</code> on the database    copy to set the required encryption key.    NOTE: To remove encryption on the copy, provide a null encryption-key.</li> </ol>"},{"location":"prebuilt-database/#using-pre-built-database-on-app-launch","title":"Using Pre-built Database on App Launch","text":"<p>During the application start-up logic, check if database exists in the required location, and if not:</p> <ol> <li>Locate the pre-packaged database (for example, in the assets or other resource folder).</li> <li> <p>Copy the pre-packaged database to the required location.</p> <p>Use the API\u2019s <code>Database.copy()</code> method \u2014 see: Example 1; this ensures that a UUID is generated for each copy.</p> <p>Important</p> <p>Do not copy the database using any other method</p> <p>Otherwise: Each copy of the app will invalidate the other apps' checkpoints because a new UUID was not generated.</p> </li> <li> <p>Open the database; you can now start querying the data and using it.</p> </li> <li> <p>Start a pull replication, to sync any changes.</p> <p>The replicator uses the pre-built database\u2019s checkpoint as the timestamp to sync from; only documents changed since then are synced.</p> <p>Important</p> <p>If you used cblite to pull the data without including a port number with the URL and are replicating in a Java or iOS (swift/ObjC) app \u2014 you must include the port number in the URL provided to the replication (port 443 for <code>wss://</code> or 80 for <code>ws://</code>).</p> <p>Otherwise: You will get a checkpoint mismatch. This is caused by a URL discrepancy, which arises because <code>cblite</code> automatically adds the default port number when none is specified, but the Java and iOS (swift/ObjC) replicators DO NOT.</p> <p>Note</p> <p>Start your normal application logic immediately, unless it is essential to have the absolute up-to-date data set to begin. That way the user is not kept hanging around watching a progress indicator. They can begin interacting with your app whilst any out-of-data data is being updated.</p> </li> </ol> <p>Example 1. Copy database using API</p> <p>Note</p> <p>Getting the path to a database and package resources is platform-specific.</p> <p>You may need to extract the database from your package resources to a temporary directory and then copy it, using <code>Database.copy()</code>.</p> <pre><code>if (Database.exists(\"travel-sample\") {\n    return\n}\nval pathToPrebuiltDb = getPrebuiltDbPathFromResources()\nDatabase.copy(\n    pathToPrebuiltDb,\n    \"travel-sample\",\n    DatabaseConfiguration()\n)\n</code></pre>"},{"location":"query-builder/","title":"QueryBuilder","text":"<p>How to use <code>QueryBuilder</code> to build effective queries with Kotbase</p> <p>Note</p> <p>The examples used here are based on the Travel Sample app and data introduced in the Couchbase Mobile Workshop tutorial.</p>"},{"location":"query-builder/#introduction","title":"Introduction","text":"<p>Kotbase provides two ways to build and run database queries; the <code>QueryBuilder</code> API described in this topic and SQL++ for Mobile.</p> <p>Database queries defined with the <code>QueryBuilder</code> API use the query statement format shown in Example 1. The structure and semantics of the query format are based on Couchbase\u2019s SQL++ query language.</p> <p>Example 1. Query Format</p> <pre><code>SELECT ____\nFROM 'data-source'\nWHERE ____,\nJOIN ____\nGROUP BY ____\nORDER BY ____\n</code></pre> <p>Query Components</p> Component Description SELECT statement The document properties that will be returned in the result set FROM The data source to query the documents from \u2014 the collection of the database WHERE statement The query criteriaThe <code>SELECT</code>ed properties of documents matching this criteria will be returned in the result set JOIN statement The criteria for joining multiple documents GROUP BY statement The criteria used to group returned items in the result set ORDER BY statement The criteria used to order the items in the result set <p>Tip</p> <p>We recommend working through the query section of the Couchbase Mobile Workshop tutorial as a good way to build your skills in this area.</p> <p>Tip</p> <p>The examples in the documentation use the official Couchbase Lite query builder APIs, available in the Kotbase core artifacts. Many queries can take advantage of the concise <code>infix</code> function query builder APIs available in the Kotbase KTX extensions.</p>"},{"location":"query-builder/#select-statement","title":"SELECT statement","text":"<p>In this section Return All Properties | Return Selected Properties </p> <p>Related Result Sets</p> <p>Use the <code>SELECT</code> statement to specify which properties you want to return from the queried documents. You can opt to retrieve entire documents, or just the specific properties you need.</p>"},{"location":"query-builder/#return-all-properties","title":"Return All Properties","text":"<p>Use the <code>SelectResult.all()</code> method to return all the properties of selected documents \u2014 see Example 2.</p> <p>Example 2. Using SELECT to Retrieve All Properties</p> <p>This query shows how to retrieve all properties from all documents in a collection.</p> <pre><code>val queryAll = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"hotel\")))\n</code></pre> <p>The <code>Query.execute()</code> statement returns the results in a dictionary, where the key is the database name \u2014 see Example 3.</p> <p>Example 3. ResultSet Format from SelectResult.all()</p> <pre><code>[\n  {\n    \"travel-sample\": { // The result for the first document matching the query criteria.\n      \"callsign\": \"MILE-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"Q5\",\n      \"icao\": \"MLA\",\n      \"id\": 10,\n      \"name\": \"40-Mile Air\",\n      \"type\": \"airline\"\n    }\n  },\n  {\n    \"travel-sample\": { // The result for the next document matching the query criteria.\n      \"callsign\": \"ALASKAN-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"AA\",\n      \"icao\": \"AAA\",\n      \"id\": 10,\n      \"name\": \"Alaskan Airways\",\n      \"type\": \"airline\"\n    }\n  }\n]\n</code></pre> <p>See Result Sets for more on processing query results.</p>"},{"location":"query-builder/#return-selected-properties","title":"Return Selected Properties","text":"<p>To access only specific properties, specify a comma-separated list of <code>SelectResult</code> expressions, one for each property, in the select statement of your query \u2014 see Example 4.</p> <p>Example 4. Using SELECT to Retrieve Specific Properties</p> <p>In this query we retrieve and then print the <code>_id</code>, <code>type</code>, and <code>name</code> properties of each document.</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"name\"),\n        SelectResult.property(\"type\")\n    )\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"hotel\")))\n    .orderBy(Ordering.expression(Meta.id))\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"hotel id -&gt; ${it.getString(\"id\")}\")\n        println(\"hotel name -&gt; ${it.getString(\"name\")}\")\n    }\n}\n</code></pre> <p>The <code>Query.execute()</code> statement returns one or more key-value pairs, one for each <code>SelectResult</code> expression, with the property-name as the key \u2014 see Example 5.</p> <p>Example 5. Select Result Format</p> <pre><code>[\n  { // The result for the first document matching the query criteria.\n    \"id\": \"hotel123\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Ghia\"\n  },\n  { // The result for the next document matching the query criteria.\n    \"id\": \"hotel456\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Deluxe\"\n  }\n]\n</code></pre> <p>See Result Sets for more on processing query results.</p>"},{"location":"query-builder/#where-statement","title":"WHERE statement","text":"<p>In this section Comparison Operators | Collection Operators | Like Operator | Regex Operator | Deleted Document</p> <p>Like SQL, you can use the <code>WHERE</code> statement to choose which documents are returned by your query. The <code>where()</code> statement takes in an <code>Expression</code>. You can chain any number of <code>Expression</code>s in order to implement sophisticated filtering capabilities.</p>"},{"location":"query-builder/#comparison-operators","title":"Comparison Operators","text":"<p>The <code>Expression</code> Comparators can be used in the <code>WHERE</code> statement to specify on which property to match documents. In the example below, we use the <code>equalTo</code> operator to query documents where the <code>type</code> property equals \"hotel\".</p> <pre><code>[\n  { \n    \"id\": \"hotel123\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Ghia\"\n  },\n  { \n    \"id\": \"hotel456\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Deluxe\"\n  }\n]\n</code></pre> <p>Example 6. Using Where</p> <pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"hotel\")))\n    .limit(Expression.intValue(10))\n\nquery.execute().use { rs -&gt;\n    rs.forEach { result -&gt;\n        result.getDictionary(\"myDatabase\")?.let {\n            println(\"name -&gt; ${it.getString(\"name\")}\")\n            println(\"type -&gt; ${it.getString(\"type\")}\")\n        }\n    }\n}\n</code></pre>"},{"location":"query-builder/#collection-operators","title":"Collection Operators","text":"<p><code>ArrayFunction</code> Collection Operators are useful to check if a given value is present in an array.</p>"},{"location":"query-builder/#contains-operator","title":"CONTAINS Operator","text":"<p>The following example uses the <code>ArrayFunction</code> to find documents where the <code>public_likes</code> array property contains a value equal to \"Armani Langworth\".</p> <pre><code>{\n  \"_id\": \"hotel123\",\n  \"name\": \"Apple Droid\",\n  \"public_likes\": [\"Armani Langworth\", \"Elfrieda Gutkowski\", \"Maureen Ruecker\"]\n}\n</code></pre> <p>Example 7. Using the CONTAINS operator</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"name\"),\n        SelectResult.property(\"public_likes\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"hotel\"))\n            .and(\n                ArrayFunction.contains(\n                    Expression.property(\"public_likes\"),\n                    Expression.string(\"Armani Langworth\")\n                )\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"public_likes -&gt; ${it.getArray(\"public_likes\")?.toList()}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#in-operator","title":"IN Operator","text":"<p>The <code>IN</code> operator is useful when you need to explicitly list out the values to test against. The following example looks for documents whose <code>first</code>, <code>last</code>, or <code>username</code> property value equals \"Armani\".</p> <p>Example 8. Using the IN operator</p> <pre><code>val query = QueryBuilder.select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.string(\"Armani\").`in`(\n            Expression.property(\"first\"),\n            Expression.property(\"last\"),\n            Expression.property(\"username\")\n        )\n    )\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"public_likes -&gt; ${it.toMap()}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#like-operator","title":"Like Operator","text":"<p>In this section String Matching | Wildcard Match | Wildcard Character Match</p>"},{"location":"query-builder/#string-matching","title":"String Matching","text":"<p>The <code>like()</code> operator can be used for string matching \u2014 see Example 9.</p> <p>Note</p> <p>The <code>like</code> operator performs case sensitive matches. To perform case insensitive matching, use <code>Function.lower</code> or <code>Function.upper</code> to ensure all comparators have the same case, thereby removing the case issue.</p> <p>This query returns <code>landmark</code> type documents where the <code>name</code> matches the string \"Royal Engineers Museum\", regardless of how it is capitalized (so, it selects \"royal engineers museum\", \"ROYAL ENGINEERS MUSEUM\" and so on).</p> <p>Example 9. Like with case-insensitive matching</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"landmark\"))\n            .and(\n                Function.lower(Expression.property(\"name\"))\n                    .like(Expression.string(\"royal engineers museum\"))\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"name -&gt; ${it.getString(\"name\")}\")\n    }\n}\n</code></pre> <p>Note the use of <code>Function.lower()</code> to transform <code>name</code> values to the same case as the literal comparator.</p>"},{"location":"query-builder/#wildcard-match","title":"Wildcard Match","text":"<p>We can use <code>%</code> sign within a <code>like</code> expression to do a wildcard match against zero or more characters. Using wildcards allows you to have some fuzziness in your search string.</p> <p>In Example 10 below, we are looking for documents of <code>type</code> \"landmark\" where the name property matches any string that begins with \"eng\" followed by zero or more characters, the letter \"e\", followed by zero or more characters. Once again, we are using <code>Function.lower()</code> to make the search case-insensitive.</p> <p>So the query returns \"landmark\" documents with names such as \"Engineers\", \"engine\", \"english egg\" and \"England Eagle\". Notice that the matches may span word boundaries.</p> <p>Example 10. Wildcard Matches</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"landmark\"))\n            .and(\n                Function.lower(Expression.property(\"name\"))\n                    .like(Expression.string(\"eng%e%\"))\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"name -&gt; ${it.getString(\"name\")}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#wildcard-character-match","title":"Wildcard Character Match","text":"<p>We can use an <code>_</code> sign within a <code>like</code> expression to do a wildcard match against a single character.</p> <p>In Example 11 below, we are looking for documents of type \"landmark\" where the <code>name</code> property matches any string that begins with \"eng\" followed by exactly 4 wildcard characters and ending in the letter \"r\". The query returns \"landmark\" type documents with names such as \"Engineer\", \"engineer\" and so on.</p> <p>Example 11. Wildcard Character Matching</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"landmark\"))\n            .and(\n                Function.lower(Expression.property(\"name\"))\n                    .like(Expression.string(\"eng____r\"))\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"name -&gt; ${it.getString(\"name\")}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#regex-operator","title":"Regex Operator","text":"<p>Similar to the wildcards in <code>like</code> expressions, <code>regex</code> based pattern matching allow you to introduce an element of fuzziness in your search string \u2014 see the code shown in Example 12.</p> <p>Note</p> <p>The <code>regex</code> operator is case sensitive, use <code>upper</code> or <code>lower</code> functions to mitigate this if required.</p> <p>Example 12. Using Regular Expressions</p> <p>This example returns documents with a <code>type</code> of \"landmark\" and a <code>name</code> property that matches any string that begins with \"eng\" and ends in the letter \"e\".</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"landmark\"))\n            .and(\n                Function.lower(Expression.property(\"name\"))\n                    .regex(Expression.string(\"\\\\beng.*r\\\\b\"))\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"name -&gt; ${it.getString(\"name\")}\")\n    }\n}\n</code></pre> <p>The <code>\\b</code> specifies that the match must occur on word boundaries.</p> <p>Tip</p> <p>For more on the regex spec used by Couchbase Lite see cplusplus regex reference page.</p>"},{"location":"query-builder/#deleted-document","title":"Deleted Document","text":"<p>You can query documents that have been deleted (tombstones) as shown in Example 13.</p> <p>Example 13. Query to select Deleted Documents</p> <p>This example shows how to query deleted documents in the database. It returns is an array of key-value pairs.</p> <pre><code>// Query documents that have been deleted\nval query = QueryBuilder\n    .select(SelectResult.expression(Meta.id))\n    .from(DataSource.collection(collection))\n    .where(Meta.deleted)\n</code></pre>"},{"location":"query-builder/#join-statement","title":"JOIN statement","text":"<p>The <code>JOIN</code> clause enables you to select data from multiple documents that have been linked by criteria specified in the <code>JOIN</code> statement. For example to combine airline details with route details, linked by the airline id \u2014 see Example 14 .</p> <p>Example 14. Using JOIN to Combine Document Details</p> <p>This example JOINS the document of <code>type</code> \"route\" with documents of <code>type</code> \"airline\" using the document ID (<code>_id</code>) on the airline document and <code>airlineid</code> on the route document.</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Expression.property(\"name\").from(\"airline\")),\n        SelectResult.expression(Expression.property(\"callsign\").from(\"airline\")),\n        SelectResult.expression(Expression.property(\"destinationairport\").from(\"route\")),\n        SelectResult.expression(Expression.property(\"stops\").from(\"route\")),\n        SelectResult.expression(Expression.property(\"airline\").from(\"route\"))\n    )\n    .from(DataSource.collection(airlineCollection).`as`(\"airline\"))\n    .join(\n        Join.join(DataSource.collection(routeCollection).`as`(\"route\"))\n            .on(\n                Meta.id.from(\"airline\")\n                    .equalTo(Expression.property(\"airlineid\").from(\"route\"))\n            )\n    )\n    .where(\n        Expression.property(\"type\").from(\"route\").equalTo(Expression.string(\"route\"))\n            .and(\n                Expression.property(\"type\").from(\"airline\")\n                    .equalTo(Expression.string(\"airline\"))\n            )\n            .and(\n                Expression.property(\"sourceairport\").from(\"route\")\n                    .equalTo(Expression.string(\"RIX\"))\n            )\n    )\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"name -&gt; ${it.toMap()}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#group-by-statement","title":"GROUP BY statement","text":"<p>You can perform further processing on the data in your result set before the final projection is generated.</p> <p>The following example looks for the number of airports at an altitude of 300 ft or higher and groups the results by country and timezone.</p> Data Model for Example<pre><code>{\n  \"_id\": \"airport123\",\n  \"type\": \"airport\",\n  \"country\": \"United States\",\n  \"geo\": { \"alt\": 456 },\n  \"tz\": \"America/Anchorage\"\n}\n</code></pre> <p>Example 15. Query using GroupBy</p> <p>This example shows a query that selects all airports with an altitude above 300ft. The output (a count, $1) is grouped by country, within timezone.</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Function.count(Expression.string(\"*\"))),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"tz\")\n    )\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").equalTo(Expression.string(\"airport\"))\n            .and(Expression.property(\"geo.alt\").greaterThanOrEqualTo(Expression.intValue(300)))\n    )\n    .groupBy(\n        Expression.property(\"country\"), Expression.property(\"tz\")\n    )\n    .orderBy(Ordering.expression(Function.count(Expression.string(\"*\"))).descending())\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\n            \"There are ${it.getInt(\"$1\")} airports on the ${\n                it.getString(\"tz\")\n            } timezone located in ${\n                it.getString(\"country\")\n            } and above 300ft\"\n        )\n    }\n}\n</code></pre> <p>The query shown in Example 15 generates the following output:</p> <p>There are 138 airports on the Europe/Paris timezone located in France and above 300 ft There are 29 airports on the Europe/London timezone located in United Kingdom and above 300 ft There are 50 airports on the America/Anchorage timezone located in United States and above 300 ft There are 279 airports on the America/Chicago timezone located in United States and above 300 ft There are 123 airports on the America/Denver timezone located in United States and above 300 ft</p>"},{"location":"query-builder/#order-by-statement","title":"ORDER BY statement","text":"<p>It is possible to sort the results of a query based on a given expression result \u2014 see Example 16.</p> <p>Example 16. Query using OrderBy</p> <p>This example shows a query that returns documents of <code>type</code> equal to \"hotel\" sorted in ascending order by the value of the <code>title</code> property.</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"hotel\")))\n    .orderBy(Ordering.property(\"name\").ascending())\n    .limit(Expression.intValue(10))\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n        println(\"${it.toMap()}\")\n    }\n}\n</code></pre> <p>The query shown in Example 16 generates the following output:</p> <p>Aberdyfi Achiltibuie Altrincham Ambleside Annan Ard\u00e8che Armagh Avignon</p>"},{"location":"query-builder/#datetime-functions","title":"Date/Time Functions","text":"<p>Couchbase Lite documents support a date type that internally stores dates in ISO 8601 with the GMT/UTC timezone.</p> <p>Couchbase Lite\u2019s Query Builder API includes four functions for date comparisons.</p> <p><code>Function.stringToMillis(Expression.property(\"date_time\"))</code> The input to this will be a validly formatted ISO 8601 <code>date_time</code> string. The end result will be an expression (with a numeric content) that can be further input into the query builder.</p> <p><code>Function.stringToUTC(Expression.property(\"date_time\"))</code> The input to this will be a validly formatted ISO 8601 <code>date_time</code> string. The end result will be an expression (with string content) that can be further input into the query builder.</p> <p><code>Function.millisToString(Expression.property(\"date_time\"))</code> The input for this is a numeric value representing milliseconds since the Unix epoch. The end result will be an expression (with string content representing the date and time as an ISO 8601 string in the device\u2019s timezone) that can be further input into the query builder.</p> <p><code>Function.millisToUTC(Expression.property(\"date_time\"))</code> The input for this is a numeric value representing milliseconds since the Unix epoch. The end result will be an expression (with string content representing the date and time as a UTC ISO 8601 string) that can be further input into the query builder.</p>"},{"location":"query-builder/#result-sets","title":"Result Sets","text":"<p>In this section Processing | Select All Properties | Select Specific Properties | Select Document ID Only | Select Count-only | Handling Pagination</p>"},{"location":"query-builder/#processing","title":"Processing","text":"<p>This section shows how to handle the returned result sets for different types of <code>SELECT</code> statements.</p> <p>The result set format and its handling varies slightly depending on the type of <code>SelectResult</code> statements used. The result set formats you may encounter include those generated by:</p> <ul> <li><code>SelectResult.all()</code> \u2014 see All Properties</li> <li><code>SelectResult.property(\"name\")</code> \u2014 see Specific Properties</li> <li><code>SelectResult.expression(Meta.id)</code> \u2014 Metadata (such as the <code>_id</code>) \u2014 see Document ID Only</li> <li><code>SelectResult.expression(Function.count(Expression.all())).as(\"mycount\")</code> \u2014 see Select   Count-only</li> </ul> <p>To process the results of a query, you first need to execute it using <code>Query.execute()</code>.</p> <p>The execution of a Kotbase database query typically returns an array of results, a result set.</p> <ul> <li>The result set of an aggregate, count-only, query is a key-value pair \u2014 see Select Count-only \u2014   which you can access using the count name as its key.</li> <li>The result set of a query returning document properties is an array.   Each array row represents the data from a document that matched your search criteria (the <code>WHERE</code> statements). The   composition of each row is determined by the combination of <code>SelectResult</code> expressions provided in the <code>SELECT</code>   statement. To unpack these result sets you need to iterate this array.</li> </ul>"},{"location":"query-builder/#select-all-properties","title":"Select All Properties","text":""},{"location":"query-builder/#query","title":"Query","text":"<p>The <code>Select</code> statement for this type of query, returns all document properties for each document matching the query criteria \u2014 see Example 17.</p> <p>Example 17. Query selecting All Properties</p> <pre><code>val query = QueryBuilder.select(SelectResult.all())\n    .from(DataSource.collection(collection))\n</code></pre>"},{"location":"query-builder/#result-set-format","title":"Result Set Format","text":"<p>The result set returned by queries using <code>SelectResult.all()</code> is an array of dictionary objects \u2014 one for each document matching the query criteria.</p> <p>For each result object, the key is the database name and the value is a dictionary representing each document property as a key-value pair \u2014 see Example 18.</p> <p>Example 18. Format of Result Set (All Properties)</p> <pre><code>[\n  {\n    \"travel-sample\": { // The result for the first document matching the query criteria.\n      \"callsign\": \"MILE-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"Q5\",\n      \"icao\": \"MLA\",\n      \"id\": 10,\n      \"name\": \"40-Mile Air\",\n      \"type\": \"airline\"\n    }\n  },\n  {\n    \"travel-sample\": { // The result for the next document matching the query criteria.\n      \"callsign\": \"ALASKAN-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"AA\",\n      \"icao\": \"AAA\",\n      \"id\": 10,\n      \"name\": \"Alaskan Airways\",\n      \"type\": \"airline\"\n    }\n  }\n]\n</code></pre>"},{"location":"query-builder/#result-set-access","title":"Result Set Access","text":"<p>In this case access the retrieved document properties by converting each row\u2019s value, in turn, to a dictionary \u2014 as shown in Example 19.</p> <p>Example 19. Using Document Properties (All)</p> <pre><code>val hotels = mutableMapOf&lt;String, Hotel&gt;()\nquery.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        // get the k-v pairs from the 'hotel' key's value into a dictionary\n        val docProps = it.getDictionary(0) \n        val docId = docProps!!.getString(\"id\")\n        val docName = docProps.getString(\"name\")\n        val docType = docProps.getString(\"type\")\n        val docCity = docProps.getString(\"city\")\n\n        // Alternatively, access results value dictionary directly\n        val id = it.getDictionary(0)?.getString(\"id\")!!\n        hotels[id] = Hotel(\n            id,\n            it.getDictionary(0)?.getString(\"type\"),\n            it.getDictionary(0)?.getString(\"name\"),\n            it.getDictionary(0)?.getString(\"city\"),\n            it.getDictionary(0)?.getString(\"country\"),\n            it.getDictionary(0)?.getString(\"description\")\n        )\n    }\n}\n</code></pre>"},{"location":"query-builder/#select-specific-properties","title":"Select Specific Properties","text":""},{"location":"query-builder/#query_1","title":"Query","text":"<p>Here we use <code>SelectResult.property(\"&lt;property-name&gt;\")</code> to specify the document properties we want our query to return \u2014 see Example 20.</p> <p>Example 20. Query selecting Specific Properties</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"country\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n</code></pre>"},{"location":"query-builder/#result-set-format_1","title":"Result Set Format","text":"<p>The result set returned when selecting only specific document properties is an array of dictionary objects \u2014 one for each document matching the query criteria.</p> <p>Each result object comprises a key-value pair for each selected document property \u2014 see Example 21.</p> <p>Example 21. Format of Result Set (Specific Properties)</p> <pre><code>[\n  { // The result for the first document matching the query criteria.\n    \"id\": \"hotel123\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Ghia\"\n  },\n  { // The result for the next document matching the query criteria.\n    \"id\": \"hotel456\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Deluxe\",\n  }\n]\n</code></pre>"},{"location":"query-builder/#result-set-access_1","title":"Result Set Access","text":"<p>Access the retrieved properties by converting each row into a dictionary \u2014 as shown in Example 22.</p> <p>Example 22. Using Returned Document Properties (Specific Properties)</p> <pre><code>query.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        println(\"Hotel name -&gt; ${it.getString(\"name\")}, in ${it.getString(\"country\")}\")\n    }\n}\n</code></pre>"},{"location":"query-builder/#select-document-id-only","title":"Select Document ID Only","text":""},{"location":"query-builder/#query_2","title":"Query","text":"<p>You would typically use this type of query if retrieval of document properties directly would consume excessive amounts of memory and-or processing time \u2014 see Example 23.</p> <p>Example 23. Query selecting only Doc ID</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id).`as`(\"hotelId\")\n    )\n    .from(DataSource.collection(collection))\n</code></pre>"},{"location":"query-builder/#result-set-format_2","title":"Result Set Format","text":"<p>The result set returned by queries using a <code>SelectResult</code> expression of the form <code>SelectResult.expression(Meta.id)</code> is an array of dictionary objects \u2014 one for each document matching the query criteria. Each result object has <code>id</code> as the key and the ID value as its value \u2014 see Example 24.</p> <p>Example 24. Format of Result Set (Doc ID only)</p> <pre><code>[\n  {\n    \"id\": \"hotel123\"\n  },\n  {\n    \"id\": \"hotel456\"\n  }\n]\n</code></pre>"},{"location":"query-builder/#result-set-access_2","title":"Result Set Access","text":"<p>In this case, access the required document\u2019s properties by unpacking the <code>id</code> and using it to get the document from the database \u2014 see Example 25.</p> <p>Example 25. Using Returned Document Properties (Document ID)</p> <pre><code>query.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        // Extract the ID value from the dictionary\n        it.getString(\"hotelId\")?.let { hotelId -&gt;\n            println(\"hotel id -&gt; $hotelId\")\n            // use the ID to get the document from the database\n            val doc = collection.getDocument(hotelId)\n        }\n    }\n}\n</code></pre>"},{"location":"query-builder/#select-count-only","title":"Select Count-only","text":""},{"location":"query-builder/#query_3","title":"Query","text":"<p>Example 26. Query selecting a Count-only</p> <pre><code>val query = QueryBuilder\n    .select(\n        SelectResult.expression(Function.count(Expression.string(\"*\"))).`as`(\"mycount\")\n    ) \n    .from(DataSource.collection(collection))\n</code></pre> <p>The alias name, <code>mycount</code>, is used to access the count value.</p>"},{"location":"query-builder/#result-set-format_3","title":"Result Set Format","text":"<p>The result set returned by a count such as <code>Select.expression(Function.count(Expression.all)))</code> is a key-value pair. The key is the count name, as defined using <code>SelectResult.as()</code> \u2014 see Example 27 for the format and Example 26 for the query.</p> <p>Example 27. Format of Result Set (Count)</p> <pre><code>{\n  \"mycount\": 6\n}\n</code></pre> <p>The key-value pair returned by a count.</p>"},{"location":"query-builder/#result-set-access_3","title":"Result Set Access","text":"<p>Access the count using its alias name (<code>mycount</code> in this example) \u2014 see Example 28.</p> <p>Example 28. Using Returned Document Properties (Count)</p> <pre><code>query.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        printlnt(\"name -&gt; ${it.getInt(\"mycount\")}\")\n    }\n}\n</code></pre> <p>Get the count using the <code>SelectResult.as()</code> alias, which is used as its key.</p>"},{"location":"query-builder/#handling-pagination","title":"Handling Pagination","text":"<p>One way to handle pagination in high-volume queries is to retrieve the results in batches. Use the limit and offset feature, to return a defined number of results starting from a given offset \u2014 see Example 29.</p> <p>Example 29. Query Pagination</p> <pre><code>val thisOffset = 0\nval thisLimit = 20\nval query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .limit(\n        Expression.intValue(thisLimit),\n        Expression.intValue(thisOffset)\n    ) \n</code></pre> <p>Return a maximum of limit results starting from result number offset.</p> <p>Tip</p> <p>The Kotbase paging extensions provide a <code>PagingSource</code> to use with AndroidX Paging to assist loading and displaying pages of data in your app.</p> <p>Tip</p> <p>For more on using the <code>QueryBuilder</code> API, see our blog: Introducing the Query Interface in Couchbase Mobile</p>"},{"location":"query-builder/#json-result-sets","title":"JSON Result Sets","text":"<p>Kotbase provides a convenience API to convert query results to JSON strings.</p> <p>Use <code>Result.toJSON()</code> to transform your result into a JSON string, which can easily be serialized or used as required in your application. See Example 30 for a working example using kotlinx-serialization.</p> <p>Example 30. Using JSON Results</p> <pre><code>// Uses kotlinx-serialization JSON processor\n@Serializable\ndata class Hotel(val id: String, val type: String, val name: String)\n\nval hotels = mutableListOf&lt;Hotel&gt;()\n\nval query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"type\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n\n        // Get result as JSON string\n        val json = it.toJSON()\n\n        // Get JsonObject map from JSON string\n        val mapFromJsonString = Json.decodeFromString&lt;JsonObject&gt;(json)\n\n        // Use created JsonObject map\n        val hotelId = mapFromJsonString[\"id\"].toString()\n        val hotelType = mapFromJsonString[\"type\"].toString()\n        val hotelName = mapFromJsonString[\"name\"].toString()\n\n        // Get custom object from JSON string\n        val hotel = Json.decodeFromString&lt;Hotel&gt;(json)\n        hotels.add(hotel)\n    }\n}\n</code></pre>"},{"location":"query-builder/#json-string-format","title":"JSON String Format","text":"<p>If your query selects ALL then the JSON format will be:</p> <pre><code>{\n  database-name: {\n    key1: \"value1\",\n    keyx: \"valuex\"\n  }\n}\n</code></pre> <p>If your query selects a sub-set of available properties then the JSON format will be:</p> <pre><code>{\n  key1: \"value1\",\n  keyx: \"valuex\"\n}\n</code></pre>"},{"location":"query-builder/#predictive-query","title":"Predictive Query","text":"<p>This is an Enterprise Edition feature.</p> <p>Predictive Query enables Couchbase Lite queries to use machine learning, by providing query functions that can process document data (properties or blobs) via trained ML models.</p> <p>Let\u2019s consider an image classifier model that takes a picture as input and outputs a label and probability.</p> <p></p> <p>To run a predictive query with a model as the one shown above, you must implement the following steps:</p> <ol> <li>Integrate the Model</li> <li>Register the Model</li> <li>Create an Index (Optional)</li> <li>Run a Prediction Query</li> <li>Deregister the Model</li> </ol>"},{"location":"query-builder/#integrate-the-model","title":"Integrate the Model","text":"<p>To integrate a model with Couchbase Lite, you must implement the <code>PredictiveModel</code> interface which has only one function called <code>predict()</code> \u2014 see Example 31.</p> <p>Example 31. Integrating a predictive model</p> <pre><code>// tensorFlowModel is a fake implementation\nobject TensorFlowModel {\n    fun predictImage(data: ByteArray?): Map&lt;String, Any?&gt; = TODO()\n}\n\nobject ImageClassifierModel : PredictiveModel {\n    const val name = \"ImageClassifier\"\n\n    // this would be the implementation of the ml model you have chosen\n    override fun predict(input: Dictionary) = input.getBlob(\"photo\")?.let {\n        MutableDictionary(TensorFlowModel.predictImage(it.content)) \n    }\n}\n</code></pre> <p>The <code>predict(input) -&gt; output</code> method provides the input and expects the result of using the machine learning model. The input and output of the predictive model is a <code>Dictionary</code>. Therefore, the supported data type will be constrained by the data type that the <code>Dictionary</code> supports.</p>"},{"location":"query-builder/#register-the-model","title":"Register the Model","text":"<p>To register the model you must create a new instance and pass it to the <code>Database.prediction.registerModel()</code> static method.</p> <p>Example 32. Registering a predictive model</p> <pre><code>Database.prediction.registerModel(\"ImageClassifier\", ImageClassifierModel)\n</code></pre>"},{"location":"query-builder/#create-an-index","title":"Create an Index","text":"<p>Creating an index for a predictive query is highly recommended. By computing the predictions during writes and building a prediction index, you can significantly improve the speed of prediction queries (which would otherwise have to be computed during reads).</p> <p>There are two types of indexes for predictive queries:</p> <ul> <li>Value Index</li> <li>Predictive Index</li> </ul>"},{"location":"query-builder/#value-index","title":"Value Index","text":"<p>The code below creates a value index from the \"label\" value of the prediction result. When documents are added or updated, the index will call the prediction function to update the label value in the index.</p> <p>Example 33. Creating a value index</p> <pre><code>database.createIndex(\n    \"value-index-image-classifier\",\n    IndexBuilder.valueIndex(ValueIndexItem.expression(Expression.property(\"label\")))\n)\n</code></pre>"},{"location":"query-builder/#predictive-index","title":"Predictive Index","text":"<p>Predictive Index is a new index type used for predictive query. It differs from the value index in that it caches the predictive results and creates a value index from that cache when the predictive results values are specified.</p> <p>Example 34. Creating a predictive index</p> <p>Here we create a predictive index from the <code>label</code> value of the prediction result.</p> <pre><code>val inputMap: Map&lt;String, Any?&gt; = mapOf(\"numbers\" to Expression.property(\"photo\"))\ncollection.createIndex(\n    \"predictive-index-image-classifier\",\n    IndexBuilder.predictiveIndex(\"ImageClassifier\", Expression.map(inputMap), null)\n)\n</code></pre>"},{"location":"query-builder/#run-a-prediction-query","title":"Run a Prediction Query","text":"<p>The code below creates a query that calls the prediction function to return the \"label\" value for the first 10 results in the database.</p> <p>Example 35. Creating a value index</p> <pre><code>val inputMap: Map&lt;String, Any?&gt; = mapOf(\"photo\" to Expression.property(\"photo\"))\nval prediction: PredictionFunction = Function.prediction(\n    ImageClassifierModel.name,\n    Expression.map(inputMap)\n)\n\nval query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(\n        prediction.propertyPath(\"label\").equalTo(Expression.string(\"car\"))\n            .and(\n                prediction.propertyPath(\"probability\")\n                    .greaterThanOrEqualTo(Expression.doubleValue(0.8))\n            )\n    )\n\nquery.execute().use {\n    println(\"Number of rows: ${it.allResults().size}\")\n}\n</code></pre> <p>The <code>PredictiveModel.predict()</code> method returns a constructed <code>PredictionFunction</code> object which can be used further to specify a property value extracted from the output dictionary of the <code>PredictiveModel.predict()</code> function.</p> <p>Note</p> <p>The null value returned by the prediction method will be interpreted as MISSING value in queries.</p>"},{"location":"query-builder/#deregister-the-model","title":"Deregister the Model","text":"<p>To deregister the model you must call the <code>Database.prediction.unregisterModel()</code> static method.</p> <p>Example 36. Deregister a value index</p> <pre><code>Database.prediction.unregisterModel(\"ImageClassifier\")\n</code></pre>"},{"location":"query-result-sets/","title":"Query Result Sets","text":"<p>How to use Couchbase Lite Query\u2019s Result Sets</p>"},{"location":"query-result-sets/#query-execution","title":"Query Execution","text":"<p>The execution of a Couchbase Lite database query returns an array of results, a result set.</p> <p>Each row of the result set represents the data returned from a document that met the conditions defined by the <code>WHERE</code> statement of your query. The composition of each row is determined by the <code>SelectResult</code> expressions provided in the <code>SELECT</code> statement.</p>"},{"location":"query-result-sets/#returned-results","title":"Returned Results","text":"<p>Return All Document Properties | Return Document ID Only | Return Specific Properties Only</p> <p>The types of SelectResult formats you may encounter include those generated by :</p> <ul> <li><code>QueryBuilder.select(SelectResult.all())</code> \u2014 Using All</li> <li><code>QueryBuilder.select(SelectResult.expression(Meta.id))</code> \u2014 Using Doc ID Metadata such as   the <code>_id</code></li> <li><code>QueryBuilder.select(SelectResult.property(\"myProp\"))</code> \u2014 Using Specific Properties</li> </ul>"},{"location":"query-result-sets/#return-all-document-properties","title":"Return All Document Properties","text":"<p>The <code>SelectResult</code> returned by <code>SelectResult.all()</code> is a dictionary object, with the database name as the key and the document properties as an array of key-value pairs.</p> <p>Example 1. Returning All Properties</p> <pre><code>[\n  {\n    \"travel-sample\": { \n      \"callsign\": \"MILE-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"Q5\",\n      \"icao\": \"MLA\",\n      \"id\": 10,\n      \"name\": \"40-Mile Air\",\n      \"type\": \"airline\"\n    }\n  },\n  {\n    \"travel-sample\": { \n      \"callsign\": \"ALASKAN-AIR\",\n      \"country\": \"United States\",\n      \"iata\": \"AA\",\n      \"icao\": \"AAA\",\n      \"id\": 10,\n      \"name\": \"Alaskan Airways\",\n      \"type\": \"airline\"\n    }\n  }\n]\n</code></pre>"},{"location":"query-result-sets/#return-document-id-only","title":"Return Document ID Only","text":"<p>The <code>SelectResult</code> returned by queries using a <code>SelectResult</code> expression of the form <code>SelectResult.expression(Meta.id)</code> comprises a dictionary object with <code>id</code> as the key and the ID value as the value.</p> <p>Example 2. Returning Meta Properties \u2014 Document ID</p> <pre><code>[\n  {\n    \"id\": \"hotel123\"\n  },\n  {\n    \"id\": \"hotel456\"\n  }\n]\n</code></pre>"},{"location":"query-result-sets/#return-specific-properties-only","title":"Return Specific Properties Only","text":"<p>The <code>SelectResult</code> returned by queries using one or more <code>SelectResult</code> expressions of the form <code>SelectResult.expression(property(\"name\"))</code> comprises a key-value pair for each <code>SelectResult</code> expression in the query, the key being the property name.</p> <p>Example 3. Returning Specific Properties</p> <pre><code>[\n  { \n    \"id\": \"hotel123\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Ghia\"\n  },\n  { \n    \"id\": \"hotel456\",\n    \"type\": \"hotel\",\n    \"name\": \"Hotel Deluxe\",\n  }\n]\n</code></pre>"},{"location":"query-result-sets/#processing-results","title":"Processing Results","text":"<p>Access Document Properties \u2014 All Properties | Access Document Properties \u2014 ID | Access Document Properties \u2014 Selected Properties </p> <p>To retrieve the results of your query, you need to execute it using <code>Query.execute()</code>.</p> <p>The output from the execution is an array, with each array element representing the data from a document that matched your search criteria.</p> <p>To unpack the results you need to iterate through this array. Alternatively, you can convert the result to a JSON string \u2014 see: JSON Result Sets</p>"},{"location":"query-result-sets/#access-document-properties-all-properties","title":"Access Document Properties - All Properties","text":"<p>Here we look at how to access document properties when you have used <code>SelectResult.all()</code>.</p> <p>In this case each array element is a dictionary structure with the database name as its key. The properties are presented in the value as an array of key-value pairs (property name/property value).</p> <p>You access the retrieved document properties by converting each row\u2019s value, in turn, to a dictionary \u2014 as shown in Example 4.</p> <p>Example 4. Access All Properties</p> <pre><code>val hotels = mutableMapOf&lt;String, Hotel&gt;()\nquery.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        // get the k-v pairs from the 'hotel' key's value into a dictionary\n        val docProps = it.getDictionary(0)\n        val docId = docProps!!.getString(\"id\")\n        val docType = docProps.getString(\"type\")\n        val docName = docProps.getString(\"name\")\n        val docCity = docProps.getString(\"city\")\n\n        // Alternatively, access results value dictionary directly\n        val id = it.getDictionary(0)?.getString(\"id\")\n        hotels[id] = Hotel(\n            id,\n            it.getDictionary(0)?.getString(\"type\"),\n            it.getDictionary(0)?.getString(\"name\"),\n            it.getDictionary(0)?.getString(\"city\"),\n            it.getDictionary(0)?.getString(\"country\"),\n            it.getDictionary(0)?.getString(\"description\")\n        )\n    }\n}\n</code></pre>"},{"location":"query-result-sets/#access-document-properties-id","title":"Access Document Properties - ID","text":"<p>Here we look at how to access document properties when you have returned only the document IDs for documents that matched your selection criteria.</p> <p>This is something you may do when retrieval of the properties directly by the query may consume excessive amounts of memory and-or processing time.</p> <p>In this case each array element is a dictionary structure where <code>id</code> is the key and the required document ID is the value.</p> <p>Access the required document properties by retrieving the document from the database using its document ID \u2014 as shown in Example 5.</p> <p>Example 5. Access by ID</p> <pre><code>query.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        // Extract the ID value from the dictionary\n        it.getString(\"id\")?.let { hotelId -&gt;\n            println(\"hotel id -&gt; $hotelId\")\n            // use the ID to get the document from the database\n            val doc = collection.getDocument(hotelId)\n        }\n    }\n}\n</code></pre>"},{"location":"query-result-sets/#access-document-properties-selected-properties","title":"Access Document Properties - Selected Properties","text":"<p>Here we look at how to access properties when you have used <code>SelectResult</code> to get a specific subset of properties.</p> <p>In this case each array element is an array of key value pairs (property name/property value).</p> <p>Access the retrieved properties by converting each row into a dictionary \u2014 as shown in Example 6.</p> <p>Example 6. Access Selected Properties</p> <pre><code>query.execute().use { rs -&gt;\n    rs.allResults().forEach {\n        println(\"Hotel name -&gt; ${it.getString(\"name\")}, in ${it.getString(\"country\")}\")\n    }\n}\n</code></pre>"},{"location":"query-result-sets/#json-result-sets","title":"JSON Result Sets","text":"<p>Use <code>Result.toJSON()</code> to transform your result into a JSON string, which can easily be serialized or used as required in your application. See Example 7 for a working example using kotlinx-serialization.</p> <p>Example 7. Using JSON Results</p> <pre><code>// Uses kotlinx-serialization JSON processor\n@Serializable\ndata class Hotel(val id: String, val type: String, val name: String)\n\nval hotels = mutableListOf&lt;Hotel&gt;()\n\nval query = QueryBuilder\n    .select(\n        SelectResult.expression(Meta.id),\n        SelectResult.property(\"type\"),\n        SelectResult.property(\"name\")\n    )\n    .from(DataSource.collection(collection))\n\nquery.execute().use { rs -&gt;\n    rs.forEach {\n\n        // Get result as JSON string\n        val json = it.toJSON()\n\n        // Get JsonObject map from JSON string\n        val mapFromJsonString = Json.decodeFromString&lt;JsonObject&gt;(json)\n\n        // Use created JsonObject map\n        val hotelId = mapFromJsonString[\"id\"].toString()\n        val hotelType = mapFromJsonString[\"type\"].toString()\n        val hotelName = mapFromJsonString[\"name\"].toString()\n\n        // Get custom object from JSON string\n        val hotel = Json.decodeFromString&lt;Hotel&gt;(json)\n        hotels.add(hotel)\n    }\n}\n</code></pre>"},{"location":"query-result-sets/#json-string-format","title":"JSON String Format","text":"<p>If your query selects ALL then the JSON format will be:</p> <pre><code>{\n  database-name: {\n    key1: \"value1\",\n    keyx: \"valuex\"\n  }\n}\n</code></pre> <p>If your query selects a sub-set of available properties then the JSON format will be:</p> <pre><code>{\n  key1: \"value1\",\n  keyx: \"valuex\"\n}\n</code></pre>"},{"location":"query-troubleshooting/","title":"Query Troubleshooting","text":"<p>How to use the Couchbase Lite <code>Query</code> API\u2019s <code>explain()</code> method to examine a query</p>"},{"location":"query-troubleshooting/#query-explain","title":"Query Explain","text":""},{"location":"query-troubleshooting/#using","title":"Using","text":"<p><code>Query</code>\u2019s <code>explain()</code> method can provide useful insight when you are trying to diagnose query performance issues and-or optimize queries. To examine how your query is working, either embed the call inside your app (see Example 1), or use it interactively within a <code>cblite</code> shell (see Example 2).</p> <p>Example 1. Using Query Explain in App</p> <pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"university\")))\n    .groupBy(Expression.property(\"country\"))\n    .orderBy(Ordering.property(\"name\").descending()) \n\nprintln(query.explain())\n</code></pre> <ol> <li>Construct your query as normal</li> <li>Call the query\u2019s explain method; all output is sent to the application\u2019s console log.</li> </ol> <p>Example 2. Using Query Explain in cblite</p> <pre><code>cblite &lt;your-database-name&gt;.cblite2 \n\n(cblite) select --explain domains group by country order by country, name \n\n(cblite) query --explain {\"GROUP_BY\":[[\".country\"]],\"ORDER_BY\":[[\".country\"],[\".name\"]],\"WHAT\":[[\".domains\"]]} \n</code></pre> <ol> <li>Within a terminal session open your database with <code>cblite</code> and enter your query</li> <li>Here the query is entered as a N1QL-query using <code>select</code></li> <li>Here the query is entered as a JSON-string using <code>query</code></li> </ol>"},{"location":"query-troubleshooting/#output","title":"Output","text":"<p>The output from <code>explain()</code> remains the same whether invoked by an app, or <code>cblite</code>\u2014see Example 3 for an example of how it looks.</p> <p>Example 3. Query.explain() Output</p> <pre><code>SELECT fl_result(fl_value(_doc.body, 'domains')) FROM kv_default AS _doc WHERE (_doc.flags &amp; 1 = 0) GROUP BY fl_value(_doc.body, 'country') ORDER BY fl_value(_doc.body, 'country'), fl_value(_doc.body, 'name')\n\n7|0|0| SCAN TABLE kv_default AS _doc\n12|0|0| USE TEMP B-TREE FOR GROUP BY\n52|0|0| USE TEMP B-TREE FOR ORDER BY\n\n{\"GROUP_BY\":[[\".country\"]],\"ORDER_BY\":[[\".country\"],[\".name\"]],\"WHAT\":[[\".domains\"]]}\n</code></pre> <p>This output (Example 3) comprises three main elements:</p> <ol> <li>The translated SQL-query, which is not necessarily useful, being aimed more at Couchbase support and-or engineering    teams.</li> <li>The SQLite query plan, which gives a high-level view of how the SQL query will be implemented. You can use this to    identify potential issues and so optimize problematic queries.</li> <li>The query in JSON-string format, which you can copy-and-paste directly into the <code>cblite</code> tool.</li> </ol>"},{"location":"query-troubleshooting/#the-query-plan","title":"The Query Plan","text":""},{"location":"query-troubleshooting/#format","title":"Format","text":"<p>The query plan section of the output displays a tabular form of the translated query\u2019s execution plan. It primarily shows how the data will be retrieved and, where appropriate, how it will be sorted for navigation and-or presentation purposes. For more on SQLite\u2019s Explain Query Plan \u2014 see SQLite Explain Query Plan.</p> <p>Example 4. A Query Plan</p> <pre><code>7|0|0| SCAN TABLE kv_default AS _doc\n12|0|0| USE TEMP B-TREE FOR GROUP BY\n52|0|0| USE TEMP B-TREE FOR ORDER BY\n</code></pre> <ol> <li>Retrieval method \u2014 This line shows the retrieval method being used for the query; here a sequential read of the    database. Something you may well be looking to optimize \u2014 see Retrieval Method for more.</li> <li>Grouping method \u2014 This line shows that the <code>Group By</code> clause used in the query requires the data to be sorted and    that a b-tree will be used for temporary storage \u2014 see Order and Group.</li> <li>Ordering method \u2014 This line shows that the <code>Order By</code> clause used in the query requires the data to be sorted and    that a b-tree will be used for temporary storage \u2014 see Order and Group.</li> </ol>"},{"location":"query-troubleshooting/#retrieval-method","title":"Retrieval Method","text":"<p>The query optimizer will attempt to retrieve the requested data items as efficiently as possible, which generally will be by using one or more of the available indexes. The retrieval method shows the approach decided upon by the optimizer \u2014 see Table 1.</p> <p>Table 1. Retrieval methods</p> Retrieval Method Description Search Here the query is able to access the required data directly using keys into the index. Queries using the Search mode are the fastest. Scan Index Here the query is able to retrieve the data by scanning all or part-of the index (for example when seeking to match values within a range). This type of query is slower than search, but at least benefits from the compact and ordered form of the index. Scan Table Here the query must scan the database table(s) to retrieve the required data. It is the slowest of these methods and will benefit most from some form of optimization. <p>When looking to optimize a query\u2019s retrieval method, consider whether:</p> <ul> <li>Providing an additional index makes sense</li> <li>You could use an existing index \u2014 perhaps by restructuring the query to minimize wildcard use, or the reliance on   functions that modify the query\u2019s interpretation of index keys (for example, <code>lower()</code>)</li> <li>You could reduce the data set being requested to minimize the query\u2019s footprint on the database</li> </ul>"},{"location":"query-troubleshooting/#order-and-group","title":"Order and Group","text":"<p>The <code>Use temp b-tree for</code> lines in the example indicate that the query requires sorting to cater for grouping and then sorting again to present the output results. Minimizing, if not eliminating, this ordering and re-ordering will obviously reduce the amount of time taken to process your query.</p> <p>Ask \"is the grouping and-or ordering absolutely necessary?\": if it isn\u2019t, drop it or modify it to minimize its impact.</p>"},{"location":"query-troubleshooting/#queries-and-indexes","title":"Queries and Indexes","text":"<p>Querying documents using a pre-existing database index is much faster because an index narrows down the set of documents to examine.</p> <p>When planning the indexes you need for your database, remember that while indexes make queries faster, they may also:</p> <ul> <li>Make writes slightly slower, because each index must be updated whenever a document is updated</li> <li>Make your Couchbase Lite database slightly larger.</li> </ul> <p>Too many indexes may hurt performance. Optimal performance depends on designing and creating the right indexes to go along with your queries.</p> <p>Constraints</p> <p>Couchbase Lite does not currently support partial value indexes; indexes with non-property expressions. You should only index with properties that you plan to use in the query.</p> <p>The query optimizer converts your query into a parse tree that groups zero or more and-connected clauses together (as dictated by your where conditionals) for effective query engine processing.</p> <p>Ideally a query will be able to satisfy its requirements entirely by either directly accessing the index or searching sequential index rows. Less good is if the query must scan the whole index; although the compact nature of most indexes means this is still much faster than the alternative of scanning the entire database with no help from the indexes at all.</p> <p>Searches that begin with or rely upon an inequality with the primary key are inherently less effective than those using a primary key equality.</p>"},{"location":"query-troubleshooting/#working-with-the-query-optimizer","title":"Working with the Query Optimizer","text":"<p>You may have noticed that sometimes a query runs faster on a second run, or after re-opening the database, or after deleting and recreating an index. This typically happens when SQL Query Optimizer has gathered sufficient stats to recognize a means of optimizing a suboptimal query.</p> <p>If only those stats were available from the start. In fact, they are gathered after certain events, such as:</p> <ul> <li>Following index creation</li> <li>On a database close</li> <li>When running a database compact</li> </ul> <p>So, if your analysis of the Query Explain output indicates a suboptimal query and your rewrites fail to sufficiently optimize it, consider compacting the database. Then re-generate the Query Explain and note any improvements in optimization. They may not, in themselves, resolve the issue entirely; but they can provide a useful guide toward further optimizing changes you could make.</p>"},{"location":"query-troubleshooting/#wildcard-and-like-based-queries","title":"Wildcard and Like-based Queries","text":"<p>Like-based searches can use the index(es) only if:</p> <ul> <li>The search-string doesn\u2019t start with a wildcard</li> <li>The primary search expression uses a property that is an indexed key</li> <li>The search-string is a constant known at run time (that is, not a value derived during processing of the query)</li> </ul> <p>To illustrate this we can use a modified query from the Mobile Travel Sample application; replacing a simple equality test with a <code>LIKE</code>.</p> <p>In Example 5 we use a wildcard prefix and suffix. You can see that the query plan decides on a retrieval method of <code>Scan Table</code>.</p> <p>Tip</p> <p>For more on indexes \u2014 see Indexing</p> <p>Example 5. Like with Wildcard Prefix</p> <pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").like(Expression.string(\"%hotel%\"))\n            .and(Expression.property(\"name\").like(Expression.string(\"%royal%\")))\n    )\nprintln(query.explain())\n</code></pre> <p>The indexed property, <code>type</code>, cannot use its index because of the wildcard prefix.</p> Resulting Query Plan<pre><code>2|0|0| SCAN TABLE kv_default AS _doc\n</code></pre> <p>By contrast, by removing the wildcard prefix <code>%</code> (in Example 6), we see that the query plan\u2019s retrieval method changes to become an index search. Where practical, simple changes like this can make significant differences in query performance.</p> <p>Example 6. Like with No Wildcard-prefix</p> <pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(\n        Expression.property(\"type\").like(Expression.string(\"hotel%\"))\n            .and(Expression.property(\"name\").like(Expression.string(\"%royal%\")))\n    )\nprintln(query.explain())\n</code></pre> <p>Simply removing the wildcard prefix enables the query optimizer to access the <code>typeIndex</code>, which results in a more efficient search.</p> Resulting Query Plan<pre><code>3|0|0| SEARCH TABLE kv_default AS _doc USING INDEX typeIndex (&lt;expr&gt;&gt;? AND &lt;expr&gt;&lt;?)\n</code></pre>"},{"location":"query-troubleshooting/#use-functions-wisely","title":"Use Functions Wisely","text":"<p>Functions are a very useful tool in building queries, but be aware that they can impact whether the query-optimizer is able to use your index(es).</p> <p>For example, you can observe a similar situation to that shown in Wildcard and Like-based Queries  when using the <code>lower()</code> function on an indexed property.</p> Query<pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(Function.lower(Expression.property(\"type\")).equalTo(Expression.string(\"hotel\")))\nprintln(query.explain())\n</code></pre> <p>Here we use the <code>lower()</code> function in the Where expression</p> Query Plan<pre><code>2|0|0| SCAN TABLE kv_default AS _doc\n</code></pre> <p>But removing the <code>lower()</code> function, changes things:</p> Query<pre><code>val query = QueryBuilder\n    .select(SelectResult.all())\n    .from(DataSource.collection(collection))\n    .where(Expression.property(\"type\").equalTo(Expression.string(\"hotel\"))) \nprintln(query.explain())\n</code></pre> <p>Here we have removed <code>lower()</code> from the Where expression</p> Query Plan<pre><code>3|0|0| SEARCH TABLE kv_default AS _doc USING INDEX typeIndex (&lt;expr&gt;=?)\n</code></pre> <p>Knowing this, you can consider how you create the index; for example, using <code>lower()</code> when you create the index and then always using lowercase comparisons.</p>"},{"location":"query-troubleshooting/#optimization-considerations","title":"Optimization Considerations","text":"<p>Try to minimize the amount of data retrieved. Reduce it down to the few properties you really do need to achieve the required result.</p> <p>Consider fetching details lazily. You could break complex queries into components. Returning just the doc-ids, then process the array of doc-ids using either the Document API or a query that uses the array of doc-ids to return information.</p> <p>Consider using paging to minimize the data returned when the number of results returned is expected to be high. Getting the whole lot at once will be slow and resource intensive. Plus does anyone want to access them all in one go? Instead, retrieve batches of information at a time, perhaps using the <code>LIMIT/OFFSET</code> feature to set a starting point for each subsequent batch. Although, note that using query offsets becomes increasingly less effective as the overhead of skipping a growing number of rows each time increases. You can work around this, by instead using ranges of search-key values. If the last search-key value of batch one was 'x' then that could become the starting point for your next batch and-so-on.</p> <p>Optimize document size in design. Smaller docs load more quickly. Break your data into logical linked units.</p> <p>Consider Using Full Text Search instead of complex like or regex patterns \u2014 see Full Text Search.</p>"},{"location":"remote-sync-gateway/","title":"Remote Sync Gateway","text":"<p>Couchbase Lite \u2014 Synchronizing data changes between local and remote databases using Sync Gateway</p> <p>Android enablers</p> <p>Allow Unencrypted Network Traffic</p> <p>To use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>Use Background Threads</p> <p>As with any network or file I/O activity, Couchbase Lite activities should not be performed on the UI thread. Always use a background thread.</p> <p>Code Snippets</p> <p>All code examples are indicative only. They demonstrate the basic concepts and approaches to using a feature. Use them as inspiration and adapt these examples to best practice when developing applications for your platform.</p>"},{"location":"remote-sync-gateway/#introduction","title":"Introduction","text":"<p>Couchbase Lite provides API support for secure, bi-directional, synchronization of data changes between mobile applications and a central server database. It does so by using a replicator to interact with Sync Gateway.</p> <p>The replicator is designed to manage replication of documents and-or document changes between a source and a target database. For example, between a local Couchbase Lite database and remote Sync Gateway database, which is ultimately mapped to a bucket in a Couchbase Server instance in the cloud or on a server.</p> <p>This page shows sample code and configuration examples covering the implementation of a replication using Sync Gateway.</p> <p>Your application runs a replicator (also referred to here as a client), which will initiate connection with a Sync Gateway (also referred to here as a server) and participate in the replication of database changes to bring both local and remote databases into sync.</p> <p>Subsequent sections provide additional details and examples for the main configuration options.</p>"},{"location":"remote-sync-gateway/#replication-concepts","title":"Replication Concepts","text":"<p>Couchbase Lite allows for one database for each application running on the mobile device. This database can contain one or more scopes. Each scope can contain one or more collections.</p> <p>To learn about Scopes and Collections, see Databases.</p> <p>You can set up a replication scheme across these data levels:</p> <p>Database The <code>_default</code> collection is synced.</p> <p>Collection A specific collection or a set of collections is synced.</p> <p>As part of the syncing setup, the Sync Gateway has to map the Couchbase Lite database to the Couchbase Server or Capella database being synced.</p>"},{"location":"remote-sync-gateway/#replication-protocol","title":"Replication Protocol","text":""},{"location":"remote-sync-gateway/#scheme","title":"Scheme","text":"<p>Couchbase Mobile uses a replication protocol based on WebSockets for replication. To use this protocol the replication URL should specify WebSockets as the URL scheme (see the Configure Target section below).</p>"},{"location":"remote-sync-gateway/#ordering","title":"Ordering","text":"<p>To optimize for speed, the replication protocol doesn\u2019t guarantee that documents will be received in a particular order. So we don\u2019t recommend to rely on that when using the replication or database change listeners for example.</p>"},{"location":"remote-sync-gateway/#scopes-and-collections","title":"Scopes and Collections","text":"<p>Scopes and Collections allow you to organize your documents in Couchbase Lite.</p> <p>When syncing, you can configure the collections to be synced.</p> <p>The collections specified in the Couchbase Lite replicator setup must exist (both scope and collection name must be identical) on the Sync Gateway side, otherwise starting the Couchbase Lite replicator will result in an error.</p> <p>During replication:</p> <ol> <li>If Sync Gateway config (or server) is updated to remove a collection that is being synced, the client replicator will    be offline and will be stopped after the first retry. An error will be reported.</li> <li>If Sync Gateway config is updated to add a collection to a scope that is being synchronized, the replication will    ignore the collection. The added collection will not automatically sync until the Couchbase Lite replicator\u2019s    configuration is updated.</li> </ol>"},{"location":"remote-sync-gateway/#default-collection","title":"Default Collection","text":"<p>When upgrading Couchbase Lite to 3.1, the existing documents in the database will be automatically migrated to the default collection.</p> <p>For backward compatibility with the code prior to 3.1, when you set up the replicator with the database, the default collection will be set up to sync with the default collection on Sync Gateway.</p> <p>Sync Couchbase Lite database with the default collection on Sync Gateway </p> <p>Sync Couchbase Lite default collection with default collection on Sync Gateway </p>"},{"location":"remote-sync-gateway/#user-defined-collections","title":"User-Defined Collections","text":"<p>The user-defined collections specified in the Couchbase Lite replicator setup must exist (and be identical) on the Sync Gateway side to sync.</p> <p>Syncing scope with user-defined collections </p> <p>Syncing scope with user-defined collections. Couchbase Lite has more collections than the Sync Gateway configuration (with collection filters) </p>"},{"location":"remote-sync-gateway/#configuration-summary","title":"Configuration Summary","text":"<p>You should configure and initialize a replicator for each Couchbase Lite database instance you want to sync. Example 1 shows the configuration and initialization process.</p> <p>Note</p> <p>You need Couchbase Lite 3.1+ and Sync Gateway 3.1+ to use <code>custom</code> Scopes and Collections. If you\u2019re using Capella App Services or Sync Gateway releases that are older than version 3.1, you won\u2019t be able to access <code>custom</code> Scopes and Collections. To use Couchbase Lite 3.1+ with these older versions, you can use the <code>default</code> Collection as a backup option.</p> <p>Example 1. Replication configuration and initialization</p> <pre><code>val repl = Replicator(\n    // initialize the replicator configuration\n    ReplicatorConfiguration(URLEndpoint(\"wss://listener.com:8954\"))\n        .addCollections(collections).apply {\n            // Set replicator type\n            type = ReplicatorType.PUSH_AND_PULL\n\n            // Configure Sync Mode\n            isContinuous = false // default value\n\n            // set auto-purge behavior\n            // (here we override default)\n            isAutoPurgeEnabled = false\n\n            // Configure Server Authentication --\n            // only accept self-signed certs\n            isAcceptOnlySelfSignedServerCertificate = true\n\n            // Configure the credentials the\n            // client will provide if prompted\n            authenticator = BasicAuthenticator(\"PRIVUSER\", \"let me in\".toCharArray())\n        }\n)\n\n// Optionally add a change listener\nval token = repl.addChangeListener { change -&gt;\n    val err: CouchbaseLiteException? = change.status.error\n    if (err != null) {\n        println(\"Error code ::  ${err.code}\\n$err\")\n    }\n}\n\n// Start replicator\nrepl.start(false)\n\nthis.replicator = repl\nthis.token = token\n</code></pre> <p>Notes on Example</p> <ol> <li>Get endpoint for target database.</li> <li>Use the <code>ReplicatorConfiguration</code> class\u2019s constructor \u2014    <code>ReplicatorConfiguration(Endpoint)</code> \u2014 to initialize the    replicator configuration \u2014 see also Configure Target.</li> <li>The default is to auto-purge documents that this user no longer has access to \u2014 see Auto-purge on Channel Access    Revocation. Here we override this behavior by setting its flag to false.</li> <li>Configure how the client will authenticate the server. Here we say connect only to servers presenting a self-signed    certificate. By default, clients accept only servers presenting certificates that can be verified using the OS    bundled Root CA Certificates \u2014 see Server Authentication.</li> <li>Configure the client-authentication credentials (if required). These are the credential the client will present to    sync gateway if requested to do so.    Here we configure to provide Basic Authentication credentials. Other options are available \u2014 see Client    Authentication.</li> <li>Configure how the replication should handle conflict resolution \u2014 see Handling Data Conflicts topic for mor on conflict resolution.</li> <li>Initialize the replicator using your configuration \u2014 see Initialize.</li> <li>Optionally, register an observer, which will notify you of changes to the replication status \u2014 see Monitor    .</li> <li>Start the replicator \u2014 see Start Replicator.</li> </ol>"},{"location":"remote-sync-gateway/#configure","title":"Configure","text":"<p>In this section Configure Target | Sync Mode | Retry Configuration | User Authorization | Server Authentication | Client Authentication  | Monitor Document Changes | Custom Headers | Checkpoint Starts | Replication Filters | Channels | Auto-purge on Channel Access Revocation | Delta Sync</p>"},{"location":"remote-sync-gateway/#configure-target","title":"Configure Target","text":"<p>Initialize and define the replication configuration with local and remote database locations using the <code>ReplicatorConfiguration</code> object.</p> <p>The constructor provides the server\u2019s URL (including the port number and the name of the remote database to sync with).</p> <p>It is expected that the app will identify the IP address and URL and append the remote database name to the URL endpoint, producing for example: <code>wss://10.0.2.2:4984/travel-sample</code>.</p> <p>The URL scheme for web socket URLs uses <code>ws:</code> (non-TLS) or <code>wss:</code> (SSL/TLS) prefixes.</p> <p>Note</p> <p>On the Android platform, to use cleartext, un-encrypted, network traffic (<code>http://</code> and-or <code>ws://</code>), include <code>android:usesCleartextTraffic=\"true\"</code> in the <code>application</code> element of the manifest as shown on developer.android.com. This is not recommended in production.</p> <p>Add the database collections to sync along with the <code>CollectionConfiguration</code> for each to the <code>ReplicatorConfiguration</code>. Multiple collections can use the same configuration, or each their own as needed. A null configuration will use the default configuration values, found in <code>Defaults.Replicator</code>.</p> <p>Example 2. Add Target to Configuration</p> <pre><code>// initialize the replicator configuration\nval config = ReplicatorConfiguration(\n    URLEndpoint(\"wss://10.0.2.2:8954/travel-sample\")\n).addCollections(collections, null)\n</code></pre> <p>Note use of the scheme prefix (<code>wss://</code> to ensure TLS encryption \u2014 strongly recommended in production \u2014 or <code>ws://</code>)</p>"},{"location":"remote-sync-gateway/#sync-mode","title":"Sync Mode","text":"<p>Here we define the direction and type of replication we want to initiate.</p> <p>We use <code>ReplicatorConfiguration</code> class\u2019s <code>type</code> and <code>isContinuous</code> parameters, to tell the replicator:</p> <ul> <li>The type (or direction) of the replication: <code>PUSH_AND_PULL</code>; <code>PULL</code>; <code>PUSH</code></li> <li>The replication mode, that is either of:<ul> <li>Continuous \u2014 remaining active indefinitely to replicate changed documents (<code>isContinuous=true</code>).</li> <li>Ad-hoc \u2014 a one-shot replication of changed documents (<code>isContinuous=false</code>).</li> </ul> </li> </ul> <p>Example 3. Configure replicator type and mode</p> <pre><code>// Set replicator type\ntype = ReplicatorType.PUSH_AND_PULL,\n\n// Configure Sync Mode\ncontinuous = false, // default value\n</code></pre> <p>Tip</p> <p>Unless there is a solid use-case not to, always initiate a single <code>PUSH_AND_PULL</code> replication rather than identical separate <code>PUSH</code> and <code>PULL</code> replications.</p> <p>This prevents the replications generating the same checkpoint <code>docID</code> resulting in multiple conflicts.</p>"},{"location":"remote-sync-gateway/#retry-configuration","title":"Retry Configuration","text":"<p>Couchbase Lite\u2019s replication retry logic assures a resilient connection.</p> <p>The replicator minimizes the chance and impact of dropped connections by maintaining a heartbeat; essentially pinging the Sync Gateway at a configurable interval to ensure the connection remains alive.</p> <p>In the event it detects a transient error, the replicator will attempt to reconnect, stopping only when the connection is re-established, or the number of retries exceeds the retry limit (9 times for a single-shot replication and unlimited for a continuous replication).</p> <p>On each retry the interval between attempts is increased exponentially (exponential backoff) up to the maximum wait time limit (5 minutes).</p> <p>The REST API provides configurable control over this replication retry logic using a set of configurable properties \u2014 see Table 1.</p> <p>Table 1. Replication Retry Configuration Properties</p> Property Use cases Description <code>setHeartbeat()</code> <ul><li>Reduce to detect connection errors sooner</li><li>Align to load-balancer or proxy <code>keep-alive</code> interval \u2014 see Sync Gateway\u2019s topic Load Balancer - Keep Alive</li></ul> The interval (in seconds) between the heartbeat pulses.Default: The replicator pings the Sync Gateway every 300 seconds. <code>setMaxAttempts()</code> Change this to limit or extend the number of retry attempts. The maximum number of retry attempts<ul><li>Set to zero (0) to use default values</li><li>Set to one (1) to prevent any retry attempt</li><li>The retry attempt count is reset when the replicator is able to connect and replicate</li><li>Default values are:<ul><li>Single-shot replication = 9;</li><li>Continuous replication = maximum integer value</li></ul></li><li>Negative values generate a Couchbase exception <code>InvalidArgumentException</code></li></ul> <code>setMaxAttemptWaitTime()</code> Change this to adjust the interval between retries. The maximum interval between retry attemptsWhile you can configure the maximum permitted wait time, the replicator\u2019s exponential backoff algorithm calculates each individual interval which is not configurable.<ul><li>Default value: 300 seconds (5 minutes)</li><li>Zero sets the maximum interval between retries to the default of 300 seconds</li><li>300 sets the maximum interval between retries to the default of 300 seconds</li><li>A negative value generates a Couchbase exception, <code>InvalidArgumentException</code></li></ul> <p>When necessary you can adjust any or all of those configurable values \u2014 see Example 4 for how to do this.</p> <p>Example 4. Configuring Replication Retries</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .apply {\n            //  other config params as required . .\n            heartbeat = 150\n            maxAttempts = 20\n            maxAttemptWaitTime = 600\n        }\n)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"remote-sync-gateway/#user-authorization","title":"User Authorization","text":"<p>By default, Sync Gateway does not enable user authorization. This makes it easier to get up and running with synchronization.</p> <p>You can enable authorization in the sync gateway configuration file, as shown in Example 5.</p> <p>Example 5. Enable Authorization</p> <pre><code>{\n  \"databases\": {\n    \"mydatabase\": {\n      \"users\": {\n        \"GUEST\": { \"disabled\": true }\n      }\n    }\n  }\n}\n</code></pre> <p>To authorize with Sync Gateway, an associated user must first be created. Sync Gateway users can be created through the <code>POST /{db}/_user</code> endpoint on the Admin REST API.</p>"},{"location":"remote-sync-gateway/#server-authentication","title":"Server Authentication","text":"<p>Define the credentials your app (the client) is expecting to receive from the Sync Gateway (the server) in order to ensure it is prepared to continue with the sync.</p> <p>Note that the client cannot authenticate the server if TLS is turned off. When TLS is enabled (Sync Gateway\u2019s default) the client must authenticate the server. If the server cannot provide acceptable credentials then the connection will fail.</p> <p>Use <code>ReplicatorConfiguration</code> properties <code>setAcceptOnlySelfSignedServerCertificate</code> and <code>setPinnedServerCertificate</code>, to tell the replicator how to verify server-supplied TLS server certificates.</p> <ul> <li>If there is a pinned certificate, nothing else matters, the server cert must exactly match the pinned certificate.</li> <li>If there are no pinned certs and <code>setAcceptOnlySelfSignedServerCertificate</code> is <code>true</code> then any self-signed   certificate is accepted. Certificates that are not self-signed are rejected, no matter who signed them.</li> <li>If there are no pinned certificates and <code>setAcceptOnlySelfSignedServerCertificate</code> is <code>false</code> (default), the client   validates the server\u2019s certificates against the system CA certificates. The server must supply a chain of certificates   whose root is signed by one of the certificates in the system CA bundle.</li> </ul> <p>Example 6. Set Server TLS security</p> CA CertSelf-Signed CertPinned Certificate <p>Set the client to expect and accept only CA attested certificates.</p> <pre><code>// Configure Server Security\n// -- only accept CA attested certs\nacceptOnlySelfSignedServerCertificate = false,\n</code></pre> <p>This is the default. Only certificate chains with roots signed by a trusted CA are allowed. Self-signed certificates are not allowed.</p> <p>Set the client to expect and accept only self-signed certificates.</p> <pre><code>// Configure Server Authentication --\n// only accept self-signed certs\nacceptOnlySelfSignedServerCertificate = true,\n</code></pre> <p>Set this to <code>true</code> to accept any self-signed cert. Any certificates that are not self-signed are rejected.</p> <p>Set the client to expect and accept only a pinned certificate.</p> <pre><code>// Use the pinned certificate from the byte array (cert)\npinnedServerCertificate = TLSIdentity.getIdentity(\"Our Corporate Id\")\n    ?.certs?.firstOrNull()\n    ?: throw IllegalStateException(\"Cannot find corporate id\"),\n</code></pre> <p>Configure the pinned certificate using data from the byte array <code>cert</code></p> <p>This all assumes that you have configured the Sync Gateway to provide the appropriate SSL certificates, and have included the appropriate certificate in your app bundle \u2014 for more on this see Certificate Pinning .</p>"},{"location":"remote-sync-gateway/#client-authentication","title":"Client Authentication","text":"<p>There are two ways to authenticate from a Couchbase Lite client: Basic Authentication or Session Authentication.</p>"},{"location":"remote-sync-gateway/#basic-authentication","title":"Basic Authentication","text":"<p>You can provide a username and password to the basic authenticator class method. Under the hood, the replicator will send the credentials in the first request to retrieve a <code>SyncGatewaySession</code> cookie and use it for all subsequent requests during the replication. This is the recommended way of using basic authentication. Example 7 shows how to initiate a one-shot replication as the user username with the password password.</p> <p>Example 7. Basic Authentication</p> <pre><code>// Create replicator (be sure to hold a reference somewhere that will prevent the Replicator from being GCed)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .setAuthenticator(BasicAuthenticator(\"username\", \"password\".toCharArray()))\n)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"remote-sync-gateway/#session-authentication","title":"Session Authentication","text":"<p>Session authentication is another way to authenticate with Sync Gateway.</p> <p>A user session must first be created through the <code>POST /{db}/_session</code> endpoint on the Public REST API.</p> <p>The HTTP response contains a session ID which can then be used to authenticate as the user it was created for.</p> <p>See Example 8, which shows how to initiate a one-shot replication with the session ID returned from the <code>POST /{db}/_session</code> endpoint.</p> <p>Example 8. Session Authentication</p> <pre><code>// Create replicator (be sure to hold a reference somewhere that will prevent the Replicator from being GCed)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .setAuthenticator(SessionAuthenticator(\"904ac010862f37c8dd99015a33ab5a3565fd8447\"))\n)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"remote-sync-gateway/#custom-headers","title":"Custom Headers","text":"<p>Custom headers can be set on the configuration object. The replicator will then include those headers in every request.</p> <p>This feature is useful in passing additional credentials, perhaps when an authentication or authorization step is being done by a proxy server (between Couchbase Lite and Sync Gateway) \u2014 see Example 9.</p> <p>Example 9. Setting custom headers</p> <pre><code>// Create replicator (be sure to hold a reference somewhere that will prevent the Replicator from being GCed)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .setHeaders(mapOf(\"CustomHeaderName\" to \"Value\"))\n)\nrepl.start()\nthis.replicator = repl\n</code></pre>"},{"location":"remote-sync-gateway/#replication-filters","title":"Replication Filters","text":"<p>Replication Filters allow you to have quick control over the documents stored as the result of a push and/or pull replication.</p>"},{"location":"remote-sync-gateway/#push-filter","title":"Push Filter","text":"<p>The push filter allows an app to push a subset of a database to the server. This can be very useful. For instance, high-priority documents could be pushed first, or documents in a \"draft\" state could be skipped.</p> <pre><code>val collectionConfig = CollectionConfiguration(\n    pushFilter = { _, flags -&gt; flags.contains(DocumentFlag.DELETED) }\n)\n\n// Create replicator (be sure to hold a reference somewhere that will prevent the Replicator from being GCed)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections, collectionConfig)\n)\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>The callback should follow the semantics of a pure function. Otherwise, long-running functions would slow down the replicator considerably. Furthermore, your callback should not make assumptions about what thread it is being called on.</p>"},{"location":"remote-sync-gateway/#pull-filter","title":"Pull Filter","text":"<p>The pull filter gives an app the ability to validate documents being pulled, and skip ones that fail. This is an important security mechanism in a peer-to-peer topology with peers that are not fully trusted.</p> <p>Note</p> <p>Pull replication filters are not a substitute for channels. Sync Gateway channels are designed to be scalable (documents are filtered on the server) whereas a pull replication filter is applied to a document once it has been downloaded.</p> <pre><code>val collectionConfig = CollectionConfiguration(\n    pullFilter = { document, _ -&gt; \"draft\" == document.getString(\"type\") }\n)\n\n// Create replicator (be sure to hold a reference somewhere that will prevent the Replicator from being GCed)\nval repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollections(collections, collectionConfig)\n)\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>The callback should follow the semantics of a pure function. Otherwise, long-running functions would slow down the replicator considerably. Furthermore, your callback should not make assumptions about what thread it is being called on.</p> <p>Losing access to a document via the Sync Function.</p> <p>Losing access to a document (via the Sync Function) also triggers the pull replication filter.</p> <p>Filtering out such an event would retain the document locally.</p> <p>As a result, there would be a local copy of the document disjointed from the one that resides on Couchbase Server.</p> <p>Further updates to the document stored on Couchbase Server would not be received in pull replications and further local edits could be pushed but the updated versions will not be visible.</p> <p>For more information, see Auto-purge on Channel Access Revocation.</p>"},{"location":"remote-sync-gateway/#channels","title":"Channels","text":"<p>By default, Couchbase Lite gets all the channels to which the configured user account has access.</p> <p>This behavior is suitable for most apps that rely on user authentication and the sync function to specify which data to pull for each user.</p> <p>Optionally, it\u2019s also possible to specify a string array of channel names on Couchbase Lite\u2019s replicator configuration object. In this case, the replication from Sync Gateway will only pull documents tagged with those channels.</p>"},{"location":"remote-sync-gateway/#auto-purge-on-channel-access-revocation","title":"Auto-purge on Channel Access Revocation","text":"<p>This is a Breaking Change at 3.0</p>"},{"location":"remote-sync-gateway/#new-outcome","title":"New outcome","text":"<p>By default, when a user loses access to a channel all documents in the channel (that do not also belong to any of the user\u2019s other channels) are auto-purged from the local database (in devices belonging to the user).</p>"},{"location":"remote-sync-gateway/#prior-outcome","title":"Prior outcome","text":"<p>Previously these documents remained in the local database</p> <p>Prior to CBL 3.0, CBL auto-purged only in the case when the user loses access to a document by removing the doc from all of the channels belonging to the user. Now, in addition to 2.x auto purge, Couchbase Lite also auto-purges the docs when the user loses access to the doc via channel access revocation. This feature is enabled by default, but an opt-out is available.</p>"},{"location":"remote-sync-gateway/#behavior","title":"Behavior","text":"<p>Users may lose access to channels in a number of ways:</p> <ul> <li>User loses direct access to channel</li> <li>User is removed from a role</li> <li>A channel is removed from a role the user is assigned to</li> </ul> <p>By default, when a user loses access to a channel, the next Couchbase Lite pull replication auto-purges all documents in the channel from local Couchbase Lite databases (on devices belonging to the user) unless they belong to any of the user\u2019s other channels \u2014 see Table 2.</p> <p>Documents that exist in multiple channels belonging to the user (even if they are not actively replicating that channel) are not auto-purged unless the user loses access to all channels.</p> <p>Users will receive an <code>ACCESS_REMOVED</code> notification from the <code>DocumentReplicationListener</code> if they lose document access due to channel access revocation; this is sent regardless of the current auto-purge setting.</p> <p>Table 2. Behavior following access revocation</p> System State Impact on Sync Replication Type Access Control on Sync Gateway Expected behavior when <code>isAutoPurgeEnabled=true</code> Pull only <p>User REVOKED access to channel.</p> <p>Sync Function includes <code>requireAccess(revokedChannel)</code></p> <p>Previously synced documents are auto purged on local</p> Push only <p>User REVOKED access to channel.</p> <p>Sync Function includes <code>requireAccess(revokedChannel)</code></p> <p>No impact of auto-purge</p> <p>Documents get pushed but are rejected by Sync Gateway</p> Push-pull <p>User REVOKED access to channel.</p> <p>Sync Function includes <code>requireAccess(revokedChannel)</code></p> <p>Previously synced documents are auto purged on Couchbase Lite.</p> <p>Local changes continue to be  pushed to remote but are rejected by Sync Gateway</p> <p>If a user subsequently regains access to a lost channel, then any previously auto-purged documents still assigned to any of their channels are automatically pulled down by the active Sync Gateway when they are next updated \u2014 see behavior summary in Table 3.</p> <p>Table 3. Behavior if access is regained</p> System State Impact on Sync Replication Type Access Control on Sync Gateway Expected behavior when <code>isAutoPurgeEnabled=true</code> Pull only User REASSIGNED access to channel <p>Previously purged documents that are still in the channel are automatically pulled by Couchbase Lite when they are next updated</p> Push only <p>User REASSIGNED access to channel</p> <p>Sync Function includes <code>requireAccess(reassignedChannel)</code></p> <p>No impact of auto-purge</p> <p>Local changes previously rejected by Sync Gateway will not be automatically pushed to remote unless <code>resetCheckpoint</code> is involved on CBL.</p> <p>Document changes subsequent to the channel reassignment will be pushed up as usual.</p> Push-pull <p>User REASSIGNED access to channel</p> <p>Sync Function includes <code>requireAccess(reassignedChannel)</code></p> <p>Previously purged documents are automatically pulled by Couchbase Lite</p> <p>Local changes previously rejected by Sync Gateway will not be automatically pushed to remote unless <code>resetCheckpoint</code> is involved.</p> <p>Document changes subsequent to the channel reassignment will be pushed up as usual</p>"},{"location":"remote-sync-gateway/#config","title":"Config","text":"<p>Auto-purge behavior is controlled primarily by the <code>ReplicationConfiguration</code> option <code>setAutoPurgeEnabled()</code>. Changing the state of this will impact only future replications; the replicator will not attempt to sync revisions that were auto purged on channel access removal. Clients wishing to sync previously removed documents must use the <code>resetCheckpoint</code> API to resync from the start.</p> <p>Example 10. Setting auto-purge</p> <pre><code>// set auto-purge behavior\n// (here we override default)\nenableAutoPurge = false,\n</code></pre> <p>Here we have opted to turn off the auto purge behavior. By default auto purge is enabled.</p>"},{"location":"remote-sync-gateway/#overrides","title":"Overrides","text":"<p>Where necessary, clients can override the default auto-purge behavior. This can be done either by setting <code>setAutoPurgeEnabled()</code> to <code>false</code>, or for finer control by applying pull-filters \u2014 see Table 4 and Replication Filters  This ensures backwards compatible with 2.8 clients that use pull filters to prevent auto purge of removed docs.</p> <p>Table 4. Impact of Pull-Filters</p> purge_on_removal setting Pull Filter Not Defined Defined to filter removals/revoked docs disabled <p>Doc remains in local database</p> <p>App notified of <code>ACCESS_REMOVED</code> if a <code>DocumentReplicationListener</code> is registered</p> enabled (DEFAULT) <p>Doc is auto purged</p> <p>App notified of <code>ACCESS_REMOVED</code> if <code>DocumentReplicationListener</code> registered</p> Doc remains in local database"},{"location":"remote-sync-gateway/#delta-sync","title":"Delta Sync","text":"<p>This is an Enterprise Edition feature.</p> <p>With Delta Sync, only the changed parts of a Couchbase document are replicated. This can result in significant savings in bandwidth consumption as well as throughput improvements, especially when network bandwidth is typically constrained.</p> <p>Replications to a Server (for example, a Sync Gateway, or passive listener) automatically use delta sync if the property is enabled at database level by the server \u2014 see Admin REST API <code>delta_sync.enabled</code> or legacy JSON configuration <code>databases.$db.delta_sync.enabled</code>.</p> <p>Intra-Device replications automatically disable delta sync, whilst Peer-to-Peer replications automatically enable delta sync.</p>"},{"location":"remote-sync-gateway/#initialize","title":"Initialize","text":"<p>In this section Start Replicator | Checkpoint Starts</p>"},{"location":"remote-sync-gateway/#start-replicator","title":"Start Replicator","text":"<p>Use the <code>Replicator</code> class\u2019s <code>Replicator(ReplicatorConfiguration)</code> constructor, to initialize the replicator with the configuration you have defined. You can, optionally, add a change listener (see Monitor) before starting the replicator running using <code>start()</code>.</p> <p>Example 11. Initialize and run replicator</p> <pre><code>// Create replicator\n// Consider holding a reference somewhere\n// to prevent the Replicator from being GCed\nval repl = Replicator( \n\n    // initialize the replicator configuration\n    ReplicatorConfiguration(URLEndpoint(\"wss://listener.com:8954\"))\n        .addCollections(collections)\n        .apply {\n            // Set replicator type\n            type = ReplicatorType.PUSH_AND_PULL\n\n            // Configure Sync Mode\n            isContinuous = false // default value\n\n            // set auto-purge behavior\n            // (here we override default)\n            isAutoPurgeEnabled = false\n\n            // Configure Server Authentication --\n            // only accept self-signed certs\n            isAcceptOnlySelfSignedServerCertificate = true\n\n            // Configure the credentials the\n            // client will provide if prompted\n            authenticator = BasicAuthenticator(\"PRIVUSER\", \"let me in\".toCharArray())\n        }\n)\n\n// Start replicator\nrepl.start(false)\n\nthis.replicator = repl\nthis.token = token\n</code></pre> <ol> <li>Initialize the replicator with the configuration</li> <li>Start the replicator</li> </ol>"},{"location":"remote-sync-gateway/#checkpoint-starts","title":"Checkpoint Starts","text":"<p>Replicators use checkpoints to keep track of documents sent to the target database.</p> <p>Without checkpoints, Couchbase Lite would replicate the entire database content to the target database on each connection, even though previous replications may already have replicated some or all of that content.</p> <p>This functionality is generally not a concern to application developers. However, if you do want to force the replication to start again from zero, use the checkpoint reset argument when starting the replicator \u2014 as shown in Example 12.</p> <p>Example 12. Resetting checkpoints</p> <pre><code>repl.start(true)\n</code></pre> <p>Set start\u2019s reset option to <code>true</code>. The default <code>false</code> is shown above for completeness only; it is unlikely you would explicitly use it in practice.</p>"},{"location":"remote-sync-gateway/#monitor","title":"Monitor","text":"<p>In this section Change Listeners | Replicator Status | Monitor Document Changes  | Documents Pending Push</p> <p>You can monitor a replication\u2019s status by using a combination of Change Listeners and the <code>replicator.status.activityLevel</code> property \u2014 see <code>activityLevel</code>. This enables you to know, for example, when the replication is actively transferring data and when it has stopped.</p> <p>You can also choose to monitor document changes \u2014 see Monitor Document Changes.</p>"},{"location":"remote-sync-gateway/#change-listeners","title":"Change Listeners","text":"<p>Use this to monitor changes and to inform on sync progress; this is an optional step. You can add a replicator change listener at any point; it will report changes from the point it is registered.</p> <p>Tip</p> <p>Don\u2019t forget to save the token so you can remove the listener later</p> <p>Use the <code>Replicator</code> class to add a change listener as a callback with <code>Replicator.addChangeListener()</code> \u2014 see Example 13. You will then be asynchronously notified of state changes.</p> <p>You can remove a change listener with <code>ListenerToken.remove()</code>.</p>"},{"location":"remote-sync-gateway/#using-kotlin-flows","title":"Using Kotlin Flows","text":"<p>Kotlin developers can take advantage of <code>Flow</code>s to monitor replicators.</p> <pre><code>fun replChangeFlowExample(repl: Replicator): Flow&lt;ReplicatorActivityLevel&gt; {\n    return repl.replicatorChangesFlow()\n        .map { it.status.activityLevel }\n}\n</code></pre>"},{"location":"remote-sync-gateway/#replicator-status","title":"Replicator Status","text":"<p>You can use the <code>ReplicatorStatus</code> class to check the replicator status. That is, whether it is actively transferring data or if it has stopped \u2014 see Example 13.</p> <p>The returned <code>ReplicatorStatus</code> structure comprises:</p> <ul> <li><code>activityLevel</code> \u2014 <code>STOPPED</code>, <code>OFFLINE</code>,   <code>CONNECTING</code>, <code>IDLE</code>, or <code>BUSY</code> \u2014 see states described in Table 5</li> <li><code>progress</code><ul> <li><code>completed</code> \u2014 the total number of changes completed</li> <li><code>total</code> \u2014 the total number of changes to be processed</li> </ul> </li> <li><code>error</code> \u2014 the current error, if any</li> </ul> <p>Example 13. Monitor replication</p> Adding a Change ListenerUsing replicator.status <pre><code>val token = repl.addChangeListener { change -&gt;\n    val err: CouchbaseLiteException? = change.status.error\n    if (err != null) {\n        println(\"Error code :: ${err.code}\\n$err\")\n    }\n}\n</code></pre> <pre><code>repl.status.let {\n    val progress = it.progress\n    println(\n        \"The Replicator is ${\n            it.activityLevel\n        } and has processed ${\n            progress.completed\n        } of ${progress.total} changes\"\n    )\n}\n</code></pre>"},{"location":"remote-sync-gateway/#replication-states","title":"Replication States","text":"<p>Table 5 shows the different states, or activity levels, reported in the API; and the meaning of each.</p> <p>Table 5. Replicator activity levels</p> State Meaning <code>STOPPED</code> The replication is finished or hit a fatal error. <code>OFFLINE</code> The replicator is offline as the remote host is unreachable. <code>CONNECTING</code> The replicator is connecting to the remote host. <code>IDLE</code> The replication caught up with all the changes available from the server. The <code>IDLE</code> state is only used in continuous replications. <code>BUSY</code> The replication is actively transferring data. <p>Note</p> <p>The replication change object also has properties to track the progress (<code>change.status.completed</code> and <code>change.status.total</code>). Since the replication occurs in batches the total count can vary through the course of a replication.</p>"},{"location":"remote-sync-gateway/#replication-status-and-app-life-cycle","title":"Replication Status and App Life Cycle","text":""},{"location":"remote-sync-gateway/#ios","title":"iOS","text":"<p>The following diagram describes the status changes when the application starts a replication, and when the application is being backgrounded or foregrounded by the OS. It applies to iOS only.</p> <p></p> <p>Additionally, on iOS, an app already in the background may be terminated. In this case, the <code>Database</code> and <code>Replicator</code> instances will be <code>null</code> when the app returns to the foreground. Therefore, as preventive measure, it is recommended to do a <code>null</code> check when the app enters the foreground, and to re-initialize the database and replicator if any of those are <code>null</code>.</p> <p>On other platforms, Couchbase Lite doesn\u2019t react to OS backgrounding or foregrounding events and replication(s) will continue running as long as the remote system does not terminate the connection and the app does not terminate. It is generally recommended to stop replications before going into the background otherwise socket connections may be closed by the OS and this may interfere with the replication process.</p>"},{"location":"remote-sync-gateway/#other-platforms","title":"Other Platforms","text":"<p>Couchbase Lite replications will continue running until the app terminates, unless the remote system, or the application, terminates the connection.</p> <p>Note</p> <p>Recall that the Android OS may kill an application without warning. You should explicitly stop replication processes when they are no longer useful (for example, when the app is in the background and the replication is <code>IDLE</code>) to avoid socket connections being closed by the OS, which may interfere with the replication process.</p>"},{"location":"remote-sync-gateway/#monitor-document-changes","title":"Monitor Document Changes","text":"<p>You can choose to register for document updates during a replication.</p> <p>For example, the code snippet in Example 14 registers a listener to monitor document replication performed by the replicator referenced by the variable <code>repl</code>. It prints the document ID of each document received and sent. Stop the listener as shown in Example 15.</p> <p>Example 14. Register a document listener</p> <pre><code>val token = repl.addDocumentReplicationListener { replication -&gt;\n    println(\"Replication type: ${if (replication.isPush) \"push\" else \"pull\"}\")\n\n    for (doc in replication.documents) {\n        println(\"Doc ID: ${doc.id}\")\n\n        doc.error?.let {\n            // There was an error\n            println(\"Error replicating document: $it\")\n            return@addDocumentReplicationListener\n        }\n\n        if (doc.flags.contains(DocumentFlag.DELETED)) {\n            println(\"Successfully replicated a deleted document\")\n        }\n    }\n}\n\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>Example 15. Stop document listener</p> <p>This code snippet shows how to stop the document listener using the token from the previous example.</p> <pre><code>token.remove()\n</code></pre>"},{"location":"remote-sync-gateway/#document-access-removal-behavior","title":"Document Access Removal Behavior","text":"<p>When access to a document is removed on Sync Gateway (see Sync Gateway\u2019s Sync Function), the document replication listener sends a notification with the <code>ACCESS_REMOVED</code> flag set to <code>true</code> and subsequently purges the document from the database.</p>"},{"location":"remote-sync-gateway/#documents-pending-push","title":"Documents Pending Push","text":"<p>Tip</p> <p><code>Replicator.isDocumentPending()</code> is quicker and more efficient. Use it in preference to returning a list of pending document IDs, where possible.</p> <p>You can check whether documents are waiting to be pushed in any forthcoming sync by using either of the following API methods:</p> <ul> <li>Use the <code>Replicator.getPendingDocumentIds()</code> method, which returns a list of document IDs   that have local changes, but which have not yet been pushed to the server.   This can be very useful in tracking the progress of a push sync, enabling the app to provide a visual indicator to the   end user on its status, or decide when it is safe to exit.</li> <li>Use the <code>Replicator.isDocumentPending()</code> method   to quickly check whether an individual document is pending a push.</li> </ul> <p>Example 16. Use Pending Document ID API</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"ws://localhost:4984/mydatabase\"))\n        .addCollection(collection)\n        .setType(ReplicatorType.PUSH)\n)\n\nval pendingDocs = repl.getPendingDocumentIds()\n\n// iterate and report on previously\n// retrieved pending docIds 'list'\nif (pendingDocs.isNotEmpty()) {\n    println(\"There are ${pendingDocs.size} documents pending\")\n\n    val firstDoc = pendingDocs.first()\n    repl.addChangeListener { change -&gt;\n        println(\"Replicator activity level is ${change.status.activityLevel}\")\n        try {\n            if (!repl.isDocumentPending(firstDoc)) {\n                println(\"Doc ID $firstDoc has been pushed\")\n            }\n        } catch (err: CouchbaseLiteException) {\n            println(\"Failed getting pending docs\\n$err\")\n        }\n    }\n\n    repl.start()\n    this.replicator = repl\n}\n</code></pre> <ol> <li><code>Replicator.getPendingDocumentIds()</code>    returns a list of the document IDs for all documents waiting to be pushed. This is a snapshot and may have changed by    the time the response is received and processed.</li> <li><code>Replicator.isDocumentPending()</code> returns    <code>true</code> if the document is waiting to be pushed, and <code>false</code> otherwise.</li> </ol>"},{"location":"remote-sync-gateway/#stop","title":"Stop","text":"<p>Stopping a replication is straightforward. It is done using <code>stop()</code>. This initiates an asynchronous operation and so is not necessarily immediate. Your app should account for this potential delay before attempting any subsequent operations.</p> <p>You can find further information on database operations in Databases.</p> <p>Example 17. Stop replicator</p> <pre><code>// Stop replication.\nrepl.stop()\n</code></pre> <p>Here we initiate the stopping of the replication using the <code>stop()</code> method. It will stop any active change listener  once the replication is stopped.</p>"},{"location":"remote-sync-gateway/#error-handling","title":"Error Handling","text":"<p>When a replicator detects a network error it updates its status depending on the error type (permanent or temporary) and returns an appropriate HTTP error code.</p> <p>The following code snippet adds a change listener, which monitors a replication for errors and logs the returned error code.</p> <p>Example 18. Monitoring for network errors</p> <pre><code>repl.addChangeListener { change -&gt;\n    change.status.error?.let {\n        println(\"Error code: ${it.code}\")\n    }\n}\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>For permanent network errors (for example, <code>404</code> not found, or <code>401</code> unauthorized): Replicator will stop permanently, whether <code>setContinuous</code> is true or false. Of course, it sets its status to <code>STOPPED</code>.</p> <p>For recoverable or temporary errors: Replicator sets its status to <code>OFFLINE</code>, then:</p> <ul> <li>If <code>setContinuous=true</code> it retries the connection indefinitely</li> <li>If <code>setContinuous=false</code> (one-shot) it retries the connection a limited number of times.</li> </ul> <p>The following error codes are considered temporary by the Couchbase Lite replicator and thus will trigger a connection retry:</p> <ul> <li><code>408</code>: Request Timeout</li> <li><code>429</code>: Too Many Requests</li> <li><code>500</code>: Internal Server Error</li> <li><code>502</code>: Bad Gateway</li> <li><code>503</code>: Service Unavailable</li> <li><code>504</code>: Gateway Timeout</li> <li><code>1001</code>: DNS resolution error</li> </ul>"},{"location":"remote-sync-gateway/#using-kotlin-flows_1","title":"Using Kotlin Flows","text":"<p>Kotlin developers can also take advantage of <code>Flow</code>s to monitor replicators.</p> <pre><code>scope.launch {\n    repl.replicatorChangesFlow()\n        .mapNotNull { it.status.error }\n        .collect { error -&gt;\n            println(\"Replication error :: $error\")\n        }\n}\n</code></pre>"},{"location":"remote-sync-gateway/#load-balancers","title":"Load Balancers","text":"<p>Couchbase Lite uses WebSockets as the communication protocol to transmit data. Some load balancers are not configured for WebSocket connections by default (NGINX for example); so it might be necessary to explicitly enable them in the load balancer\u2019s configuration \u2014 see Load Balancers.</p> <p>By default, the WebSocket protocol uses compression to optimize for speed and bandwidth utilization. The level of compression is set on Sync Gateway and can be tuned in the configuration file (<code>replicator_compression</code>).</p>"},{"location":"remote-sync-gateway/#certificate-pinning","title":"Certificate Pinning","text":"<p>Couchbase Lite supports certificate pinning.</p> <p>Certificate pinning is a technique that can be used by applications to \"pin\" a host to its certificate. The certificate is typically delivered to the client by an out-of-band channel and bundled with the client. In this case, Couchbase Lite uses this embedded certificate to verify the trustworthiness of the server (for example, a Sync Gateway) and no longer needs to rely on a trusted third party for that (commonly referred to as the Certificate Authority).</p> <p>For the 3.0.2. release, changes have been made to the way certificates on the host are matched:</p> Prior to CBL 3.0.2 The pinned certificate was only compared with the leaf certificate of the host. This is not always suitable as leaf certificates are usually valid for shorter periods of time. CBL 3.0.2+ The pinned certificate will be compared against any certificate in the server\u2019s certificate chain. <p>The following steps describe how to configure certificate pinning between Couchbase Lite and Sync Gateway:</p> <ol> <li>Create your own self-signed certificate with    the <code>openssl</code> command. After completing this step, you should have 3 files: <code>cert.pem</code>, <code>cert.cer</code>, and    <code>privkey.pem</code>.</li> <li>Configure Sync Gateway with the    <code>cert.pem</code> and <code>privkey.pem</code> files. After completing this step, Sync Gateway is reachable over <code>https</code>/<code>wss</code>.</li> <li>On the Couchbase Lite side, the replication must point to a URL with the <code>wss</code> scheme and configured with the    <code>cert.cer</code> file created in step 1.</li> </ol> <p>This example loads the certificate from the application sandbox, then converts it to the appropriate type to configure the replication object.</p> <p>Example 19. Cert Pinnings</p> <pre><code>val repl = Replicator(\n    ReplicatorConfiguration(URLEndpoint(\"wss://localhost:4984/mydatabase\"))\n        .addCollections(collections)\n        .setPinnedServerCertificate(PlatformUtils.getAsset(\"cert.cer\")?.readByteArray())\n)\nrepl.start()\nthis.replicator = repl\n</code></pre> <p>Note</p> <p><code>PlatformUtils.getAsset()</code> needs to be implemented in a platform-specific way \u2014 see example in Kotbase tests.</p> <p>The replication should now run successfully over <code>https</code>/<code>wss</code> with certificate pinning.</p> <p>For more on pinning certificates see the blog entry: Certificate Pinning with Couchbase Mobile.</p>"},{"location":"remote-sync-gateway/#troubleshooting","title":"Troubleshooting","text":""},{"location":"remote-sync-gateway/#logs","title":"Logs","text":"<p>As always, when there is a problem with replication, logging is your friend. You can increase the log output for activity related to replication with Sync Gateway \u2014 see Example 20.</p> <p>Example 20. Set logging verbosity</p> <pre><code>LogSinks.console = ConsoleLogSink(LogLevel.DEBUG, LogDomain.REPLICATOR)\n</code></pre> <p>For more on troubleshooting with logs, see Using Logs.</p>"},{"location":"remote-sync-gateway/#authentication-errors","title":"Authentication Errors","text":"<p>If Sync Gateway is configured with a self-signed certificate but your app points to a <code>ws</code> scheme instead of <code>wss</code> you will encounter an error with status code <code>11006</code> \u2014 see Example 21.</p> <p>Example 21. Protocol Mismatch</p> <pre><code>CouchbaseLite Replicator ERROR: {Repl#2} Got LiteCore error: WebSocket error 1006 \"connection closed abnormally\"\n</code></pre> <p>If Sync Gateway is configured with a self-signed certificate, and your app points to a <code>wss</code> scheme but the replicator configuration isn\u2019t using the certificate you will encounter an error with status code <code>5011</code> \u2014 see Example 22 .</p> <p>Example 22. Certificate Mismatch or Not Found</p> <pre><code>CouchbaseLite Replicator ERROR: {Repl#2} Got LiteCore error: Network error 11 \"server TLS certificate is self-signed or has unknown root cert\"\n</code></pre>"},{"location":"roadmap/","title":"Roadmap","text":"<ul> <li> Documentation website (kotbase.dev)</li> <li> <code>NSInputStream</code> interoperability (Okio #1123) (kotlinx-io #174)</li> <li> Linux ARM64 support</li> <li> Public release</li> <li> Sample apps<ul> <li> Getting Started</li> <li> Getting Started Compose Multiplatform</li> <li> Kotbase Notes</li> <li> SwiftUI for Kotbase Notes</li> </ul> </li> <li> Couchbase Lite 3.1 API - Scopes and Collections</li> <li> Versioned docs</li> <li> Couchbase Lite 3.2 API - Vector Search</li> <li> Couchbase Lite 3.3 API - Multipeer Replicator</li> <li> Couchbase Lite 4.0 API - Version Vectors</li> <li> Improve Swift API alignment with Couchbase Lite using Swift   export, <code>@ObjCName</code>, and/or <code>@ShouldRefineInSwift</code></li> <li> Async coroutines API</li> </ul>"},{"location":"scopes-and-collections/","title":"Scopes and Collections","text":"<p>Scopes and collections allow you to organize your documents within a database.</p> <p>At a glance</p> <p>Use collections to organize your content in a database</p> <p>For example, if your database contains travel information, airport documents can be assigned to an airports collection, hotel documents can be assigned to a hotels collection, and so on.</p> <ul> <li>Document names must be unique within their collection.</li> </ul> <p>Use scopes to group multiple collections</p> <p>Collections can be assigned to different scopes according to content-type or deployment-phase (for example, test versus production).</p> <ul> <li>Collection names must be unique within their scope.</li> </ul>"},{"location":"scopes-and-collections/#default-scopes-and-collections","title":"Default Scopes and Collections","text":"<p>Every database you create contains a default scope and a default collection named _default.</p> <p>If you create a document in the database and don\u2019t specify a specific scope or collection, it is saved in the default collection, in the default scope.</p> <p>If you upgrade from a version of Couchbase Lite prior to 3.1, all existing data is automatically placed in the default scope and default collection.</p> <p>The default scope and collection cannot be dropped.</p>"},{"location":"scopes-and-collections/#create-a-scope-and-collection","title":"Create a Scope and Collection","text":"<p>In addition to the default scope and collection, you can create your own scope and collection when you create a document.</p> <p>Naming conventions for collections and scopes:</p> <ul> <li>Must be between 1 and 251 characters in length.</li> <li>Can only contain the characters <code>A-Z</code>, <code>a-z</code>, <code>0-9</code>, and the symbols <code>_</code>, <code>-</code>, and <code>%</code>.</li> <li>Cannot start with <code>_</code> or <code>%</code>.</li> <li>Scope names must be unique in databases.</li> <li>Collection names must be unique within a scope.</li> </ul> <p>Note</p> <p>Scope and collection names are case sensitive.</p> <p>Example 1. Create a scope and collection</p> <pre><code>// create the collection \"Verlaine\" in the default scope (\"_default\")\nvar collection1: Collection? = db.createCollection(\"Verlaine\")\n// both of these retrieve collection1 created above\ncollection1 = db.getCollection(\"Verlaine\")\ncollection1 = db.defaultScope.getCollection(\"Verlaine\")\n\n// create the collection \"Verlaine\" in the scope \"Television\"\nvar collection2: Collection? = db.createCollection(\"Television\", \"Verlaine\")\n// both of these retrieve  collection2 created above\ncollection2 = db.getCollection(\"Television\", \"Verlaine\")\ncollection2 = db.getScope(\"Television\")!!.getCollection(\"Verlaine\")\n</code></pre> <p>In the example above, you can see that <code>db.createCollection()</code> can take two parameters. The first is the scope assigned to the created collection, if this parameter is omitted then a collection of the given name will be assigned to the <code>_default</code> scope. In this case, creating a collection called <code>Verlaine</code>.</p> <p>The second parameter is the name of the collection you want to create, in this case <code>Verlaine</code>. In the second section of the example you can see <code>db.createCollection(\"Television\", \"Verlaine\")</code>. This creates the collection <code>Verlaine</code> and then checks to see if the scope <code>Television</code> exists. If the scope <code>Television</code> exists, the collection <code>Verlaine</code> is assigned to the scope <code>Television</code>. If not, a new scope, <code>Television</code>, is created and then the collection <code>Verlaine</code> is assigned to it.</p> <p>Note</p> <p>You cannot create an empty user-defined scope. A scope is implicitly created in the <code>db.createCollection()</code> method.</p>"},{"location":"scopes-and-collections/#index-a-collection","title":"Index a Collection","text":"<p>Example 2. Index a Collection</p> <pre><code>// Create an index named \"nameIndex1\" on the property \"lastName\" in the collection using the IndexBuilder\ncollection.createIndex(\"nameIndex1\", IndexBuilder.valueIndex(ValueIndexItem.property(\"lastName\")))\n\n// Create a similar index named \"nameIndex2\" using an IndexConfiguration\ncollection.createIndex(\"nameIndex2\", ValueIndexConfiguration(\"lastName\"))\n\n// get the names of all the indices in the collection\nval indices = collection.indexes\n\n// delete all the collection indices\nindices.forEach { collection.deleteIndex(it) }\n</code></pre>"},{"location":"scopes-and-collections/#drop-a-collection","title":"Drop a Collection","text":"<p>Example 3. Drop a Collection</p> <pre><code>db.getCollection(collectionName, scopeName)?.let {\n    db.deleteCollection(it.name, it.scope.name)\n}\n</code></pre> <p>Note</p> <p>There is no need to drop a user-defined scope. User-defined scopes are dropped when the collections associated with them contain no documents.</p>"},{"location":"scopes-and-collections/#list-scopes-and-collections","title":"List Scopes and Collections","text":"<p>Example 4. List Scopes and Collections</p> <pre><code>// List all of the collections in each of the scopes in the database\ndb.scopes.forEach { scope -&gt;\n    println(\"Scope :: ${scope.name}\")\n    scope.collections.forEach {\n        println(\"    Collection :: ${it.name}\")\n    }\n}\n</code></pre>"},{"location":"vector-search/","title":"Vector Search","text":"<p>Use Vector Search to build adaptive and user-focused applications using Generative AI.</p>"},{"location":"vector-search/#about-vector-search","title":"About Vector Search","text":"<p>This is an Enterprise Edition feature.</p> <p>Vector Search is a technique to retrieve semantically similar items based on vector embedding representations of the items in a multi-dimensional space. You can use Vector Search to find the top N items similar to a given item based on their vector representations. Vector Search is an essential component of Generative AI and Predictive AI applications.</p> <p>Vector Search is a sophisticated data retrieval technique that focuses on matching the contextual meanings of search queries and data entries, rather than simple text matching. Vectors are represented by arrays of numbers known as an embedding, which are generated by Large Language Models (LLMs) to depict objects such as text, images, and audio.</p> <p>Once you choose the LLM you wish to integrate in your application, you can create vector indexes that will store these embeddings for improved search performance and start querying against them.</p>"},{"location":"vector-search/#applications-of-vector-search","title":"Applications of Vector Search","text":"<p>You can use Vector Search to enhance your mobile and edge applications in a variety of use cases, these include:</p> <ul> <li>Perform Semantic and Similarity Search on the Edge - Any offline-first mobile or IoT application can benefit from rich   semantic text capabilities offered by Vector Search to retrieve contextually relevant data and present it to users.</li> <li>Create Recommendation Engines - Vector Search enables the creation of advanced recommendation systems that analyze   semantic similarities between items, user behavior, and preferences. This approach delivers personalized   recommendations, improving user engagement and satisfaction.</li> <li>Enhance the contextual relevance of your applications with Retrieval Augmented Generation (RAG) - RAG is a technique   for enhancing the accuracy and reliability of generative AI models with facts fetched from external sources that are   contextual to your application, such as an internal vector database. The search results are then included as context   data to queries sent to the LLM in order to customize query responses. This results in the LLM returning a result that   is likely to be far more contextually relevant than the standalone prompt.</li> </ul> <p>Additionally, Vector Search in Couchbase Lite provides the following benefits:</p> <ul> <li>Unified Cloud-to-Edge Support for Vector Similarity Search - Couchbase supports Vector Search from cloud to edge,   which enables applications to efficiently utilize cloud and edge computing\u2019s strengths.</li> <li>Enhanced Data Privacy on the Edge - By performing Vector Search within the device, personal data and search queries of   a sensitive nature do not have to leave the device.</li> <li>Low Latency Application Support - You can run searches locally against a local dataset using a local embedded model.   This eliminates the network variability and results in more consistent execution speed. Even in the case where the   model is not embedded within the local device but is deployed at the edge location, the round trip time (RTT)   associated with queries can be significantly reduced compared to searches made over the Internet.</li> <li>Cost Per Query Reduction - When you have hundreds of thousands of connected clients querying against a cloud-based   LLM, the load on cloud model and operational costs of running the cloud based model can be considerably high. By   running queries locally on the device, you can save on data transfer costs and cloud egress charges while also   decentralizing the operational costs.</li> </ul>"},{"location":"vector-search/#key-concepts-of-vector-search-in-couchbase-lite","title":"Key Concepts of Vector Search in Couchbase Lite","text":"<p>When working with Vector Search, you should be aware of the core concepts below.</p>"},{"location":"vector-search/#about-vector-embeddings","title":"About Vector Embeddings","text":"<p>Vector embeddings represent the output of a Machine Learning (ML) model as an array of numbers to capture semantic or contextual relationships between data points. This representation encodes how a ML model understands the input or inputs provided to it, based on how the model was initially trained and the internal structure of the model. When a model considers the features of a given input as similar, the distance between the vector embeddings will be short. Vector embeddings are stored within embedded vector indexes.</p> <p>The current supported formats for Vector embeddings are:</p> <ul> <li>An array of 32-bit floats.</li> <li>A Base64 string that encodes a Little-endian array of 32-bit floats.</li> </ul>"},{"location":"vector-search/#about-vector-indexes","title":"About Vector Indexes","text":"<p>Vector Indexes are used to store and manage vector representations of content in the form of vector embeddings. You can use Vector Indexes to efficiently retrieve vectors, similar to a target vector. Before use, a Vector Index needs to be trained to compute the centroids and parameters for encoding the vectors.</p> <p>You can configure both the minimum and maximum training sizes for your vector index by setting the relevant parameters in your vector index configuration. For an example of how you can do so, see create a vector index.</p> <p>Couchbase Lite Vector Search initiates training on the first Vector Search query automatically when the number of vectors to be trained satisfies the <code>minimum-training-size</code> configuration. If the database does not contain the required number of vectors, an error message will be logged indicating the required number of vectors.</p> <p>See Vector Index Configuration for more information about configurations you can modify for your vector index.</p> <p>Be aware that vector index training can affect query performance. If a query is executed against the index before it is trained, a full scan of the vectors will be performed.</p>"},{"location":"vector-search/#about-lazy-vector-indexes","title":"About Lazy Vector Indexes","text":"<p>Important</p> <p>Lazy index is not an automatic process, you will need to manually schedule the index updates.</p> <p>Lazy vector indexes (lazy index) is Couchbase Lite specific functionality that updates indexes asynchronously, satisfying the following use cases:</p> <ul> <li>Documents have been added to the application by the end-user with no available Machine Learning (ML) model to generate   the vectors. You can use lazy indexing to schedule updates to the index of such documents when a ML model is   available.</li> <li>The remote ML model used stops working or has intermittent availability, causing a failed update. With lazy indexing,   you can skip documents that fail to update and schedule the index process at a later date.</li> </ul> <p>Lazy indexing is an asynchronous process that provides developers full control of:</p> <ul> <li>When to update the index.</li> <li>The number of vectors to update to the index.</li> <li>Whether to cancel or skip certain indexes when the model is unavailable or has failed.</li> </ul> <p>Note</p> <p>Updating in lazy index is an independent process from saving document operations.</p> <p>See here for examples of how to use lazy index in your applications.</p> <p>Lazy indexing is an alternate approach to using the standard predictive model with regular vector indexes which handle the indexing process automatically. The table below compares the two processes.</p> <p>Table 1. Regular Vector Indexes vs Lazy Vector Indexes</p> Feature Regular Index Lazy Index Update when documents are changed Update when documents are deleted or purged The application has control when to update the index The application can skip updating the index Is an asynchronous process"},{"location":"vector-search/#about-vector-encoding","title":"About Vector Encoding","text":"<p>Vector encoding reduces the size of the vectors index by algorithmic compression. You can configure the Vector Encoding in Couchbase Lite to address your application\u2019s needs.</p> <p>This vector encoding compression reduces disk space required and I/O time during indexing and queries, but greater compression can result in inaccurate results in distance calculations.</p> <p>Vector Search for Couchbase Lite supports the following encoding algorithms:</p> <ul> <li>None - This will return the highest quality results but at high performance and disk space costs.</li> <li>Scalar Quantizer - This reduces the number of bits used for each number in a vector. The number of bits per component   can be set to 4, 6, or 8 bits. The default setting in Couchbase Lite is 8 bits Scalar Quantizer or SQ-8.</li> <li>Product Quantizer - This reduces the number of dimensions and bits per dimension. It splits the vectors into multiple   subspaces and performing scalar quantization on each space independently before compression. This can produce higher   quality results than Scalar Quantization at the cost of greater complexity.</li> </ul> <p>Note</p> <p>Quantizers are algorithmic processes that map input values from a larger set to output values in a smaller set, common quantization processes can include operations such as rounding and truncation.</p>"},{"location":"vector-search/#about-centroids","title":"About Centroids","text":"<p>Centroids are vectors that function as the center point of a vector cluster within the data set. Each vector is then associated to the vector it is closest to by k-means clustering. Each Centroid is contained within a bucket along with its associated vectors. The greater the number of Centroids, the greater the potential accuracy of the model. However, a greater number of Centroids will incur a longer indexing time.</p> <p>Choosing Centroids in Vector Search involves trade-offs that can impact clustering effectiveness and search efficiency. The initial selection of Centroids, the number chosen, and their sensitivity to high dimensionality and outliers affect the quality of vector clustering.</p> <p>The general guideline for the optimum number of Centroids is approximately the square root of the number of documents.</p>"},{"location":"vector-search/#about-probes","title":"About Probes","text":"<p>The number of Probes refers to the maximum number of Centroid buckets that the search algorithm will check to look for similar vectors to a given query vector. You can change the number of Probes by altering the value of the <code>NumProbes</code> variable shown in the following example. Couchbase recommends that when setting a custom number of probes, the number should be at least 8 or 0.5% the number of Centroids used.</p>"},{"location":"vector-search/#about-dimensions","title":"About Dimensions","text":"<p>Vector dimensions describes the amount of numbers in a given vector embedding, commonly known as its width. The greater the number of dimensions, the greater accuracy of results. However, a greater number of dimensions also results in greater compute and memory costs and an increase in the latency of the search. Vector dimensions are dependent on the LLM used to generate the Vector Embeddings.</p> <p>Note</p> <p>Couchbase Lite supports dimension sizes in the range of <code>2 - 4096</code>.</p>"},{"location":"vector-search/#about-distance-metrics","title":"About Distance Metrics","text":"<p>Distance metrics are functions used to define how close an input query vector is to other vectors within a vector index.</p> <p>Couchbase Lite supports the following distance metrics:</p> <ul> <li>Squared Euclidean Distance - This is the default distance metric. This measures the straight-line distance between two   points in Euclidean space which is defined by n dimensions, such as x,y,z. This metric focuses on the spatial   separation or distance between two vectors. Both the magnitude and direction of the vectors matter. The smaller the   distance value, the more similar the vectors are. You can use this metric to simplify computation in situations where   only the relative distance matters, rather than actual distance.</li> <li>Euclidean Distance - This measures the straight-line distance between two points in Euclidean space which is defined   by n dimensions, such as x,y,z. This metric focuses on the spatial separation or distance between two vectors. Both   the magnitude and direction of the vectors matter. The smaller the distance value, the more similar the vectors are.   This differs from Squared Euclidean Distance by taking the square root of the calculated distance between two point.   The result is a \"true\" geometric distance. You can use this metric when the actual geometric distance matters, such as   calculating distance between cities using GPS coordinates.</li> <li>Cosine Distance - This measures the cosine of the angle between two vectors in vector space. This metric focuses on   the alignment of two vectors, the similarity of direction. Only the direction of the vectors matter. The smaller the   distance value, the more similar the vectors are. You can use this metric when comparing similarity of document   content no matter the document size in text similarity or information retrieval applications.</li> <li>Dot Product Distance - This metric captures the overall similarity by comparing the magnitude and direction of   vectors. The result is larger when the vectors are aligned and have large magnitudes and smaller in the opposite case.   You can use this metric in recommendation systems to provide users with related content with preference to items the   most similar to frequently visited items.</li> </ul>"},{"location":"vector-search/#hybrid-vector-search","title":"Hybrid Vector Search","text":"<p>Hybrid Vector Search (Hybrid Search) combines traditional keyword-based search such as full text search (FTS), which matches exact text or metadata with advanced methods such as Vector Search which matches content based on semantic similarity. Hybrid Search aims to enhance search capabilities by using both exact matches and contextual relevance to improve the overall accuracy and relevance of search results. See the following examples for more information on how to use Hybrid Search.</p> <p>Vector Search will be performed on the documents that have been filtered based on the criteria specified in the WHERE clause. No LIMIT clause is required for Hybrid Vector Search.</p> <p>See the Hybrid Search blog post for more information about Hybrid Search.</p>"},{"location":"working-with-vector-search/","title":"Working with Vector Search","text":"<p>Use Vector Search with Full Text Search and Query.</p>"},{"location":"working-with-vector-search/#use-vector-search","title":"Use Vector Search","text":"<p>This is an Enterprise Edition feature.</p> <p>To configure a project to use vector search, follow the installation instructions to add the Vector Search extension.</p> <p>Note</p> <p>You must install Couchbase Lite to use the Vector Search extension.</p>"},{"location":"working-with-vector-search/#create-a-vector-index","title":"Create a Vector Index","text":"<p>This method shows how you can create a vector index using the Couchbase Lite Vector Search extension.</p> <pre><code>// create the configuration for a vector index named \"vector\"\n// with 3 dimensions, 100 centroids, no encoding, using cosine distance\n// with a max training size 5000 and amin training size 2500\n// no vector encoding and using COSINE distance measurement\nval config = VectorIndexConfiguration(\"vector\", 3L, 100L).apply {\n    encoding = VectorEncoding.none()\n    metric = VectorIndexConfiguration.DistanceMetric.COSINE\n    numProbes = 8L\n    minTrainingSize = 2500L\n    maxTrainingSize = 5000L\n}\n</code></pre> <p>First, initialize the <code>config</code> object with the <code>VectorIndexConfiguration()</code> method with the following parameters:</p> <ul> <li>The expression of the data as a vector.</li> <li>The width or <code>dimensions</code> of the vector index is set to <code>3</code>.</li> <li>The amount of <code>centroids</code> is set to <code>100</code>. This means that there will be one hundred buckets with a single centroid   each that gathers together similar vectors.</li> </ul> <p>You can also alter some optional config settings such as <code>encoding</code>. From there, you create an index within a given collection using the previously generated <code>config</code> object.</p> <p>Note</p> <p>The number of vectors, the width or dimensions of the vectors and the training size can incur high CPU and memory costs as the size of each variable increases. This is because the training vectors have to be resident on the machine.</p>"},{"location":"working-with-vector-search/#vector-index-configuration","title":"Vector Index Configuration","text":"<p>The table below displays the different configurations you can modify within your <code>VectorIndexConfiguration()</code> function. For more information on specific configurations, see Vector Search.</p> <p>Table 1. Vector Index Configuration Options</p> Configuration Name Is Required Default Configuration Further Information Expression No default A SQL++ expression indicating where to get the vectors. A document property for embedded vectors or <code>prediction()</code> to call a registered Predictive model. Number of Dimensions No default 2-4096 Number of Centroids No default 1-64000. The general guideline is an approximate square root of the number of documents. Distance Metric Squared Euclidean Distance (euclideanSquared) You can set the following alternates as your Distance Metric:<ul><li>cosine (1 - Cosine similarity)</li><li>Euclidean</li><li>dot (negated dot product)</li></ul> Encoding Scalar Quantizer(SQ) or SQ-8 bits There are three possible configurations:<ul><li>None No compression, No data loss</li><li>Scalar Quantizer (SQ) or SQ-8 bits (Default) Reduces the number of bits per dimension</li><li>Product Quantizer (PQ) Reduces the number of dimensions and bits per dimension</li></ul> Training Size The default values for both the minimum and maximum training size is zero. The training size is calculated based on the number of Centroids and the encoding type. The guidelines for the minimum and maximum training size are as follows:<ul><li>The minimum training size is set to 25x the number of Centroids or 2<sup>PQ\u2019s bits</sup> when PQ is used</li><li>The maximum training size is set to 256x the number of Centroids or 2<sup>PQ\u2019s bits</sup> when PQ is used</li></ul> NumProbes The default value is 0. The number of Probes is calculated based on the number of Centroids. A guideline for setting a custom number of probes is at least 8 or 0.5% the number of Centroids. isLazy False Setting the value to true will enable lazy mode for the vector index. <p>Caution</p> <p>Altering the default training sizes could be detrimental to the accuracy of returned results produced by the model and total computation time.</p>"},{"location":"working-with-vector-search/#generating-vectors","title":"Generating Vectors","text":"<p>You can use the following methods to generate vectors in Couchbase Lite:</p> <ol> <li>You can call a Machine Learning(ML) model, and embed the generated vectors inside the documents.</li> <li>You can use the <code>prediction()</code> function to generate vectors to be indexed for each document at the indexing time.</li> <li>You can use Lazy Vector Index (lazy index) to generate vectors asynchronously from remote ML models that may not always be reachable or functioning, skipping or scheduling retries for those specific cases.</li> </ol> <p>Below are example configurations of the previously mentioned methods.</p>"},{"location":"working-with-vector-search/#create-a-vector-index-with-embeddings","title":"Create a Vector Index with Embeddings","text":"<p>This method shows you how to create a Vector Index with embeddings.</p> <pre><code>// Get the collection named \"colors\" in the default scope.\nval collection = database.getCollection(\"colors\")\n    ?: throw IllegalStateException(\"No such collection: colors\")\n\n// Create a vector index configuration with a document property named \"vector\",\n// 3 dimensions, and 100 centroids.\nval config = VectorIndexConfiguration(\"vector\", 3, 100)\n// Create a vector index from the configuration with the name \"colors_index\".\ncollection.createIndex(\"colors_index\", config)\n</code></pre> <ol> <li>First, create the standard configuration, setting up an expression, number of dimensions and number of centroids for    the vector embedding.</li> <li>Next, create a vector index, <code>colors_index</code>, on a collection and pass it the configuration.</li> </ol>"},{"location":"working-with-vector-search/#create-vector-index-embeddings-from-a-predictive-model","title":"Create Vector Index Embeddings from a Predictive Model","text":"<p>This method generates vectors to be indexed for each document at the index time by using the <code>prediction()</code> function. The key difference to note is that the <code>config</code> object uses the output of the <code>prediction()</code> function as the <code>expression</code> parameter to generate the vector index.</p> <pre><code>class ColorModel : PredictiveModel {\n    override fun predict(input: Dictionary): Dictionary? {\n        // Get the color input from the input dictionary\n        val color = input.getString(\"colorInput\")\n            ?: throw IllegalStateException(\"No input color found\")\n\n        // Use ML model to get a vector (an array of floats) for the input color.\n        val vector = Color.getVector(color) ?: return null\n\n        // Create an output dictionary by setting the vector result to\n        // the dictionary key named \"vector\".\n        val output = MutableDictionary()\n        output.setValue(\"vector\", vector)\n        return output\n    }\n}\n\nfun createVectorIndexFromPredictiveIndex() {\n    // Register the predictive model named \"ColorModel\".\n    Database.prediction.registerModel(\"ColorModel\", ColorModel())\n\n    // Create a vector index configuration with an expression using the prediction\n    // function to get the vectors from the registered predictive model.\n    val expression = \"prediction(ColorModel, {\\\"colorInput\\\": color}).vector\"\n    val config = VectorIndexConfiguration(expression, 3, 100)\n\n    // Create vector index from the configuration\n    collection.createIndex(\"colors_index\", config)\n}\n</code></pre> <p>Note</p> <p>You can use less storage by using the <code>prediction()</code> function as the encoded vectors will only be stored in the index. However, the index time will be longer as vector embedding generation is occurring at run time.</p>"},{"location":"working-with-vector-search/#create-a-lazy-vector-index","title":"Create a Lazy Vector Index","text":"<p>Lazy indexing is an alternate approach to using the standard predictive model with regular vector indexes which handle the indexing process automatically. You can use lazy indexing to use a ML model that is not available locally on the device and to create vector indexes without having vector embeddings in the documents.</p> <pre><code>// Creating a lazy vector index using the document's property named \"color\".\n// The \"color\" property's value will be used to compute a vector when updating the index.\nval config = VectorIndexConfiguration(\"color\", 3, 100).apply { \n    isLazy = true\n}\n</code></pre> <p>You can enable lazy vector indexing by setting the <code>isLazy</code> property to <code>true</code> in your vector index configuration.</p> <p>Note</p> <p>Lazy Vector Indexing is opt-in functionality, the <code>isLazy</code> property is set to <code>false</code> by default.</p>"},{"location":"working-with-vector-search/#updating-the-lazy-index","title":"Updating the Lazy Index","text":"<p>Below is an example of how you can update your lazy index.</p> <pre><code>val index = collection.getIndex(\"colors_index\")\n    ?: throw IllegalStateException(\"colors_index not found\")\n\nwhile (true) {\n    // Start an update on it (in this case, limit to 50 entries at a time)\n    index.beginUpdate(50)?.use { updater -&gt;\n        for (i in 0..&lt;updater.count) {\n            // The value type will depend on the expression you have set in your index.\n            // In this example, it is a string property.\n            val color = updater.getString(i)\n\n            try {\n                val embedding: List&lt;Float&gt;? = Color.getVectorAsync(color)\n                // Set the computed vector here. If vector is null, calling setVector\n                // will cause the underlying document to NOT be indexed.\n                updater.setVector(embedding, i)\n            } catch (e: IOException) {\n                // Bad connection? Corrupted over the wire? Something bad happened\n                // and the vector cannot be generated at the moment: skip it.\n                // The next time beginUpdate() is called, we'll try it again.\n                updater.skipVector(i)\n            }\n        }\n        // This writes the vectors to the index. You MUST either have set or skipped each\n        // of the vectors in the updater or this call will throw an exception.\n        updater.finish()\n    }\n    // loop until there are no more vectors to update\n        ?: break\n}\n</code></pre> <p>You procedurally update the vectors in the index by looping through the vectors in batches until you reach the value of the <code>limit</code> parameter.</p> <p>The update process follows the following sequence:</p> <ol> <li> <p>Get a value for the updater.</p> <ol> <li>If the there is no value for the vector, handle it. In this case, the vector will be skipped and considered the    next time <code>beginUpdate()</code> is called.</li> </ol> <p>Note</p> <p>A key benefit of lazy indexing is that the indexing process continues if a vector fails to generate. For standard vector indexing, this will cause the affected documents to be dropped from the indexing process.</p> </li> <li> <p>Set the vector from the computed vector derived from the updater value and your ML model.</p> <ol> <li>If there is no value for the vector, this will result in the underlying document to not be indexed.</li> </ol> </li> <li>Once all vectors have completed the update loop, finish updating.</li> </ol> <p>Note</p> <p><code>updater.finish()</code> will throw an error if any values inside the updater have not been set or skipped.</p>"},{"location":"working-with-vector-search/#vector-search-sql-support","title":"Vector Search SQL++ Support","text":"<p>Couchbase Lite currently supports Hybrid Vector Search and the <code>APPROX_VECTOR_DISTANCE()</code> function.</p> <p>Important</p> <p>Similar to the Full Text Search <code>match()</code> function, the <code>APPROX_VECTOR_DISTANCE()</code> function and Hybrid Vector Search cannot use the <code>OR</code> expression with the other expressions in the related <code>WHERE</code> clause.</p>"},{"location":"working-with-vector-search/#use-hybrid-vector-search","title":"Use Hybrid Vector Search","text":"<p>You can use Hybrid Vector Search (Hybrid Search) to perform vector search in conjunction with regular SQL++ queries. With Hybrid Search, you perform vector search on documents that have already been filtered based on criteria specified in the <code>WHERE</code> clause.</p> <p>Note</p> <p>A <code>LIMIT</code> clause is required for non-hybrid Vector Search, this avoids a slow, exhaustive unlimited search of all possible vectors.</p>"},{"location":"working-with-vector-search/#hybrid-vector-search-with-full-text-match","title":"Hybrid Vector Search with Full Text Match","text":"<p>Below are examples of using Hybrid Search with the Full Text <code>match()</code> function.</p> <pre><code>// Create a hybrid vector search query with full-text's match() that\n// uses the the full-text index named \"color_desc_index\".\nval sql = $$\"\"\"\n    SELECT meta().id, color\n    WHERE MATCH(color_desc_index, $text)\n    ORDER BY approx_vector_distance(vector, $vector)\n    LIMIT 8\n\"\"\".trimIndent()\n\nval query = database.createQuery(sql)\n\n// Get a vector, an array of float numbers, for the input color code (e.g. FF000AA).\n// Normally, you will get the vector from your ML model.\nval vector = Color.getVector(\"FF00AA\")\n    ?: throw IllegalStateException(\"Vector not found\")\n\nval parameters = Parameters()\n// Set the vector array to the parameter \"$vector\"\nparameters.setValue(\"vector\", vector)\n// Set the vector array to the parameter \"$text\".\nparameters.setString(\"text\", \"vibrant\")\nquery.parameters = parameters\n\n// Execute the query\nquery.execute().use { rs -&gt;\n    // process results\n}\n</code></pre>"},{"location":"working-with-vector-search/#prediction-with-hybrid-vector-search","title":"Prediction with Hybrid Vector Search","text":"<p>Below are examples of using Hybrid Search with an array of vectors generated by the <code>Prediction()</code> function at index time.</p> <pre><code>// Create a hybrid vector search query that uses prediction() for computing vectors.\nval sql = $$\"\"\"\n    SELECT meta().id, color\n    WHERE saturation &gt; 0.5\n    ORDER BY approx_vector_distance(prediction(ColorModel, {\"colorInput\": color}).vector, $vector)\n    LIMIT 8\n\"\"\".trimIndent()\n\nval query = database.createQuery(sql)\n\n// Get a vector, an array of float numbers, for the input color code (e.g. FF000AA).\n// Normally, you will get the vector from your ML model.\nval vector = Color.getVector(\"FF00AA\")\n    ?: throw IllegalStateException(\"Vector not found\")\n\n// Set the vector array to the parameter \"$vector\"\nval parameters = Parameters()\nparameters.setValue(\"vector\", vector)\nquery.parameters = parameters\n\n// Execute the query\nquery.execute().use { rs -&gt;\n    // process results\n}\n</code></pre>"},{"location":"working-with-vector-search/#approx_vector_distancevector-expr-target-vector-metric-nprobes-accurate","title":"<code>APPROX_VECTOR_DISTANCE(vector-expr, target-vector, [metric], [nprobes], [accurate])</code>","text":"<p>Warning</p> <p>If you use a different distance metric in the <code>APPROX_VECTOR_DISTANCE()</code> function from the one configured in the index, you will receive an error when compiling the query.</p> Parameter Is Required Description vector-expr The expression returning a vector (NOT Index Name). Must match the expression specified in the vector index exactly. target-vector The target vector. metric Values : \"EUCLIDEAN_SQUARED\", \u201cL2_SQUARED\u201d, \u201cEUCLIDEAN\u201d, \u201cL2\u201d, \u201dCOSINE\u201d, \u201cDOT\u201d. If not specified, the metric set in the vector index is used. If specified, the metric must match with the metric set in the vector index. This optional parameter allows multiple indexes to be attached to the same field in a document. nprobes Number of buckets to search for the nearby vectors. If not specified, the nprobes set in the vector index is used. accurate If not present, false will be used, which means that the quantized/encoded vectors in the index will be used for calculating the distance.IMPORTANT: Only accurate = false is supported"},{"location":"working-with-vector-search/#use-approx_vector_distance","title":"Use <code>APPROX_VECTOR_DISTANCE()</code>","text":"<pre><code>// Create a vector search query by using the approx_vector_distance() in WHERE clause.\nval sql = $$\"\"\"\n    SELECT meta().id, color\n    FROM _default.colors\n    WHERE approx_vector_distance(vector, $vector) &lt; 0.5\n    LIMIT 8\n\"\"\".trimIndent()\n\nval query = database.createQuery(sql)\n\n// Get a vector, an array of float numbers, for the input color code (e.g. FF000AA).\n// Normally, you will get the vector from your ML model.\nval vector = Color.getVector(\"FF00AA\")\n    ?: throw IllegalStateException(\"Vector not found\")\n\n// Set the vector array to the parameter \"$vector\"\nval parameters = Parameters()\nparameters.setValue(\"vector\", vector)\nquery.parameters = parameters\n\n// Execute the query\nquery.execute().use { rs -&gt;\n    // process results\n}\n</code></pre> <p>This function returns the approximate distance between a given vector, typically generated from your ML model, and an array of vectors with size equal to the <code>LIMIT</code> parameter, collected by a SQL++ query using <code>APPROX_VECTOR_DISTANCE()</code>.</p>"},{"location":"working-with-vector-search/#prediction-with-approx_vector_distance","title":"Prediction with <code>APPROX_VECTOR_DISTANCE()</code>","text":"<p>Below are examples of using <code>APPROX_VECTOR_DISTANCE()</code> with an array of vectors generated by the <code>Prediction()</code> function at index time.</p> <pre><code>// Create a vector search query that uses prediction() for computing vectors.\nval sql = $$\"\"\"\n    SELECT meta().id, color\n    FROM _default.colors\n    ORDER BY APPROX_VECTOR_DISTANCE(prediction(ColorModel, {\"colorInput\": color}).vector, $vector)\n    LIMIT 8\n\"\"\".trimIndent()\n\nval query = database.createQuery(sql)\n\n// Get a vector, an array of float numbers, for the input color code (e.g. FF000AA).\n// Normally, you will get the vector from your ML model.\nval vector = Color.getVector(\"FF00AA\")\n    ?: throw IllegalStateException(\"Vector not found\")\n\n// Set the vector array to the parameter \"$vector\"\nval parameters = Parameters()\nparameters.setValue(\"vector\", vector)\nquery.parameters = parameters\n\n// Execute the query\nquery.execute().use { rs -&gt;\n    // process results\n}\n</code></pre>"}]}